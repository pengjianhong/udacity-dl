{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 语言翻译\n",
    "\n",
    "在此项目中，你将了解神经网络机器翻译这一领域。你将用由英语和法语语句组成的数据集，训练一个序列到序列模型（sequence to sequence model），该模型能够将新的英语句子翻译成法语。\n",
    "\n",
    "## 获取数据\n",
    "\n",
    "因为将整个英语语言内容翻译成法语需要大量训练时间，所以我们提供了一小部分的英语语料库。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "source_path = 'data/small_vocab_en'\n",
    "target_path = 'data/small_vocab_fr'\n",
    "source_text = helper.load_data(source_path)\n",
    "target_text = helper.load_data(target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 探索数据\n",
    "\n",
    "研究 view_sentence_range，查看并熟悉该数据的不同部分。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Stats\n",
      "Roughly the number of unique words: 228\n",
      "Number of sentences: 125733\n",
      "Average number of words in a sentence: 13.222948629238147\n",
      "\n",
      "English sentences 0 to 10:\n",
      "new jersey is sometimes quiet during autumn , and it is snowy in april .\n",
      "the united states is usually chilly during july , and it is usually freezing in november .\n",
      "california is usually quiet during march , and it is usually hot in june .\n",
      "the united states is sometimes mild during june , and it is cold in september .\n",
      "your least liked fruit is the grape , but my least liked is the apple .\n",
      "his favorite fruit is the orange , but my favorite is the grape .\n",
      "paris is relaxing during december , but it is usually chilly in july .\n",
      "new jersey is busy during spring , and it is never hot in march .\n",
      "our least liked fruit is the lemon , but my least liked is the grape .\n",
      "the united states is sometimes busy during january , and it is sometimes warm in november .\n",
      "\n",
      "French sentences 0 to 10:\n",
      "new jersey est parfois calme pendant l' automne , et il est neigeux en avril .\n",
      "les états-unis est généralement froid en juillet , et il gèle habituellement en novembre .\n",
      "california est généralement calme en mars , et il est généralement chaud en juin .\n",
      "les états-unis est parfois légère en juin , et il fait froid en septembre .\n",
      "votre moins aimé fruit est le raisin , mais mon moins aimé est la pomme .\n",
      "son fruit préféré est l'orange , mais mon préféré est le raisin .\n",
      "paris est relaxant en décembre , mais il est généralement froid en juillet .\n",
      "new jersey est occupé au printemps , et il est jamais chaude en mars .\n",
      "notre fruit est moins aimé le citron , mais mon moins aimé est le raisin .\n",
      "les états-unis est parfois occupé en janvier , et il est parfois chaud en novembre .\n"
     ]
    }
   ],
   "source": [
    "view_sentence_range = (0, 10)\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "print('Dataset Stats')\n",
    "print('Roughly the number of unique words: {}'.format(len({word: None for word in source_text.split()})))\n",
    "\n",
    "sentences = source_text.split('\\n')\n",
    "word_counts = [len(sentence.split()) for sentence in sentences]\n",
    "print('Number of sentences: {}'.format(len(sentences)))\n",
    "print('Average number of words in a sentence: {}'.format(np.average(word_counts)))\n",
    "\n",
    "print()\n",
    "print('English sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(source_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))\n",
    "print()\n",
    "print('French sentences {} to {}:'.format(*view_sentence_range))\n",
    "print('\\n'.join(target_text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 实现预处理函数\n",
    "\n",
    "### 文本到单词 id\n",
    "\n",
    "和之前的 RNN 一样，你必须首先将文本转换为数字，这样计算机才能读懂。在函数 `text_to_ids()` 中，你需要将单词中的 `source_text` 和 `target_text` 转为 id。但是，你需要在 `target_text` 中每个句子的末尾，添加 `<EOS>` 单词 id。这样可以帮助神经网络预测句子应该在什么地方结束。\n",
    "\n",
    "\n",
    "你可以通过以下代码获取  `<EOS> ` 单词ID：\n",
    "\n",
    "```python\n",
    "target_vocab_to_int['<EOS>']\n",
    "```\n",
    "\n",
    "你可以使用 `source_vocab_to_int` 和 `target_vocab_to_int` 获得其他单词 id。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def text_to_ids(source_text, target_text, source_vocab_to_int, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert source and target text to proper word ids\n",
    "    :param source_text: String that contains all the source text.\n",
    "    :param target_text: String that contains all the target text.\n",
    "    :param source_vocab_to_int: Dictionary to go from the source words to an id\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: A tuple of lists (source_id_text, target_id_text)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    source_ids = []\n",
    "    target_ids = []\n",
    "    source_sentences = source_text.split('\\n')\n",
    "    target_sentences = target_text.split('\\n')\n",
    "    for ss in source_sentences:\n",
    "        ss_id = [source_vocab_to_int[word] for word in ss.split()]\n",
    "        source_ids.append(ss_id)\n",
    "\n",
    "    eos_id = target_vocab_to_int['<EOS>']\n",
    "    for ts in target_sentences:\n",
    "        ts_id = [target_vocab_to_int[word] for word in ts.split()]\n",
    "        ts_id.append(eos_id)\n",
    "        target_ids.append(ts_id)\n",
    "    return source_ids, target_ids\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_text_to_ids(text_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 预处理所有数据并保存\n",
    "\n",
    "运行以下代码单元，预处理所有数据，并保存到文件中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "helper.preprocess_and_save_data(source_path, target_path, text_to_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 检查点\n",
    "\n",
    "这是你的第一个检查点。如果你什么时候决定再回到该记事本，或需要重新启动该记事本，可以从这里继续。预处理的数据已保存到磁盘上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import helper\n",
    "\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = helper.load_preprocess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 检查 TensorFlow 版本，确认可访问 GPU\n",
    "\n",
    "这一检查步骤，可以确保你使用的是正确版本的 TensorFlow，并且能够访问 GPU。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.0.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) in [LooseVersion('1.0.0'), LooseVersion('1.0.1')], 'This project requires TensorFlow version 1.0  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 构建神经网络\n",
    "\n",
    "你将通过实现以下函数，构建出要构建一个序列到序列模型所需的组件：\n",
    "\n",
    "- `model_inputs`\n",
    "- `process_decoding_input`\n",
    "- `encoding_layer`\n",
    "- `decoding_layer_train`\n",
    "- `decoding_layer_infer`\n",
    "- `decoding_layer`\n",
    "- `seq2seq_model`\n",
    "\n",
    "### 输入\n",
    "\n",
    "实现 `model_inputs()` 函数，为神经网络创建 TF 占位符。该函数应该创建以下占位符：\n",
    "\n",
    "- 名为 “input” 的输入文本占位符，并使用 TF Placeholder 名称参数（等级（Rank）为 2）。\n",
    "- 目标占位符（等级为 2）。\n",
    "- 学习速率占位符（等级为 0）。\n",
    "- 名为 “keep_prob” 的保留率占位符，并使用 TF Placeholder 名称参数（等级为 0）。\n",
    "\n",
    "在以下元祖（tuple）中返回占位符：（输入、目标、学习速率、保留率）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def model_inputs():\n",
    "    \"\"\"\n",
    "    Create TF Placeholders for input, targets, and learning rate.\n",
    "    :return: Tuple (input, targets, learning rate, keep probability)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    input_ = tf.placeholder(tf.int32,[None,None],name='input')\n",
    "    targets = tf.placeholder(tf.int32,[None,None],name='targets')\n",
    "    learning_rate = tf.placeholder(tf.float32,name='learning_rate')\n",
    "    keep_prob = tf.placeholder(tf.float32,name='keep_prob')\n",
    "    return (input_,targets,learning_rate,keep_prob)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_model_inputs(model_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 处理解码输入\n",
    "\n",
    "使用 TensorFlow 实现 `process_decoding_input`，以便删掉 `target_data` 中每个批次的最后一个单词 ID，并将 GO ID 放到每个批次的开头。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def process_decoding_input(target_data, target_vocab_to_int, batch_size):\n",
    "    \"\"\"\n",
    "    Preprocess target data for dencoding\n",
    "    :param target_data: Target Placehoder\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param batch_size: Batch Size\n",
    "    :return: Preprocessed target data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    ending = tf.strided_slice(target_data, [0, 0], [batch_size, -1], [1, 1])\n",
    "    target_data = tf.concat([tf.fill([batch_size, 1], target_vocab_to_int['<GO>']), ending], 1)\n",
    "    return target_data\n",
    "\n",
    "#     go_id = target_vocab_to_int['<GO>']\n",
    "#     shape = target_data.get_shape().as_list()\n",
    "#     print(\"shape: \",shape)\n",
    "#     go = tf.fill([batch_size,1],go_id) \n",
    "#     a = tf.slice(target_data,[0,1],[batch_size,shape[1]-1])\n",
    "#     target_data_p = tf.concat([go,a],1)\n",
    "#     return target_data_p\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_process_decoding_input(process_decoding_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 编码\n",
    "\n",
    "实现 `encoding_layer()`，以使用 [`tf.nn.dynamic_rnn()`](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn) 创建编码器 RNN 层级。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob):\n",
    "    \"\"\"\n",
    "    Create encoding layer\n",
    "    :param rnn_inputs: Inputs for the RNN\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: RNN state\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(rnn_size)\n",
    "    # TODO: multirnncell first or dropwarpper first??? \n",
    "    lstm_cell = tf.contrib.rnn.DropoutWrapper(lstm_cell,output_keep_prob=keep_prob)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([lstm_cell]*num_layers)\n",
    "    outputs,state = tf.nn.dynamic_rnn(cell,rnn_inputs,dtype=tf.float32)\n",
    "    return state\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_encoding_layer(encoding_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 解码 - 训练\n",
    "\n",
    "使用 [`tf.contrib.seq2seq.simple_decoder_fn_train()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_train) 和 [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) 创建训练分对数（training logits）。将 `output_fn` 应用到 [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) 输出上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope,\n",
    "                         output_fn, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for training\n",
    "    :param encoder_state: Encoder State\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embed_input: Decoder embedded input\n",
    "    :param sequence_length: Sequence Length\n",
    "    :param decoding_scope: TenorFlow Variable Scope for decoding\n",
    "    :param output_fn: Function to apply the output layer\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: Train Logits\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    train_decoder_fn = tf.contrib.seq2seq.simple_decoder_fn_train(encoder_state)\n",
    "    train_pred, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(\n",
    "        dec_cell, train_decoder_fn, dec_embed_input, sequence_length, scope=decoding_scope)\n",
    "    train_logits =  output_fn(train_pred)\n",
    "    train_logits = tf.nn.dropout(train_logits, keep_prob)\n",
    "    return train_logits\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_decoding_layer_train(decoding_layer_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 解码 - 推论\n",
    "\n",
    "使用 [`tf.contrib.seq2seq.simple_decoder_fn_inference()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/simple_decoder_fn_inference) 和 [`tf.contrib.seq2seq.dynamic_rnn_decoder()`](https://www.tensorflow.org/versions/r1.0/api_docs/python/tf/contrib/seq2seq/dynamic_rnn_decoder) 创建推论分对数（inference logits）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id,\n",
    "                         maximum_length, vocab_size, decoding_scope, output_fn, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a decoding layer for inference\n",
    "    :param encoder_state: Encoder state\n",
    "    :param dec_cell: Decoder RNN Cell\n",
    "    :param dec_embeddings: Decoder embeddings\n",
    "    :param start_of_sequence_id: GO ID\n",
    "    :param end_of_sequence_id: EOS Id\n",
    "    :param maximum_length: The maximum allowed time steps to decode\n",
    "    :param vocab_size: Size of vocabulary\n",
    "    :param decoding_scope: TensorFlow Variable Scope for decoding\n",
    "    :param output_fn: Function to apply the output layer\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: Inference Logits\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    infer_decoder_fn = tf.contrib.seq2seq.simple_decoder_fn_inference(\n",
    "        output_fn, encoder_state, dec_embeddings, start_of_sequence_id, end_of_sequence_id, \n",
    "        maximum_length, vocab_size)\n",
    "    inference_logits, _, _ = tf.contrib.seq2seq.dynamic_rnn_decoder(dec_cell, infer_decoder_fn, scope=decoding_scope)\n",
    "    inference_logits = tf.nn.dropout(inference_logits, keep_prob)\n",
    "    return inference_logits\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_decoding_layer_infer(decoding_layer_infer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 构建解码层级\n",
    "\n",
    "实现 `decoding_layer()` 以创建解码器 RNN 层级。\n",
    "\n",
    "- 使用 `rnn_size` 和 `num_layers` 创建解码 RNN 单元。\n",
    "- 使用 [`lambda`](https://docs.python.org/3/tutorial/controlflow.html#lambda-expressions) 创建输出函数，将输入，也就是分对数转换为类分对数（class logits）。\n",
    "- 使用 `decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope, output_fn, keep_prob)` 函数获取训练分对数。\n",
    "- 使用 `decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, start_of_sequence_id, end_of_sequence_id, maximum_length, vocab_size, decoding_scope, output_fn, keep_prob)` 函数获取推论分对数。\n",
    "\n",
    "注意：你将需要使用 [tf.variable_scope](https://www.tensorflow.org/api_docs/python/tf/variable_scope) 在训练和推论分对数间分享变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size,\n",
    "                   num_layers, target_vocab_to_int, keep_prob):\n",
    "    \"\"\"\n",
    "    Create decoding layer\n",
    "    :param dec_embed_input: Decoder embedded input\n",
    "    :param dec_embeddings: Decoder embeddings\n",
    "    :param encoder_state: The encoded state\n",
    "    :param vocab_size: Size of vocabulary\n",
    "    :param sequence_length: Sequence Length\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :param keep_prob: Dropout keep probability\n",
    "    :return: Tuple of (Training Logits, Inference Logits)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    dec_cell = tf.contrib.rnn.MultiRNNCell([tf.contrib.rnn.BasicLSTMCell(rnn_size)] * num_layers)\n",
    "    with tf.variable_scope(\"decoding\") as decoding_scope:\n",
    "        output_fn = lambda x: tf.contrib.layers.fully_connected(x, vocab_size, None, scope=decoding_scope)\n",
    "        train_logits = decoding_layer_train(encoder_state, dec_cell, dec_embed_input, sequence_length, decoding_scope,\n",
    "                         output_fn, keep_prob)\n",
    "    with tf.variable_scope(\"decoding\", reuse=True) as decoding_scope: \n",
    "        infer_logits = decoding_layer_infer(encoder_state, dec_cell, dec_embeddings, target_vocab_to_int['<GO>'], target_vocab_to_int['<EOS>'],\n",
    "                         sequence_length, vocab_size, decoding_scope, output_fn, keep_prob)\n",
    "    return train_logits, infer_logits\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_decoding_layer(decoding_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 构建神经网络\n",
    "\n",
    "应用你在上方实现的函数，以：\n",
    "\n",
    "- 向编码器的输入数据应用嵌入。\n",
    "- 使用 `encoding_layer(rnn_inputs, rnn_size, num_layers, keep_prob)` 编码输入。\n",
    "- 使用 `process_decoding_input(target_data, target_vocab_to_int, batch_size)` 函数处理目标数据。\n",
    "- 向解码器的目标数据应用嵌入。\n",
    "- 使用 `decoding_layer(dec_embed_input, dec_embeddings, encoder_state, vocab_size, sequence_length, rnn_size, num_layers, target_vocab_to_int, keep_prob)` 解码编码的输入数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def seq2seq_model(input_data, target_data, keep_prob, batch_size, sequence_length, source_vocab_size, target_vocab_size,\n",
    "                  enc_embedding_size, dec_embedding_size, rnn_size, num_layers, target_vocab_to_int):\n",
    "    \"\"\"\n",
    "    Build the Sequence-to-Sequence part of the neural network\n",
    "    :param input_data: Input placeholder\n",
    "    :param target_data: Target placeholder\n",
    "    :param keep_prob: Dropout keep probability placeholder\n",
    "    :param batch_size: Batch Size\n",
    "    :param sequence_length: Sequence Length\n",
    "    :param source_vocab_size: Source vocabulary size\n",
    "    :param target_vocab_size: Target vocabulary size\n",
    "    :param enc_embedding_size: Decoder embedding size\n",
    "    :param dec_embedding_size: Encoder embedding size\n",
    "    :param rnn_size: RNN Size\n",
    "    :param num_layers: Number of layers\n",
    "    :param target_vocab_to_int: Dictionary to go from the target words to an id\n",
    "    :return: Tuple of (Training Logits, Inference Logits)\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    enc_embed_input = tf.contrib.layers.embed_sequence(input_data, source_vocab_size, enc_embedding_size)\n",
    "    encoder_state = encoding_layer(enc_embed_input, rnn_size, num_layers, keep_prob)\n",
    "    \n",
    "    target_data = process_decoding_input(target_data, target_vocab_to_int, batch_size)\n",
    "    \n",
    "    dec_embeddings = tf.Variable(tf.random_uniform([target_vocab_size, dec_embedding_size]))\n",
    "    target_embed = tf.nn.embedding_lookup(dec_embeddings, target_data)\n",
    "    return decoding_layer(target_embed, dec_embeddings, encoder_state, target_vocab_size, sequence_length, rnn_size, \\\n",
    "                   num_layers, target_vocab_to_int, keep_prob)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_seq2seq_model(seq2seq_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 训练神经网络\n",
    "\n",
    "### 超参数\n",
    "\n",
    "调试以下参数：\n",
    "\n",
    "- 将 `epochs` 设为 epoch 次数。\n",
    "- 将 `batch_size` 设为批次大小。\n",
    "- 将 `rnn_size` 设为 RNN 的大小。\n",
    "- 将 `num_layers` 设为层级数量。\n",
    "- 将 `encoding_embedding_size` 设为编码器嵌入大小。\n",
    "- 将 `decoding_embedding_size` 设为解码器嵌入大小\n",
    "- 将 `learning_rate` 设为训练速率。\n",
    "- 将 `keep_probability` 设为丢弃保留率（Dropout keep probability）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Number of Epochs\n",
    "epochs = 3\n",
    "# Batch Size\n",
    "batch_size = 256\n",
    "# RNN Size\n",
    "rnn_size = 512\n",
    "# Number of Layers\n",
    "num_layers = 2\n",
    "# Embedding Size\n",
    "encoding_embedding_size = 256\n",
    "decoding_embedding_size = 256\n",
    "# Learning Rate\n",
    "learning_rate = 0.01\n",
    "# Dropout Keep Probability\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 构建图表\n",
    "\n",
    "使用你实现的神经网络构建图表。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_path = 'checkpoints/dev'\n",
    "(source_int_text, target_int_text), (source_vocab_to_int, target_vocab_to_int), _ = helper.load_preprocess()\n",
    "max_source_sentence_length = max([len(sentence) for sentence in source_int_text])\n",
    "\n",
    "train_graph = tf.Graph()\n",
    "with train_graph.as_default():\n",
    "    input_data, targets, lr, keep_prob = model_inputs()\n",
    "    sequence_length = tf.placeholder_with_default(max_source_sentence_length, None, name='sequence_length')\n",
    "    input_shape = tf.shape(input_data)\n",
    "    \n",
    "    train_logits, inference_logits = seq2seq_model(\n",
    "        tf.reverse(input_data, [-1]), targets, keep_prob, batch_size, sequence_length, len(source_vocab_to_int), len(target_vocab_to_int),\n",
    "        encoding_embedding_size, decoding_embedding_size, rnn_size, num_layers, target_vocab_to_int)\n",
    "\n",
    "    tf.identity(inference_logits, 'logits')\n",
    "    with tf.name_scope(\"optimization\"):\n",
    "        # Loss function\n",
    "        cost = tf.contrib.seq2seq.sequence_loss(\n",
    "            train_logits,\n",
    "            targets,\n",
    "            tf.ones([input_shape[0], sequence_length]))\n",
    "\n",
    "        # Optimizer\n",
    "        optimizer = tf.train.AdamOptimizer(lr)\n",
    "\n",
    "        # Gradient Clipping\n",
    "        gradients = optimizer.compute_gradients(cost)\n",
    "        capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients if grad is not None]\n",
    "        train_op = optimizer.apply_gradients(capped_gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 训练\n",
    "\n",
    "利用预处理的数据训练神经网络。如果很难获得低损失值，请访问我们的论坛，看看其他人是否遇到了相同的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   0 Batch    0/491 - Train Accuracy:  0.234, Validation Accuracy:  0.316, Loss:  5.870\n",
      "Epoch   0 Batch    1/491 - Train Accuracy:  0.264, Validation Accuracy:  0.346, Loss: 10.890\n",
      "Epoch   0 Batch    2/491 - Train Accuracy:  0.201, Validation Accuracy:  0.270, Loss:  5.260\n",
      "Epoch   0 Batch    3/491 - Train Accuracy:  0.143, Validation Accuracy:  0.223, Loss:  6.433\n",
      "Epoch   0 Batch    4/491 - Train Accuracy:  0.151, Validation Accuracy:  0.223, Loss:  5.648\n",
      "Epoch   0 Batch    5/491 - Train Accuracy:  0.161, Validation Accuracy:  0.197, Loss:  5.249\n",
      "Epoch   0 Batch    6/491 - Train Accuracy:  0.281, Validation Accuracy:  0.331, Loss:  5.052\n",
      "Epoch   0 Batch    7/491 - Train Accuracy:  0.261, Validation Accuracy:  0.333, Loss:  4.853\n",
      "Epoch   0 Batch    8/491 - Train Accuracy:  0.281, Validation Accuracy:  0.351, Loss:  4.803\n",
      "Epoch   0 Batch    9/491 - Train Accuracy:  0.284, Validation Accuracy:  0.353, Loss:  4.705\n",
      "Epoch   0 Batch   10/491 - Train Accuracy:  0.268, Validation Accuracy:  0.352, Loss:  4.756\n",
      "Epoch   0 Batch   11/491 - Train Accuracy:  0.279, Validation Accuracy:  0.352, Loss:  4.670\n",
      "Epoch   0 Batch   12/491 - Train Accuracy:  0.276, Validation Accuracy:  0.352, Loss:  4.632\n",
      "Epoch   0 Batch   13/491 - Train Accuracy:  0.322, Validation Accuracy:  0.352, Loss:  4.509\n",
      "Epoch   0 Batch   14/491 - Train Accuracy:  0.276, Validation Accuracy:  0.348, Loss:  4.545\n",
      "Epoch   0 Batch   15/491 - Train Accuracy:  0.323, Validation Accuracy:  0.349, Loss:  4.506\n",
      "Epoch   0 Batch   16/491 - Train Accuracy:  0.311, Validation Accuracy:  0.354, Loss:  4.457\n",
      "Epoch   0 Batch   17/491 - Train Accuracy:  0.308, Validation Accuracy:  0.369, Loss:  4.534\n",
      "Epoch   0 Batch   18/491 - Train Accuracy:  0.300, Validation Accuracy:  0.367, Loss:  4.550\n",
      "Epoch   0 Batch   19/491 - Train Accuracy:  0.312, Validation Accuracy:  0.386, Loss:  4.558\n",
      "Epoch   0 Batch   20/491 - Train Accuracy:  0.315, Validation Accuracy:  0.360, Loss:  4.379\n",
      "Epoch   0 Batch   21/491 - Train Accuracy:  0.259, Validation Accuracy:  0.372, Loss:  4.497\n",
      "Epoch   0 Batch   22/491 - Train Accuracy:  0.321, Validation Accuracy:  0.384, Loss:  4.426\n",
      "Epoch   0 Batch   23/491 - Train Accuracy:  0.331, Validation Accuracy:  0.391, Loss:  4.345\n",
      "Epoch   0 Batch   24/491 - Train Accuracy:  0.345, Validation Accuracy:  0.392, Loss:  4.362\n",
      "Epoch   0 Batch   25/491 - Train Accuracy:  0.332, Validation Accuracy:  0.391, Loss:  4.376\n",
      "Epoch   0 Batch   26/491 - Train Accuracy:  0.334, Validation Accuracy:  0.392, Loss:  4.371\n",
      "Epoch   0 Batch   27/491 - Train Accuracy:  0.333, Validation Accuracy:  0.392, Loss:  4.337\n",
      "Epoch   0 Batch   28/491 - Train Accuracy:  0.409, Validation Accuracy:  0.411, Loss:  4.200\n",
      "Epoch   0 Batch   29/491 - Train Accuracy:  0.361, Validation Accuracy:  0.403, Loss:  4.222\n",
      "Epoch   0 Batch   30/491 - Train Accuracy:  0.339, Validation Accuracy:  0.406, Loss:  4.361\n",
      "Epoch   0 Batch   31/491 - Train Accuracy:  0.373, Validation Accuracy:  0.409, Loss:  4.276\n",
      "Epoch   0 Batch   32/491 - Train Accuracy:  0.355, Validation Accuracy:  0.409, Loss:  4.230\n",
      "Epoch   0 Batch   33/491 - Train Accuracy:  0.382, Validation Accuracy:  0.415, Loss:  4.204\n",
      "Epoch   0 Batch   34/491 - Train Accuracy:  0.357, Validation Accuracy:  0.412, Loss:  4.311\n",
      "Epoch   0 Batch   35/491 - Train Accuracy:  0.351, Validation Accuracy:  0.420, Loss:  4.239\n",
      "Epoch   0 Batch   36/491 - Train Accuracy:  0.382, Validation Accuracy:  0.418, Loss:  4.242\n",
      "Epoch   0 Batch   37/491 - Train Accuracy:  0.358, Validation Accuracy:  0.417, Loss:  4.207\n",
      "Epoch   0 Batch   38/491 - Train Accuracy:  0.365, Validation Accuracy:  0.433, Loss:  4.196\n",
      "Epoch   0 Batch   39/491 - Train Accuracy:  0.383, Validation Accuracy:  0.433, Loss:  4.270\n",
      "Epoch   0 Batch   40/491 - Train Accuracy:  0.447, Validation Accuracy:  0.441, Loss:  4.096\n",
      "Epoch   0 Batch   41/491 - Train Accuracy:  0.366, Validation Accuracy:  0.433, Loss:  4.126\n",
      "Epoch   0 Batch   42/491 - Train Accuracy:  0.372, Validation Accuracy:  0.435, Loss:  4.102\n",
      "Epoch   0 Batch   43/491 - Train Accuracy:  0.389, Validation Accuracy:  0.442, Loss:  4.157\n",
      "Epoch   0 Batch   44/491 - Train Accuracy:  0.391, Validation Accuracy:  0.448, Loss:  4.182\n",
      "Epoch   0 Batch   45/491 - Train Accuracy:  0.421, Validation Accuracy:  0.441, Loss:  4.060\n",
      "Epoch   0 Batch   46/491 - Train Accuracy:  0.384, Validation Accuracy:  0.440, Loss:  4.141\n",
      "Epoch   0 Batch   47/491 - Train Accuracy:  0.428, Validation Accuracy:  0.456, Loss:  4.120\n",
      "Epoch   0 Batch   48/491 - Train Accuracy:  0.424, Validation Accuracy:  0.437, Loss:  4.042\n",
      "Epoch   0 Batch   49/491 - Train Accuracy:  0.387, Validation Accuracy:  0.452, Loss:  4.185\n",
      "Epoch   0 Batch   50/491 - Train Accuracy:  0.405, Validation Accuracy:  0.456, Loss:  4.139\n",
      "Epoch   0 Batch   51/491 - Train Accuracy:  0.339, Validation Accuracy:  0.450, Loss:  4.265\n",
      "Epoch   0 Batch   52/491 - Train Accuracy:  0.418, Validation Accuracy:  0.453, Loss:  4.069\n",
      "Epoch   0 Batch   53/491 - Train Accuracy:  0.451, Validation Accuracy:  0.465, Loss:  3.993\n",
      "Epoch   0 Batch   54/491 - Train Accuracy:  0.401, Validation Accuracy:  0.449, Loss:  4.036\n",
      "Epoch   0 Batch   55/491 - Train Accuracy:  0.391, Validation Accuracy:  0.467, Loss:  4.078\n",
      "Epoch   0 Batch   56/491 - Train Accuracy:  0.438, Validation Accuracy:  0.476, Loss:  3.974\n",
      "Epoch   0 Batch   57/491 - Train Accuracy:  0.399, Validation Accuracy:  0.465, Loss:  4.041\n",
      "Epoch   0 Batch   58/491 - Train Accuracy:  0.398, Validation Accuracy:  0.470, Loss:  4.023\n",
      "Epoch   0 Batch   59/491 - Train Accuracy:  0.420, Validation Accuracy:  0.480, Loss:  4.011\n",
      "Epoch   0 Batch   60/491 - Train Accuracy:  0.406, Validation Accuracy:  0.468, Loss:  4.006\n",
      "Epoch   0 Batch   61/491 - Train Accuracy:  0.392, Validation Accuracy:  0.453, Loss:  3.953\n",
      "Epoch   0 Batch   62/491 - Train Accuracy:  0.453, Validation Accuracy:  0.489, Loss:  3.959\n",
      "Epoch   0 Batch   63/491 - Train Accuracy:  0.427, Validation Accuracy:  0.455, Loss:  3.857\n",
      "Epoch   0 Batch   64/491 - Train Accuracy:  0.455, Validation Accuracy:  0.488, Loss:  3.844\n",
      "Epoch   0 Batch   65/491 - Train Accuracy:  0.405, Validation Accuracy:  0.469, Loss:  3.897\n",
      "Epoch   0 Batch   66/491 - Train Accuracy:  0.449, Validation Accuracy:  0.473, Loss:  3.794\n",
      "Epoch   0 Batch   67/491 - Train Accuracy:  0.431, Validation Accuracy:  0.479, Loss:  3.850\n",
      "Epoch   0 Batch   68/491 - Train Accuracy:  0.405, Validation Accuracy:  0.436, Loss:  3.717\n",
      "Epoch   0 Batch   69/491 - Train Accuracy:  0.379, Validation Accuracy:  0.437, Loss:  3.769\n",
      "Epoch   0 Batch   70/491 - Train Accuracy:  0.448, Validation Accuracy:  0.476, Loss:  3.706\n",
      "Epoch   0 Batch   71/491 - Train Accuracy:  0.384, Validation Accuracy:  0.445, Loss:  3.777\n",
      "Epoch   0 Batch   72/491 - Train Accuracy:  0.433, Validation Accuracy:  0.453, Loss:  3.682\n",
      "Epoch   0 Batch   73/491 - Train Accuracy:  0.390, Validation Accuracy:  0.450, Loss:  3.746\n",
      "Epoch   0 Batch   74/491 - Train Accuracy:  0.409, Validation Accuracy:  0.436, Loss:  3.629\n",
      "Epoch   0 Batch   75/491 - Train Accuracy:  0.421, Validation Accuracy:  0.449, Loss:  3.591\n",
      "Epoch   0 Batch   76/491 - Train Accuracy:  0.375, Validation Accuracy:  0.433, Loss:  3.713\n",
      "Epoch   0 Batch   77/491 - Train Accuracy:  0.360, Validation Accuracy:  0.409, Loss:  3.594\n",
      "Epoch   0 Batch   78/491 - Train Accuracy:  0.387, Validation Accuracy:  0.417, Loss:  3.585\n",
      "Epoch   0 Batch   79/491 - Train Accuracy:  0.402, Validation Accuracy:  0.442, Loss:  3.579\n",
      "Epoch   0 Batch   80/491 - Train Accuracy:  0.361, Validation Accuracy:  0.444, Loss:  3.643\n",
      "Epoch   0 Batch   81/491 - Train Accuracy:  0.347, Validation Accuracy:  0.437, Loss:  3.629\n",
      "Epoch   0 Batch   82/491 - Train Accuracy:  0.410, Validation Accuracy:  0.460, Loss:  3.551\n",
      "Epoch   0 Batch   83/491 - Train Accuracy:  0.389, Validation Accuracy:  0.450, Loss:  3.566\n",
      "Epoch   0 Batch   84/491 - Train Accuracy:  0.399, Validation Accuracy:  0.441, Loss:  3.519\n",
      "Epoch   0 Batch   85/491 - Train Accuracy:  0.407, Validation Accuracy:  0.414, Loss:  3.437\n",
      "Epoch   0 Batch   86/491 - Train Accuracy:  0.332, Validation Accuracy:  0.398, Loss:  3.544\n",
      "Epoch   0 Batch   87/491 - Train Accuracy:  0.383, Validation Accuracy:  0.445, Loss:  3.468\n",
      "Epoch   0 Batch   88/491 - Train Accuracy:  0.423, Validation Accuracy:  0.480, Loss:  3.494\n",
      "Epoch   0 Batch   89/491 - Train Accuracy:  0.430, Validation Accuracy:  0.480, Loss:  3.433\n",
      "Epoch   0 Batch   90/491 - Train Accuracy:  0.437, Validation Accuracy:  0.464, Loss:  3.424\n",
      "Epoch   0 Batch   91/491 - Train Accuracy:  0.458, Validation Accuracy:  0.497, Loss:  3.439\n",
      "Epoch   0 Batch   92/491 - Train Accuracy:  0.415, Validation Accuracy:  0.458, Loss:  3.398\n",
      "Epoch   0 Batch   93/491 - Train Accuracy:  0.403, Validation Accuracy:  0.469, Loss:  3.450\n",
      "Epoch   0 Batch   94/491 - Train Accuracy:  0.361, Validation Accuracy:  0.434, Loss:  3.452\n",
      "Epoch   0 Batch   95/491 - Train Accuracy:  0.461, Validation Accuracy:  0.466, Loss:  3.338\n",
      "Epoch   0 Batch   96/491 - Train Accuracy:  0.463, Validation Accuracy:  0.488, Loss:  3.335\n",
      "Epoch   0 Batch   97/491 - Train Accuracy:  0.435, Validation Accuracy:  0.491, Loss:  3.358\n",
      "Epoch   0 Batch   98/491 - Train Accuracy:  0.483, Validation Accuracy:  0.503, Loss:  3.291\n",
      "Epoch   0 Batch   99/491 - Train Accuracy:  0.384, Validation Accuracy:  0.453, Loss:  3.333\n",
      "Epoch   0 Batch  100/491 - Train Accuracy:  0.450, Validation Accuracy:  0.494, Loss:  3.385\n",
      "Epoch   0 Batch  101/491 - Train Accuracy:  0.447, Validation Accuracy:  0.499, Loss:  3.326\n",
      "Epoch   0 Batch  102/491 - Train Accuracy:  0.459, Validation Accuracy:  0.493, Loss:  3.388\n",
      "Epoch   0 Batch  103/491 - Train Accuracy:  0.470, Validation Accuracy:  0.499, Loss:  3.321\n",
      "Epoch   0 Batch  104/491 - Train Accuracy:  0.472, Validation Accuracy:  0.488, Loss:  3.244\n",
      "Epoch   0 Batch  105/491 - Train Accuracy:  0.461, Validation Accuracy:  0.491, Loss:  3.245\n",
      "Epoch   0 Batch  106/491 - Train Accuracy:  0.442, Validation Accuracy:  0.490, Loss:  3.310\n",
      "Epoch   0 Batch  107/491 - Train Accuracy:  0.436, Validation Accuracy:  0.497, Loss:  3.284\n",
      "Epoch   0 Batch  108/491 - Train Accuracy:  0.492, Validation Accuracy:  0.507, Loss:  3.283\n",
      "Epoch   0 Batch  109/491 - Train Accuracy:  0.478, Validation Accuracy:  0.509, Loss:  3.259\n",
      "Epoch   0 Batch  110/491 - Train Accuracy:  0.457, Validation Accuracy:  0.505, Loss:  3.285\n",
      "Epoch   0 Batch  111/491 - Train Accuracy:  0.486, Validation Accuracy:  0.504, Loss:  3.241\n",
      "Epoch   0 Batch  112/491 - Train Accuracy:  0.457, Validation Accuracy:  0.504, Loss:  3.247\n",
      "Epoch   0 Batch  113/491 - Train Accuracy:  0.460, Validation Accuracy:  0.508, Loss:  3.334\n",
      "Epoch   0 Batch  114/491 - Train Accuracy:  0.513, Validation Accuracy:  0.514, Loss:  3.190\n",
      "Epoch   0 Batch  115/491 - Train Accuracy:  0.479, Validation Accuracy:  0.511, Loss:  3.225\n",
      "Epoch   0 Batch  116/491 - Train Accuracy:  0.475, Validation Accuracy:  0.518, Loss:  3.234\n",
      "Epoch   0 Batch  117/491 - Train Accuracy:  0.484, Validation Accuracy:  0.505, Loss:  3.200\n",
      "Epoch   0 Batch  118/491 - Train Accuracy:  0.496, Validation Accuracy:  0.507, Loss:  3.192\n",
      "Epoch   0 Batch  119/491 - Train Accuracy:  0.495, Validation Accuracy:  0.504, Loss:  3.236\n",
      "Epoch   0 Batch  120/491 - Train Accuracy:  0.466, Validation Accuracy:  0.516, Loss:  3.263\n",
      "Epoch   0 Batch  121/491 - Train Accuracy:  0.507, Validation Accuracy:  0.529, Loss:  3.145\n",
      "Epoch   0 Batch  122/491 - Train Accuracy:  0.485, Validation Accuracy:  0.508, Loss:  3.157\n",
      "Epoch   0 Batch  123/491 - Train Accuracy:  0.518, Validation Accuracy:  0.505, Loss:  3.214\n",
      "Epoch   0 Batch  124/491 - Train Accuracy:  0.487, Validation Accuracy:  0.501, Loss:  3.138\n",
      "Epoch   0 Batch  125/491 - Train Accuracy:  0.536, Validation Accuracy:  0.542, Loss:  3.136\n",
      "Epoch   0 Batch  126/491 - Train Accuracy:  0.543, Validation Accuracy:  0.531, Loss:  3.166\n",
      "Epoch   0 Batch  127/491 - Train Accuracy:  0.475, Validation Accuracy:  0.530, Loss:  3.263\n",
      "Epoch   0 Batch  128/491 - Train Accuracy:  0.511, Validation Accuracy:  0.530, Loss:  3.209\n",
      "Epoch   0 Batch  129/491 - Train Accuracy:  0.505, Validation Accuracy:  0.528, Loss:  3.187\n",
      "Epoch   0 Batch  130/491 - Train Accuracy:  0.490, Validation Accuracy:  0.510, Loss:  3.176\n",
      "Epoch   0 Batch  131/491 - Train Accuracy:  0.485, Validation Accuracy:  0.529, Loss:  3.160\n",
      "Epoch   0 Batch  132/491 - Train Accuracy:  0.499, Validation Accuracy:  0.529, Loss:  3.173\n",
      "Epoch   0 Batch  133/491 - Train Accuracy:  0.519, Validation Accuracy:  0.520, Loss:  3.116\n",
      "Epoch   0 Batch  134/491 - Train Accuracy:  0.487, Validation Accuracy:  0.513, Loss:  3.233\n",
      "Epoch   0 Batch  135/491 - Train Accuracy:  0.519, Validation Accuracy:  0.524, Loss:  3.166\n",
      "Epoch   0 Batch  136/491 - Train Accuracy:  0.519, Validation Accuracy:  0.532, Loss:  3.115\n",
      "Epoch   0 Batch  137/491 - Train Accuracy:  0.513, Validation Accuracy:  0.548, Loss:  3.137\n",
      "Epoch   0 Batch  138/491 - Train Accuracy:  0.524, Validation Accuracy:  0.536, Loss:  3.159\n",
      "Epoch   0 Batch  139/491 - Train Accuracy:  0.505, Validation Accuracy:  0.536, Loss:  3.178\n",
      "Epoch   0 Batch  140/491 - Train Accuracy:  0.487, Validation Accuracy:  0.539, Loss:  3.160\n",
      "Epoch   0 Batch  141/491 - Train Accuracy:  0.502, Validation Accuracy:  0.519, Loss:  3.173\n",
      "Epoch   0 Batch  142/491 - Train Accuracy:  0.548, Validation Accuracy:  0.543, Loss:  3.095\n",
      "Epoch   0 Batch  143/491 - Train Accuracy:  0.496, Validation Accuracy:  0.529, Loss:  3.147\n",
      "Epoch   0 Batch  144/491 - Train Accuracy:  0.517, Validation Accuracy:  0.544, Loss:  3.175\n",
      "Epoch   0 Batch  145/491 - Train Accuracy:  0.525, Validation Accuracy:  0.557, Loss:  3.146\n",
      "Epoch   0 Batch  146/491 - Train Accuracy:  0.538, Validation Accuracy:  0.534, Loss:  3.106\n",
      "Epoch   0 Batch  147/491 - Train Accuracy:  0.520, Validation Accuracy:  0.496, Loss:  3.097\n",
      "Epoch   0 Batch  148/491 - Train Accuracy:  0.484, Validation Accuracy:  0.535, Loss:  3.181\n",
      "Epoch   0 Batch  149/491 - Train Accuracy:  0.500, Validation Accuracy:  0.540, Loss:  3.160\n",
      "Epoch   0 Batch  150/491 - Train Accuracy:  0.552, Validation Accuracy:  0.555, Loss:  3.177\n",
      "Epoch   0 Batch  151/491 - Train Accuracy:  0.538, Validation Accuracy:  0.545, Loss:  3.081\n",
      "Epoch   0 Batch  152/491 - Train Accuracy:  0.540, Validation Accuracy:  0.521, Loss:  3.059\n",
      "Epoch   0 Batch  153/491 - Train Accuracy:  0.511, Validation Accuracy:  0.523, Loss:  3.108\n",
      "Epoch   0 Batch  154/491 - Train Accuracy:  0.510, Validation Accuracy:  0.530, Loss:  3.130\n",
      "Epoch   0 Batch  155/491 - Train Accuracy:  0.540, Validation Accuracy:  0.529, Loss:  3.151\n",
      "Epoch   0 Batch  156/491 - Train Accuracy:  0.510, Validation Accuracy:  0.537, Loss:  3.071\n",
      "Epoch   0 Batch  157/491 - Train Accuracy:  0.549, Validation Accuracy:  0.552, Loss:  3.073\n",
      "Epoch   0 Batch  158/491 - Train Accuracy:  0.559, Validation Accuracy:  0.558, Loss:  3.148\n",
      "Epoch   0 Batch  159/491 - Train Accuracy:  0.565, Validation Accuracy:  0.550, Loss:  3.108\n",
      "Epoch   0 Batch  160/491 - Train Accuracy:  0.541, Validation Accuracy:  0.550, Loss:  3.059\n",
      "Epoch   0 Batch  161/491 - Train Accuracy:  0.537, Validation Accuracy:  0.540, Loss:  3.125\n",
      "Epoch   0 Batch  162/491 - Train Accuracy:  0.562, Validation Accuracy:  0.543, Loss:  3.071\n",
      "Epoch   0 Batch  163/491 - Train Accuracy:  0.532, Validation Accuracy:  0.534, Loss:  3.095\n",
      "Epoch   0 Batch  164/491 - Train Accuracy:  0.535, Validation Accuracy:  0.544, Loss:  3.094\n",
      "Epoch   0 Batch  165/491 - Train Accuracy:  0.547, Validation Accuracy:  0.545, Loss:  3.080\n",
      "Epoch   0 Batch  166/491 - Train Accuracy:  0.563, Validation Accuracy:  0.549, Loss:  3.058\n",
      "Epoch   0 Batch  167/491 - Train Accuracy:  0.587, Validation Accuracy:  0.566, Loss:  3.052\n",
      "Epoch   0 Batch  168/491 - Train Accuracy:  0.512, Validation Accuracy:  0.543, Loss:  3.136\n",
      "Epoch   0 Batch  169/491 - Train Accuracy:  0.539, Validation Accuracy:  0.551, Loss:  3.130\n",
      "Epoch   0 Batch  170/491 - Train Accuracy:  0.535, Validation Accuracy:  0.550, Loss:  3.094\n",
      "Epoch   0 Batch  171/491 - Train Accuracy:  0.536, Validation Accuracy:  0.559, Loss:  3.089\n",
      "Epoch   0 Batch  172/491 - Train Accuracy:  0.565, Validation Accuracy:  0.565, Loss:  3.042\n",
      "Epoch   0 Batch  173/491 - Train Accuracy:  0.565, Validation Accuracy:  0.562, Loss:  3.075\n",
      "Epoch   0 Batch  174/491 - Train Accuracy:  0.528, Validation Accuracy:  0.563, Loss:  3.069\n",
      "Epoch   0 Batch  175/491 - Train Accuracy:  0.538, Validation Accuracy:  0.561, Loss:  3.105\n",
      "Epoch   0 Batch  176/491 - Train Accuracy:  0.558, Validation Accuracy:  0.563, Loss:  3.113\n",
      "Epoch   0 Batch  177/491 - Train Accuracy:  0.550, Validation Accuracy:  0.560, Loss:  3.098\n",
      "Epoch   0 Batch  178/491 - Train Accuracy:  0.545, Validation Accuracy:  0.566, Loss:  3.088\n",
      "Epoch   0 Batch  179/491 - Train Accuracy:  0.544, Validation Accuracy:  0.572, Loss:  3.064\n",
      "Epoch   0 Batch  180/491 - Train Accuracy:  0.589, Validation Accuracy:  0.586, Loss:  3.085\n",
      "Epoch   0 Batch  181/491 - Train Accuracy:  0.533, Validation Accuracy:  0.570, Loss:  3.040\n",
      "Epoch   0 Batch  182/491 - Train Accuracy:  0.524, Validation Accuracy:  0.568, Loss:  3.098\n",
      "Epoch   0 Batch  183/491 - Train Accuracy:  0.576, Validation Accuracy:  0.573, Loss:  3.077\n",
      "Epoch   0 Batch  184/491 - Train Accuracy:  0.582, Validation Accuracy:  0.570, Loss:  3.082\n",
      "Epoch   0 Batch  185/491 - Train Accuracy:  0.555, Validation Accuracy:  0.560, Loss:  3.062\n",
      "Epoch   0 Batch  186/491 - Train Accuracy:  0.563, Validation Accuracy:  0.573, Loss:  3.097\n",
      "Epoch   0 Batch  187/491 - Train Accuracy:  0.590, Validation Accuracy:  0.578, Loss:  3.046\n",
      "Epoch   0 Batch  188/491 - Train Accuracy:  0.546, Validation Accuracy:  0.578, Loss:  3.075\n",
      "Epoch   0 Batch  189/491 - Train Accuracy:  0.547, Validation Accuracy:  0.569, Loss:  3.075\n",
      "Epoch   0 Batch  190/491 - Train Accuracy:  0.560, Validation Accuracy:  0.575, Loss:  3.057\n",
      "Epoch   0 Batch  191/491 - Train Accuracy:  0.563, Validation Accuracy:  0.586, Loss:  3.070\n",
      "Epoch   0 Batch  192/491 - Train Accuracy:  0.582, Validation Accuracy:  0.588, Loss:  3.075\n",
      "Epoch   0 Batch  193/491 - Train Accuracy:  0.588, Validation Accuracy:  0.579, Loss:  3.034\n",
      "Epoch   0 Batch  194/491 - Train Accuracy:  0.555, Validation Accuracy:  0.588, Loss:  3.096\n",
      "Epoch   0 Batch  195/491 - Train Accuracy:  0.590, Validation Accuracy:  0.598, Loss:  3.037\n",
      "Epoch   0 Batch  196/491 - Train Accuracy:  0.587, Validation Accuracy:  0.606, Loss:  3.091\n",
      "Epoch   0 Batch  197/491 - Train Accuracy:  0.607, Validation Accuracy:  0.601, Loss:  3.070\n",
      "Epoch   0 Batch  198/491 - Train Accuracy:  0.610, Validation Accuracy:  0.600, Loss:  3.061\n",
      "Epoch   0 Batch  199/491 - Train Accuracy:  0.564, Validation Accuracy:  0.592, Loss:  3.066\n",
      "Epoch   0 Batch  200/491 - Train Accuracy:  0.584, Validation Accuracy:  0.566, Loss:  3.029\n",
      "Epoch   0 Batch  201/491 - Train Accuracy:  0.575, Validation Accuracy:  0.575, Loss:  2.957\n",
      "Epoch   0 Batch  202/491 - Train Accuracy:  0.535, Validation Accuracy:  0.569, Loss:  3.079\n",
      "Epoch   0 Batch  203/491 - Train Accuracy:  0.556, Validation Accuracy:  0.579, Loss:  3.090\n",
      "Epoch   0 Batch  204/491 - Train Accuracy:  0.554, Validation Accuracy:  0.576, Loss:  3.099\n",
      "Epoch   0 Batch  205/491 - Train Accuracy:  0.594, Validation Accuracy:  0.577, Loss:  2.973\n",
      "Epoch   0 Batch  206/491 - Train Accuracy:  0.542, Validation Accuracy:  0.574, Loss:  3.105\n",
      "Epoch   0 Batch  207/491 - Train Accuracy:  0.572, Validation Accuracy:  0.594, Loss:  3.034\n",
      "Epoch   0 Batch  208/491 - Train Accuracy:  0.573, Validation Accuracy:  0.581, Loss:  3.022\n",
      "Epoch   0 Batch  209/491 - Train Accuracy:  0.570, Validation Accuracy:  0.568, Loss:  3.102\n",
      "Epoch   0 Batch  210/491 - Train Accuracy:  0.567, Validation Accuracy:  0.577, Loss:  2.989\n",
      "Epoch   0 Batch  211/491 - Train Accuracy:  0.567, Validation Accuracy:  0.578, Loss:  3.056\n",
      "Epoch   0 Batch  212/491 - Train Accuracy:  0.561, Validation Accuracy:  0.581, Loss:  2.971\n",
      "Epoch   0 Batch  213/491 - Train Accuracy:  0.561, Validation Accuracy:  0.587, Loss:  3.021\n",
      "Epoch   0 Batch  214/491 - Train Accuracy:  0.584, Validation Accuracy:  0.595, Loss:  3.031\n",
      "Epoch   0 Batch  215/491 - Train Accuracy:  0.584, Validation Accuracy:  0.601, Loss:  3.033\n",
      "Epoch   0 Batch  216/491 - Train Accuracy:  0.570, Validation Accuracy:  0.590, Loss:  3.110\n",
      "Epoch   0 Batch  217/491 - Train Accuracy:  0.597, Validation Accuracy:  0.581, Loss:  3.057\n",
      "Epoch   0 Batch  218/491 - Train Accuracy:  0.558, Validation Accuracy:  0.603, Loss:  2.941\n",
      "Epoch   0 Batch  219/491 - Train Accuracy:  0.571, Validation Accuracy:  0.611, Loss:  3.031\n",
      "Epoch   0 Batch  220/491 - Train Accuracy:  0.577, Validation Accuracy:  0.589, Loss:  2.933\n",
      "Epoch   0 Batch  221/491 - Train Accuracy:  0.611, Validation Accuracy:  0.600, Loss:  2.973\n",
      "Epoch   0 Batch  222/491 - Train Accuracy:  0.601, Validation Accuracy:  0.599, Loss:  2.945\n",
      "Epoch   0 Batch  223/491 - Train Accuracy:  0.574, Validation Accuracy:  0.578, Loss:  3.033\n",
      "Epoch   0 Batch  224/491 - Train Accuracy:  0.577, Validation Accuracy:  0.593, Loss:  3.023\n",
      "Epoch   0 Batch  225/491 - Train Accuracy:  0.615, Validation Accuracy:  0.593, Loss:  2.975\n",
      "Epoch   0 Batch  226/491 - Train Accuracy:  0.599, Validation Accuracy:  0.593, Loss:  2.979\n",
      "Epoch   0 Batch  227/491 - Train Accuracy:  0.587, Validation Accuracy:  0.602, Loss:  2.953\n",
      "Epoch   0 Batch  228/491 - Train Accuracy:  0.601, Validation Accuracy:  0.603, Loss:  3.126\n",
      "Epoch   0 Batch  229/491 - Train Accuracy:  0.598, Validation Accuracy:  0.608, Loss:  3.073\n",
      "Epoch   0 Batch  230/491 - Train Accuracy:  0.589, Validation Accuracy:  0.611, Loss:  3.019\n",
      "Epoch   0 Batch  231/491 - Train Accuracy:  0.600, Validation Accuracy:  0.623, Loss:  2.995\n",
      "Epoch   0 Batch  232/491 - Train Accuracy:  0.569, Validation Accuracy:  0.624, Loss:  3.031\n",
      "Epoch   0 Batch  233/491 - Train Accuracy:  0.630, Validation Accuracy:  0.614, Loss:  2.973\n",
      "Epoch   0 Batch  234/491 - Train Accuracy:  0.563, Validation Accuracy:  0.608, Loss:  3.043\n",
      "Epoch   0 Batch  235/491 - Train Accuracy:  0.603, Validation Accuracy:  0.600, Loss:  2.941\n",
      "Epoch   0 Batch  236/491 - Train Accuracy:  0.580, Validation Accuracy:  0.595, Loss:  2.980\n",
      "Epoch   0 Batch  237/491 - Train Accuracy:  0.570, Validation Accuracy:  0.589, Loss:  2.987\n",
      "Epoch   0 Batch  238/491 - Train Accuracy:  0.607, Validation Accuracy:  0.591, Loss:  2.995\n",
      "Epoch   0 Batch  239/491 - Train Accuracy:  0.601, Validation Accuracy:  0.588, Loss:  2.980\n",
      "Epoch   0 Batch  240/491 - Train Accuracy:  0.582, Validation Accuracy:  0.602, Loss:  3.020\n",
      "Epoch   0 Batch  241/491 - Train Accuracy:  0.564, Validation Accuracy:  0.610, Loss:  3.004\n",
      "Epoch   0 Batch  242/491 - Train Accuracy:  0.610, Validation Accuracy:  0.615, Loss:  3.031\n",
      "Epoch   0 Batch  243/491 - Train Accuracy:  0.579, Validation Accuracy:  0.618, Loss:  3.007\n",
      "Epoch   0 Batch  244/491 - Train Accuracy:  0.604, Validation Accuracy:  0.614, Loss:  2.975\n",
      "Epoch   0 Batch  245/491 - Train Accuracy:  0.588, Validation Accuracy:  0.608, Loss:  2.974\n",
      "Epoch   0 Batch  246/491 - Train Accuracy:  0.606, Validation Accuracy:  0.618, Loss:  2.936\n",
      "Epoch   0 Batch  247/491 - Train Accuracy:  0.595, Validation Accuracy:  0.611, Loss:  3.072\n",
      "Epoch   0 Batch  248/491 - Train Accuracy:  0.610, Validation Accuracy:  0.604, Loss:  2.992\n",
      "Epoch   0 Batch  249/491 - Train Accuracy:  0.590, Validation Accuracy:  0.604, Loss:  2.951\n",
      "Epoch   0 Batch  250/491 - Train Accuracy:  0.592, Validation Accuracy:  0.613, Loss:  3.025\n",
      "Epoch   0 Batch  251/491 - Train Accuracy:  0.596, Validation Accuracy:  0.615, Loss:  3.028\n",
      "Epoch   0 Batch  252/491 - Train Accuracy:  0.617, Validation Accuracy:  0.619, Loss:  2.976\n",
      "Epoch   0 Batch  253/491 - Train Accuracy:  0.606, Validation Accuracy:  0.632, Loss:  2.937\n",
      "Epoch   0 Batch  254/491 - Train Accuracy:  0.610, Validation Accuracy:  0.634, Loss:  3.046\n",
      "Epoch   0 Batch  255/491 - Train Accuracy:  0.629, Validation Accuracy:  0.628, Loss:  2.963\n",
      "Epoch   0 Batch  256/491 - Train Accuracy:  0.593, Validation Accuracy:  0.620, Loss:  3.030\n",
      "Epoch   0 Batch  257/491 - Train Accuracy:  0.632, Validation Accuracy:  0.602, Loss:  2.963\n",
      "Epoch   0 Batch  258/491 - Train Accuracy:  0.633, Validation Accuracy:  0.607, Loss:  3.021\n",
      "Epoch   0 Batch  259/491 - Train Accuracy:  0.614, Validation Accuracy:  0.597, Loss:  2.951\n",
      "Epoch   0 Batch  260/491 - Train Accuracy:  0.600, Validation Accuracy:  0.593, Loss:  2.978\n",
      "Epoch   0 Batch  261/491 - Train Accuracy:  0.593, Validation Accuracy:  0.603, Loss:  3.058\n",
      "Epoch   0 Batch  262/491 - Train Accuracy:  0.590, Validation Accuracy:  0.608, Loss:  2.987\n",
      "Epoch   0 Batch  263/491 - Train Accuracy:  0.588, Validation Accuracy:  0.606, Loss:  3.004\n",
      "Epoch   0 Batch  264/491 - Train Accuracy:  0.588, Validation Accuracy:  0.611, Loss:  2.959\n",
      "Epoch   0 Batch  265/491 - Train Accuracy:  0.588, Validation Accuracy:  0.625, Loss:  3.005\n",
      "Epoch   0 Batch  266/491 - Train Accuracy:  0.629, Validation Accuracy:  0.621, Loss:  2.977\n",
      "Epoch   0 Batch  267/491 - Train Accuracy:  0.647, Validation Accuracy:  0.624, Loss:  2.973\n",
      "Epoch   0 Batch  268/491 - Train Accuracy:  0.633, Validation Accuracy:  0.618, Loss:  3.000\n",
      "Epoch   0 Batch  269/491 - Train Accuracy:  0.613, Validation Accuracy:  0.615, Loss:  2.919\n",
      "Epoch   0 Batch  270/491 - Train Accuracy:  0.605, Validation Accuracy:  0.634, Loss:  2.884\n",
      "Epoch   0 Batch  271/491 - Train Accuracy:  0.597, Validation Accuracy:  0.629, Loss:  2.973\n",
      "Epoch   0 Batch  272/491 - Train Accuracy:  0.587, Validation Accuracy:  0.617, Loss:  3.063\n",
      "Epoch   0 Batch  273/491 - Train Accuracy:  0.596, Validation Accuracy:  0.620, Loss:  3.046\n",
      "Epoch   0 Batch  274/491 - Train Accuracy:  0.566, Validation Accuracy:  0.630, Loss:  2.997\n",
      "Epoch   0 Batch  275/491 - Train Accuracy:  0.602, Validation Accuracy:  0.639, Loss:  3.046\n",
      "Epoch   0 Batch  276/491 - Train Accuracy:  0.620, Validation Accuracy:  0.633, Loss:  2.944\n",
      "Epoch   0 Batch  277/491 - Train Accuracy:  0.611, Validation Accuracy:  0.638, Loss:  2.933\n",
      "Epoch   0 Batch  278/491 - Train Accuracy:  0.626, Validation Accuracy:  0.636, Loss:  3.007\n",
      "Epoch   0 Batch  279/491 - Train Accuracy:  0.619, Validation Accuracy:  0.617, Loss:  2.957\n",
      "Epoch   0 Batch  280/491 - Train Accuracy:  0.651, Validation Accuracy:  0.604, Loss:  2.983\n",
      "Epoch   0 Batch  281/491 - Train Accuracy:  0.607, Validation Accuracy:  0.607, Loss:  2.926\n",
      "Epoch   0 Batch  282/491 - Train Accuracy:  0.614, Validation Accuracy:  0.634, Loss:  3.024\n",
      "Epoch   0 Batch  283/491 - Train Accuracy:  0.637, Validation Accuracy:  0.638, Loss:  3.044\n",
      "Epoch   0 Batch  284/491 - Train Accuracy:  0.638, Validation Accuracy:  0.645, Loss:  3.002\n",
      "Epoch   0 Batch  285/491 - Train Accuracy:  0.628, Validation Accuracy:  0.641, Loss:  2.922\n",
      "Epoch   0 Batch  286/491 - Train Accuracy:  0.641, Validation Accuracy:  0.632, Loss:  3.007\n",
      "Epoch   0 Batch  287/491 - Train Accuracy:  0.627, Validation Accuracy:  0.625, Loss:  2.974\n",
      "Epoch   0 Batch  288/491 - Train Accuracy:  0.590, Validation Accuracy:  0.637, Loss:  3.004\n",
      "Epoch   0 Batch  289/491 - Train Accuracy:  0.657, Validation Accuracy:  0.634, Loss:  2.931\n",
      "Epoch   0 Batch  290/491 - Train Accuracy:  0.633, Validation Accuracy:  0.652, Loss:  2.912\n",
      "Epoch   0 Batch  291/491 - Train Accuracy:  0.639, Validation Accuracy:  0.637, Loss:  2.911\n",
      "Epoch   0 Batch  292/491 - Train Accuracy:  0.647, Validation Accuracy:  0.631, Loss:  2.937\n",
      "Epoch   0 Batch  293/491 - Train Accuracy:  0.634, Validation Accuracy:  0.615, Loss:  2.910\n",
      "Epoch   0 Batch  294/491 - Train Accuracy:  0.586, Validation Accuracy:  0.626, Loss:  2.950\n",
      "Epoch   0 Batch  295/491 - Train Accuracy:  0.667, Validation Accuracy:  0.631, Loss:  2.910\n",
      "Epoch   0 Batch  296/491 - Train Accuracy:  0.637, Validation Accuracy:  0.621, Loss:  2.909\n",
      "Epoch   0 Batch  297/491 - Train Accuracy:  0.592, Validation Accuracy:  0.616, Loss:  2.972\n",
      "Epoch   0 Batch  298/491 - Train Accuracy:  0.626, Validation Accuracy:  0.637, Loss:  2.990\n",
      "Epoch   0 Batch  299/491 - Train Accuracy:  0.647, Validation Accuracy:  0.645, Loss:  2.898\n",
      "Epoch   0 Batch  300/491 - Train Accuracy:  0.622, Validation Accuracy:  0.637, Loss:  2.973\n",
      "Epoch   0 Batch  301/491 - Train Accuracy:  0.636, Validation Accuracy:  0.642, Loss:  2.977\n",
      "Epoch   0 Batch  302/491 - Train Accuracy:  0.650, Validation Accuracy:  0.640, Loss:  2.962\n",
      "Epoch   0 Batch  303/491 - Train Accuracy:  0.672, Validation Accuracy:  0.642, Loss:  2.928\n",
      "Epoch   0 Batch  304/491 - Train Accuracy:  0.638, Validation Accuracy:  0.646, Loss:  2.986\n",
      "Epoch   0 Batch  305/491 - Train Accuracy:  0.656, Validation Accuracy:  0.637, Loss:  2.902\n",
      "Epoch   0 Batch  306/491 - Train Accuracy:  0.636, Validation Accuracy:  0.632, Loss:  2.916\n",
      "Epoch   0 Batch  307/491 - Train Accuracy:  0.620, Validation Accuracy:  0.627, Loss:  2.967\n",
      "Epoch   0 Batch  308/491 - Train Accuracy:  0.654, Validation Accuracy:  0.631, Loss:  2.980\n",
      "Epoch   0 Batch  309/491 - Train Accuracy:  0.631, Validation Accuracy:  0.638, Loss:  2.948\n",
      "Epoch   0 Batch  310/491 - Train Accuracy:  0.655, Validation Accuracy:  0.650, Loss:  2.983\n",
      "Epoch   0 Batch  311/491 - Train Accuracy:  0.645, Validation Accuracy:  0.648, Loss:  2.890\n",
      "Epoch   0 Batch  312/491 - Train Accuracy:  0.657, Validation Accuracy:  0.648, Loss:  2.894\n",
      "Epoch   0 Batch  313/491 - Train Accuracy:  0.636, Validation Accuracy:  0.649, Loss:  2.983\n",
      "Epoch   0 Batch  314/491 - Train Accuracy:  0.623, Validation Accuracy:  0.650, Loss:  2.954\n",
      "Epoch   0 Batch  315/491 - Train Accuracy:  0.642, Validation Accuracy:  0.652, Loss:  2.919\n",
      "Epoch   0 Batch  316/491 - Train Accuracy:  0.626, Validation Accuracy:  0.650, Loss:  2.883\n",
      "Epoch   0 Batch  317/491 - Train Accuracy:  0.660, Validation Accuracy:  0.652, Loss:  2.966\n",
      "Epoch   0 Batch  318/491 - Train Accuracy:  0.663, Validation Accuracy:  0.668, Loss:  2.938\n",
      "Epoch   0 Batch  319/491 - Train Accuracy:  0.667, Validation Accuracy:  0.661, Loss:  2.922\n",
      "Epoch   0 Batch  320/491 - Train Accuracy:  0.644, Validation Accuracy:  0.637, Loss:  2.930\n",
      "Epoch   0 Batch  321/491 - Train Accuracy:  0.641, Validation Accuracy:  0.635, Loss:  2.914\n",
      "Epoch   0 Batch  322/491 - Train Accuracy:  0.651, Validation Accuracy:  0.643, Loss:  2.948\n",
      "Epoch   0 Batch  323/491 - Train Accuracy:  0.641, Validation Accuracy:  0.650, Loss:  2.990\n",
      "Epoch   0 Batch  324/491 - Train Accuracy:  0.630, Validation Accuracy:  0.659, Loss:  2.973\n",
      "Epoch   0 Batch  325/491 - Train Accuracy:  0.657, Validation Accuracy:  0.657, Loss:  2.906\n",
      "Epoch   0 Batch  326/491 - Train Accuracy:  0.646, Validation Accuracy:  0.640, Loss:  2.954\n",
      "Epoch   0 Batch  327/491 - Train Accuracy:  0.612, Validation Accuracy:  0.629, Loss:  2.936\n",
      "Epoch   0 Batch  328/491 - Train Accuracy:  0.663, Validation Accuracy:  0.643, Loss:  2.924\n",
      "Epoch   0 Batch  329/491 - Train Accuracy:  0.685, Validation Accuracy:  0.650, Loss:  2.902\n",
      "Epoch   0 Batch  330/491 - Train Accuracy:  0.655, Validation Accuracy:  0.653, Loss:  2.906\n",
      "Epoch   0 Batch  331/491 - Train Accuracy:  0.660, Validation Accuracy:  0.635, Loss:  2.946\n",
      "Epoch   0 Batch  332/491 - Train Accuracy:  0.630, Validation Accuracy:  0.645, Loss:  2.929\n",
      "Epoch   0 Batch  333/491 - Train Accuracy:  0.657, Validation Accuracy:  0.645, Loss:  2.907\n",
      "Epoch   0 Batch  334/491 - Train Accuracy:  0.692, Validation Accuracy:  0.643, Loss:  2.871\n",
      "Epoch   0 Batch  335/491 - Train Accuracy:  0.667, Validation Accuracy:  0.637, Loss:  2.943\n",
      "Epoch   0 Batch  336/491 - Train Accuracy:  0.667, Validation Accuracy:  0.641, Loss:  2.968\n",
      "Epoch   0 Batch  337/491 - Train Accuracy:  0.660, Validation Accuracy:  0.637, Loss:  2.937\n",
      "Epoch   0 Batch  338/491 - Train Accuracy:  0.647, Validation Accuracy:  0.658, Loss:  2.954\n",
      "Epoch   0 Batch  339/491 - Train Accuracy:  0.664, Validation Accuracy:  0.659, Loss:  2.932\n",
      "Epoch   0 Batch  340/491 - Train Accuracy:  0.646, Validation Accuracy:  0.657, Loss:  2.935\n",
      "Epoch   0 Batch  341/491 - Train Accuracy:  0.662, Validation Accuracy:  0.645, Loss:  2.923\n",
      "Epoch   0 Batch  342/491 - Train Accuracy:  0.666, Validation Accuracy:  0.642, Loss:  2.948\n",
      "Epoch   0 Batch  343/491 - Train Accuracy:  0.672, Validation Accuracy:  0.647, Loss:  2.931\n",
      "Epoch   0 Batch  344/491 - Train Accuracy:  0.662, Validation Accuracy:  0.651, Loss:  2.876\n",
      "Epoch   0 Batch  345/491 - Train Accuracy:  0.669, Validation Accuracy:  0.672, Loss:  2.934\n",
      "Epoch   0 Batch  346/491 - Train Accuracy:  0.645, Validation Accuracy:  0.668, Loss:  2.878\n",
      "Epoch   0 Batch  347/491 - Train Accuracy:  0.661, Validation Accuracy:  0.664, Loss:  2.912\n",
      "Epoch   0 Batch  348/491 - Train Accuracy:  0.666, Validation Accuracy:  0.669, Loss:  2.944\n",
      "Epoch   0 Batch  349/491 - Train Accuracy:  0.646, Validation Accuracy:  0.664, Loss:  2.863\n",
      "Epoch   0 Batch  350/491 - Train Accuracy:  0.669, Validation Accuracy:  0.656, Loss:  2.938\n",
      "Epoch   0 Batch  351/491 - Train Accuracy:  0.644, Validation Accuracy:  0.650, Loss:  2.873\n",
      "Epoch   0 Batch  352/491 - Train Accuracy:  0.676, Validation Accuracy:  0.665, Loss:  2.889\n",
      "Epoch   0 Batch  353/491 - Train Accuracy:  0.672, Validation Accuracy:  0.658, Loss:  2.932\n",
      "Epoch   0 Batch  354/491 - Train Accuracy:  0.627, Validation Accuracy:  0.643, Loss:  2.903\n",
      "Epoch   0 Batch  355/491 - Train Accuracy:  0.655, Validation Accuracy:  0.658, Loss:  2.859\n",
      "Epoch   0 Batch  356/491 - Train Accuracy:  0.683, Validation Accuracy:  0.673, Loss:  2.857\n",
      "Epoch   0 Batch  357/491 - Train Accuracy:  0.697, Validation Accuracy:  0.688, Loss:  2.931\n",
      "Epoch   0 Batch  358/491 - Train Accuracy:  0.669, Validation Accuracy:  0.679, Loss:  2.929\n",
      "Epoch   0 Batch  359/491 - Train Accuracy:  0.691, Validation Accuracy:  0.668, Loss:  2.862\n",
      "Epoch   0 Batch  360/491 - Train Accuracy:  0.649, Validation Accuracy:  0.666, Loss:  2.922\n",
      "Epoch   0 Batch  361/491 - Train Accuracy:  0.696, Validation Accuracy:  0.661, Loss:  2.891\n",
      "Epoch   0 Batch  362/491 - Train Accuracy:  0.687, Validation Accuracy:  0.665, Loss:  2.883\n",
      "Epoch   0 Batch  363/491 - Train Accuracy:  0.679, Validation Accuracy:  0.674, Loss:  2.925\n",
      "Epoch   0 Batch  364/491 - Train Accuracy:  0.633, Validation Accuracy:  0.658, Loss:  2.922\n",
      "Epoch   0 Batch  365/491 - Train Accuracy:  0.654, Validation Accuracy:  0.652, Loss:  2.852\n",
      "Epoch   0 Batch  366/491 - Train Accuracy:  0.668, Validation Accuracy:  0.654, Loss:  2.941\n",
      "Epoch   0 Batch  367/491 - Train Accuracy:  0.703, Validation Accuracy:  0.669, Loss:  2.889\n",
      "Epoch   0 Batch  368/491 - Train Accuracy:  0.741, Validation Accuracy:  0.686, Loss:  2.824\n",
      "Epoch   0 Batch  369/491 - Train Accuracy:  0.686, Validation Accuracy:  0.686, Loss:  2.919\n",
      "Epoch   0 Batch  370/491 - Train Accuracy:  0.646, Validation Accuracy:  0.676, Loss:  2.939\n",
      "Epoch   0 Batch  371/491 - Train Accuracy:  0.703, Validation Accuracy:  0.679, Loss:  3.017\n",
      "Epoch   0 Batch  372/491 - Train Accuracy:  0.700, Validation Accuracy:  0.677, Loss:  2.902\n",
      "Epoch   0 Batch  373/491 - Train Accuracy:  0.691, Validation Accuracy:  0.692, Loss:  2.867\n",
      "Epoch   0 Batch  374/491 - Train Accuracy:  0.661, Validation Accuracy:  0.682, Loss:  2.947\n",
      "Epoch   0 Batch  375/491 - Train Accuracy:  0.691, Validation Accuracy:  0.664, Loss:  2.919\n",
      "Epoch   0 Batch  376/491 - Train Accuracy:  0.664, Validation Accuracy:  0.664, Loss:  2.979\n",
      "Epoch   0 Batch  377/491 - Train Accuracy:  0.693, Validation Accuracy:  0.679, Loss:  2.880\n",
      "Epoch   0 Batch  378/491 - Train Accuracy:  0.717, Validation Accuracy:  0.695, Loss:  2.839\n",
      "Epoch   0 Batch  379/491 - Train Accuracy:  0.696, Validation Accuracy:  0.690, Loss:  2.960\n",
      "Epoch   0 Batch  380/491 - Train Accuracy:  0.680, Validation Accuracy:  0.681, Loss:  2.942\n",
      "Epoch   0 Batch  381/491 - Train Accuracy:  0.706, Validation Accuracy:  0.689, Loss:  2.845\n",
      "Epoch   0 Batch  382/491 - Train Accuracy:  0.673, Validation Accuracy:  0.696, Loss:  2.856\n",
      "Epoch   0 Batch  383/491 - Train Accuracy:  0.691, Validation Accuracy:  0.694, Loss:  2.876\n",
      "Epoch   0 Batch  384/491 - Train Accuracy:  0.718, Validation Accuracy:  0.698, Loss:  2.923\n",
      "Epoch   0 Batch  385/491 - Train Accuracy:  0.726, Validation Accuracy:  0.688, Loss:  2.887\n",
      "Epoch   0 Batch  386/491 - Train Accuracy:  0.696, Validation Accuracy:  0.684, Loss:  2.936\n",
      "Epoch   0 Batch  387/491 - Train Accuracy:  0.709, Validation Accuracy:  0.693, Loss:  2.892\n",
      "Epoch   0 Batch  388/491 - Train Accuracy:  0.690, Validation Accuracy:  0.691, Loss:  2.868\n",
      "Epoch   0 Batch  389/491 - Train Accuracy:  0.669, Validation Accuracy:  0.694, Loss:  2.970\n",
      "Epoch   0 Batch  390/491 - Train Accuracy:  0.715, Validation Accuracy:  0.712, Loss:  2.837\n",
      "Epoch   0 Batch  391/491 - Train Accuracy:  0.707, Validation Accuracy:  0.696, Loss:  2.879\n",
      "Epoch   0 Batch  392/491 - Train Accuracy:  0.680, Validation Accuracy:  0.698, Loss:  2.868\n",
      "Epoch   0 Batch  393/491 - Train Accuracy:  0.723, Validation Accuracy:  0.683, Loss:  2.866\n",
      "Epoch   0 Batch  394/491 - Train Accuracy:  0.615, Validation Accuracy:  0.683, Loss:  2.869\n",
      "Epoch   0 Batch  395/491 - Train Accuracy:  0.701, Validation Accuracy:  0.700, Loss:  2.922\n",
      "Epoch   0 Batch  396/491 - Train Accuracy:  0.684, Validation Accuracy:  0.702, Loss:  2.887\n",
      "Epoch   0 Batch  397/491 - Train Accuracy:  0.702, Validation Accuracy:  0.694, Loss:  2.913\n",
      "Epoch   0 Batch  398/491 - Train Accuracy:  0.701, Validation Accuracy:  0.671, Loss:  2.902\n",
      "Epoch   0 Batch  399/491 - Train Accuracy:  0.694, Validation Accuracy:  0.670, Loss:  2.950\n",
      "Epoch   0 Batch  400/491 - Train Accuracy:  0.692, Validation Accuracy:  0.690, Loss:  2.874\n",
      "Epoch   0 Batch  401/491 - Train Accuracy:  0.689, Validation Accuracy:  0.683, Loss:  2.834\n",
      "Epoch   0 Batch  402/491 - Train Accuracy:  0.704, Validation Accuracy:  0.697, Loss:  2.948\n",
      "Epoch   0 Batch  403/491 - Train Accuracy:  0.700, Validation Accuracy:  0.698, Loss:  2.870\n",
      "Epoch   0 Batch  404/491 - Train Accuracy:  0.714, Validation Accuracy:  0.705, Loss:  2.909\n",
      "Epoch   0 Batch  405/491 - Train Accuracy:  0.719, Validation Accuracy:  0.694, Loss:  2.837\n",
      "Epoch   0 Batch  406/491 - Train Accuracy:  0.705, Validation Accuracy:  0.691, Loss:  2.897\n",
      "Epoch   0 Batch  407/491 - Train Accuracy:  0.704, Validation Accuracy:  0.690, Loss:  2.788\n",
      "Epoch   0 Batch  408/491 - Train Accuracy:  0.681, Validation Accuracy:  0.686, Loss:  2.892\n",
      "Epoch   0 Batch  409/491 - Train Accuracy:  0.668, Validation Accuracy:  0.689, Loss:  2.869\n",
      "Epoch   0 Batch  410/491 - Train Accuracy:  0.701, Validation Accuracy:  0.701, Loss:  2.839\n",
      "Epoch   0 Batch  411/491 - Train Accuracy:  0.695, Validation Accuracy:  0.689, Loss:  2.859\n",
      "Epoch   0 Batch  412/491 - Train Accuracy:  0.712, Validation Accuracy:  0.682, Loss:  2.858\n",
      "Epoch   0 Batch  413/491 - Train Accuracy:  0.712, Validation Accuracy:  0.678, Loss:  2.874\n",
      "Epoch   0 Batch  414/491 - Train Accuracy:  0.669, Validation Accuracy:  0.667, Loss:  2.851\n",
      "Epoch   0 Batch  415/491 - Train Accuracy:  0.664, Validation Accuracy:  0.670, Loss:  2.892\n",
      "Epoch   0 Batch  416/491 - Train Accuracy:  0.736, Validation Accuracy:  0.679, Loss:  2.854\n",
      "Epoch   0 Batch  417/491 - Train Accuracy:  0.723, Validation Accuracy:  0.705, Loss:  2.912\n",
      "Epoch   0 Batch  418/491 - Train Accuracy:  0.707, Validation Accuracy:  0.699, Loss:  2.913\n",
      "Epoch   0 Batch  419/491 - Train Accuracy:  0.719, Validation Accuracy:  0.686, Loss:  2.856\n",
      "Epoch   0 Batch  420/491 - Train Accuracy:  0.713, Validation Accuracy:  0.710, Loss:  2.910\n",
      "Epoch   0 Batch  421/491 - Train Accuracy:  0.714, Validation Accuracy:  0.715, Loss:  2.895\n",
      "Epoch   0 Batch  422/491 - Train Accuracy:  0.681, Validation Accuracy:  0.702, Loss:  2.900\n",
      "Epoch   0 Batch  423/491 - Train Accuracy:  0.696, Validation Accuracy:  0.708, Loss:  2.917\n",
      "Epoch   0 Batch  424/491 - Train Accuracy:  0.679, Validation Accuracy:  0.717, Loss:  2.865\n",
      "Epoch   0 Batch  425/491 - Train Accuracy:  0.723, Validation Accuracy:  0.715, Loss:  2.862\n",
      "Epoch   0 Batch  426/491 - Train Accuracy:  0.714, Validation Accuracy:  0.700, Loss:  2.850\n",
      "Epoch   0 Batch  427/491 - Train Accuracy:  0.707, Validation Accuracy:  0.693, Loss:  2.897\n",
      "Epoch   0 Batch  428/491 - Train Accuracy:  0.705, Validation Accuracy:  0.698, Loss:  2.813\n",
      "Epoch   0 Batch  429/491 - Train Accuracy:  0.705, Validation Accuracy:  0.696, Loss:  2.893\n",
      "Epoch   0 Batch  430/491 - Train Accuracy:  0.726, Validation Accuracy:  0.708, Loss:  2.866\n",
      "Epoch   0 Batch  431/491 - Train Accuracy:  0.715, Validation Accuracy:  0.710, Loss:  2.818\n",
      "Epoch   0 Batch  432/491 - Train Accuracy:  0.748, Validation Accuracy:  0.713, Loss:  2.828\n",
      "Epoch   0 Batch  433/491 - Train Accuracy:  0.688, Validation Accuracy:  0.721, Loss:  2.908\n",
      "Epoch   0 Batch  434/491 - Train Accuracy:  0.678, Validation Accuracy:  0.718, Loss:  2.875\n",
      "Epoch   0 Batch  435/491 - Train Accuracy:  0.721, Validation Accuracy:  0.719, Loss:  2.778\n",
      "Epoch   0 Batch  436/491 - Train Accuracy:  0.679, Validation Accuracy:  0.704, Loss:  2.848\n",
      "Epoch   0 Batch  437/491 - Train Accuracy:  0.694, Validation Accuracy:  0.705, Loss:  2.897\n",
      "Epoch   0 Batch  438/491 - Train Accuracy:  0.732, Validation Accuracy:  0.716, Loss:  2.861\n",
      "Epoch   0 Batch  439/491 - Train Accuracy:  0.743, Validation Accuracy:  0.714, Loss:  2.882\n",
      "Epoch   0 Batch  440/491 - Train Accuracy:  0.733, Validation Accuracy:  0.718, Loss:  2.868\n",
      "Epoch   0 Batch  441/491 - Train Accuracy:  0.688, Validation Accuracy:  0.718, Loss:  2.864\n",
      "Epoch   0 Batch  442/491 - Train Accuracy:  0.732, Validation Accuracy:  0.736, Loss:  2.819\n",
      "Epoch   0 Batch  443/491 - Train Accuracy:  0.738, Validation Accuracy:  0.727, Loss:  2.869\n",
      "Epoch   0 Batch  444/491 - Train Accuracy:  0.785, Validation Accuracy:  0.730, Loss:  2.793\n",
      "Epoch   0 Batch  445/491 - Train Accuracy:  0.768, Validation Accuracy:  0.739, Loss:  2.808\n",
      "Epoch   0 Batch  446/491 - Train Accuracy:  0.761, Validation Accuracy:  0.739, Loss:  2.888\n",
      "Epoch   0 Batch  447/491 - Train Accuracy:  0.737, Validation Accuracy:  0.742, Loss:  2.877\n",
      "Epoch   0 Batch  448/491 - Train Accuracy:  0.740, Validation Accuracy:  0.727, Loss:  2.859\n",
      "Epoch   0 Batch  449/491 - Train Accuracy:  0.751, Validation Accuracy:  0.728, Loss:  2.885\n",
      "Epoch   0 Batch  450/491 - Train Accuracy:  0.743, Validation Accuracy:  0.737, Loss:  2.844\n",
      "Epoch   0 Batch  451/491 - Train Accuracy:  0.727, Validation Accuracy:  0.728, Loss:  2.892\n",
      "Epoch   0 Batch  452/491 - Train Accuracy:  0.745, Validation Accuracy:  0.722, Loss:  2.868\n",
      "Epoch   0 Batch  453/491 - Train Accuracy:  0.727, Validation Accuracy:  0.720, Loss:  2.908\n",
      "Epoch   0 Batch  454/491 - Train Accuracy:  0.740, Validation Accuracy:  0.717, Loss:  2.867\n",
      "Epoch   0 Batch  455/491 - Train Accuracy:  0.730, Validation Accuracy:  0.727, Loss:  2.872\n",
      "Epoch   0 Batch  456/491 - Train Accuracy:  0.764, Validation Accuracy:  0.744, Loss:  2.828\n",
      "Epoch   0 Batch  457/491 - Train Accuracy:  0.712, Validation Accuracy:  0.735, Loss:  2.919\n",
      "Epoch   0 Batch  458/491 - Train Accuracy:  0.743, Validation Accuracy:  0.730, Loss:  2.919\n",
      "Epoch   0 Batch  459/491 - Train Accuracy:  0.747, Validation Accuracy:  0.729, Loss:  2.858\n",
      "Epoch   0 Batch  460/491 - Train Accuracy:  0.729, Validation Accuracy:  0.728, Loss:  2.753\n",
      "Epoch   0 Batch  461/491 - Train Accuracy:  0.708, Validation Accuracy:  0.727, Loss:  2.883\n",
      "Epoch   0 Batch  462/491 - Train Accuracy:  0.733, Validation Accuracy:  0.751, Loss:  2.814\n",
      "Epoch   0 Batch  463/491 - Train Accuracy:  0.714, Validation Accuracy:  0.735, Loss:  2.819\n",
      "Epoch   0 Batch  464/491 - Train Accuracy:  0.733, Validation Accuracy:  0.737, Loss:  2.889\n",
      "Epoch   0 Batch  465/491 - Train Accuracy:  0.722, Validation Accuracy:  0.716, Loss:  2.926\n",
      "Epoch   0 Batch  466/491 - Train Accuracy:  0.730, Validation Accuracy:  0.719, Loss:  2.897\n",
      "Epoch   0 Batch  467/491 - Train Accuracy:  0.738, Validation Accuracy:  0.724, Loss:  2.855\n",
      "Epoch   0 Batch  468/491 - Train Accuracy:  0.744, Validation Accuracy:  0.722, Loss:  2.864\n",
      "Epoch   0 Batch  469/491 - Train Accuracy:  0.724, Validation Accuracy:  0.721, Loss:  2.801\n",
      "Epoch   0 Batch  470/491 - Train Accuracy:  0.733, Validation Accuracy:  0.719, Loss:  2.874\n",
      "Epoch   0 Batch  471/491 - Train Accuracy:  0.742, Validation Accuracy:  0.730, Loss:  2.831\n",
      "Epoch   0 Batch  472/491 - Train Accuracy:  0.778, Validation Accuracy:  0.741, Loss:  2.832\n",
      "Epoch   0 Batch  473/491 - Train Accuracy:  0.737, Validation Accuracy:  0.745, Loss:  2.796\n",
      "Epoch   0 Batch  474/491 - Train Accuracy:  0.758, Validation Accuracy:  0.749, Loss:  2.878\n",
      "Epoch   0 Batch  475/491 - Train Accuracy:  0.757, Validation Accuracy:  0.737, Loss:  2.832\n",
      "Epoch   0 Batch  476/491 - Train Accuracy:  0.747, Validation Accuracy:  0.750, Loss:  2.911\n",
      "Epoch   0 Batch  477/491 - Train Accuracy:  0.775, Validation Accuracy:  0.737, Loss:  2.836\n",
      "Epoch   0 Batch  478/491 - Train Accuracy:  0.757, Validation Accuracy:  0.738, Loss:  2.811\n",
      "Epoch   0 Batch  479/491 - Train Accuracy:  0.745, Validation Accuracy:  0.747, Loss:  2.870\n",
      "Epoch   0 Batch  480/491 - Train Accuracy:  0.745, Validation Accuracy:  0.741, Loss:  2.865\n",
      "Epoch   0 Batch  481/491 - Train Accuracy:  0.763, Validation Accuracy:  0.730, Loss:  2.854\n",
      "Epoch   0 Batch  482/491 - Train Accuracy:  0.762, Validation Accuracy:  0.743, Loss:  2.846\n",
      "Epoch   0 Batch  483/491 - Train Accuracy:  0.731, Validation Accuracy:  0.751, Loss:  2.806\n",
      "Epoch   0 Batch  484/491 - Train Accuracy:  0.769, Validation Accuracy:  0.747, Loss:  2.822\n",
      "Epoch   0 Batch  485/491 - Train Accuracy:  0.734, Validation Accuracy:  0.748, Loss:  2.794\n",
      "Epoch   0 Batch  486/491 - Train Accuracy:  0.766, Validation Accuracy:  0.740, Loss:  2.832\n",
      "Epoch   0 Batch  487/491 - Train Accuracy:  0.764, Validation Accuracy:  0.745, Loss:  2.836\n",
      "Epoch   0 Batch  488/491 - Train Accuracy:  0.765, Validation Accuracy:  0.753, Loss:  2.836\n",
      "Epoch   0 Batch  489/491 - Train Accuracy:  0.737, Validation Accuracy:  0.760, Loss:  2.849\n",
      "Epoch   1 Batch    0/491 - Train Accuracy:  0.750, Validation Accuracy:  0.753, Loss:  2.800\n",
      "Epoch   1 Batch    1/491 - Train Accuracy:  0.765, Validation Accuracy:  0.744, Loss:  2.858\n",
      "Epoch   1 Batch    2/491 - Train Accuracy:  0.738, Validation Accuracy:  0.738, Loss:  2.892\n",
      "Epoch   1 Batch    3/491 - Train Accuracy:  0.733, Validation Accuracy:  0.734, Loss:  2.792\n",
      "Epoch   1 Batch    4/491 - Train Accuracy:  0.773, Validation Accuracy:  0.741, Loss:  2.861\n",
      "Epoch   1 Batch    5/491 - Train Accuracy:  0.714, Validation Accuracy:  0.754, Loss:  2.815\n",
      "Epoch   1 Batch    6/491 - Train Accuracy:  0.763, Validation Accuracy:  0.747, Loss:  2.773\n",
      "Epoch   1 Batch    7/491 - Train Accuracy:  0.771, Validation Accuracy:  0.755, Loss:  2.810\n",
      "Epoch   1 Batch    8/491 - Train Accuracy:  0.767, Validation Accuracy:  0.743, Loss:  2.798\n",
      "Epoch   1 Batch    9/491 - Train Accuracy:  0.744, Validation Accuracy:  0.743, Loss:  2.805\n",
      "Epoch   1 Batch   10/491 - Train Accuracy:  0.766, Validation Accuracy:  0.738, Loss:  2.856\n",
      "Epoch   1 Batch   11/491 - Train Accuracy:  0.775, Validation Accuracy:  0.744, Loss:  2.817\n",
      "Epoch   1 Batch   12/491 - Train Accuracy:  0.743, Validation Accuracy:  0.734, Loss:  2.862\n",
      "Epoch   1 Batch   13/491 - Train Accuracy:  0.777, Validation Accuracy:  0.739, Loss:  2.846\n",
      "Epoch   1 Batch   14/491 - Train Accuracy:  0.758, Validation Accuracy:  0.751, Loss:  2.776\n",
      "Epoch   1 Batch   15/491 - Train Accuracy:  0.771, Validation Accuracy:  0.753, Loss:  2.815\n",
      "Epoch   1 Batch   16/491 - Train Accuracy:  0.778, Validation Accuracy:  0.752, Loss:  2.793\n",
      "Epoch   1 Batch   17/491 - Train Accuracy:  0.739, Validation Accuracy:  0.755, Loss:  2.870\n",
      "Epoch   1 Batch   18/491 - Train Accuracy:  0.735, Validation Accuracy:  0.759, Loss:  2.812\n",
      "Epoch   1 Batch   19/491 - Train Accuracy:  0.775, Validation Accuracy:  0.758, Loss:  2.855\n",
      "Epoch   1 Batch   20/491 - Train Accuracy:  0.791, Validation Accuracy:  0.757, Loss:  2.795\n",
      "Epoch   1 Batch   21/491 - Train Accuracy:  0.774, Validation Accuracy:  0.755, Loss:  2.773\n",
      "Epoch   1 Batch   22/491 - Train Accuracy:  0.758, Validation Accuracy:  0.771, Loss:  2.740\n",
      "Epoch   1 Batch   23/491 - Train Accuracy:  0.767, Validation Accuracy:  0.770, Loss:  2.842\n",
      "Epoch   1 Batch   24/491 - Train Accuracy:  0.783, Validation Accuracy:  0.782, Loss:  2.803\n",
      "Epoch   1 Batch   25/491 - Train Accuracy:  0.784, Validation Accuracy:  0.775, Loss:  2.809\n",
      "Epoch   1 Batch   26/491 - Train Accuracy:  0.750, Validation Accuracy:  0.774, Loss:  2.892\n",
      "Epoch   1 Batch   27/491 - Train Accuracy:  0.780, Validation Accuracy:  0.782, Loss:  2.763\n",
      "Epoch   1 Batch   28/491 - Train Accuracy:  0.759, Validation Accuracy:  0.772, Loss:  2.820\n",
      "Epoch   1 Batch   29/491 - Train Accuracy:  0.768, Validation Accuracy:  0.779, Loss:  2.820\n",
      "Epoch   1 Batch   30/491 - Train Accuracy:  0.769, Validation Accuracy:  0.768, Loss:  2.845\n",
      "Epoch   1 Batch   31/491 - Train Accuracy:  0.789, Validation Accuracy:  0.759, Loss:  2.751\n",
      "Epoch   1 Batch   32/491 - Train Accuracy:  0.769, Validation Accuracy:  0.761, Loss:  2.779\n",
      "Epoch   1 Batch   33/491 - Train Accuracy:  0.791, Validation Accuracy:  0.757, Loss:  2.775\n",
      "Epoch   1 Batch   34/491 - Train Accuracy:  0.785, Validation Accuracy:  0.758, Loss:  2.821\n",
      "Epoch   1 Batch   35/491 - Train Accuracy:  0.796, Validation Accuracy:  0.763, Loss:  2.825\n",
      "Epoch   1 Batch   36/491 - Train Accuracy:  0.771, Validation Accuracy:  0.765, Loss:  2.776\n",
      "Epoch   1 Batch   37/491 - Train Accuracy:  0.780, Validation Accuracy:  0.770, Loss:  2.817\n",
      "Epoch   1 Batch   38/491 - Train Accuracy:  0.762, Validation Accuracy:  0.765, Loss:  2.764\n",
      "Epoch   1 Batch   39/491 - Train Accuracy:  0.766, Validation Accuracy:  0.756, Loss:  2.768\n",
      "Epoch   1 Batch   40/491 - Train Accuracy:  0.802, Validation Accuracy:  0.763, Loss:  2.798\n",
      "Epoch   1 Batch   41/491 - Train Accuracy:  0.771, Validation Accuracy:  0.770, Loss:  2.795\n",
      "Epoch   1 Batch   42/491 - Train Accuracy:  0.784, Validation Accuracy:  0.767, Loss:  2.803\n",
      "Epoch   1 Batch   43/491 - Train Accuracy:  0.764, Validation Accuracy:  0.766, Loss:  2.807\n",
      "Epoch   1 Batch   44/491 - Train Accuracy:  0.756, Validation Accuracy:  0.781, Loss:  2.767\n",
      "Epoch   1 Batch   45/491 - Train Accuracy:  0.799, Validation Accuracy:  0.791, Loss:  2.743\n",
      "Epoch   1 Batch   46/491 - Train Accuracy:  0.779, Validation Accuracy:  0.783, Loss:  2.806\n",
      "Epoch   1 Batch   47/491 - Train Accuracy:  0.790, Validation Accuracy:  0.789, Loss:  2.784\n",
      "Epoch   1 Batch   48/491 - Train Accuracy:  0.794, Validation Accuracy:  0.788, Loss:  2.775\n",
      "Epoch   1 Batch   49/491 - Train Accuracy:  0.783, Validation Accuracy:  0.783, Loss:  2.803\n",
      "Epoch   1 Batch   50/491 - Train Accuracy:  0.798, Validation Accuracy:  0.782, Loss:  2.801\n",
      "Epoch   1 Batch   51/491 - Train Accuracy:  0.767, Validation Accuracy:  0.775, Loss:  2.864\n",
      "Epoch   1 Batch   52/491 - Train Accuracy:  0.795, Validation Accuracy:  0.762, Loss:  2.801\n",
      "Epoch   1 Batch   53/491 - Train Accuracy:  0.787, Validation Accuracy:  0.766, Loss:  2.788\n",
      "Epoch   1 Batch   54/491 - Train Accuracy:  0.802, Validation Accuracy:  0.784, Loss:  2.717\n",
      "Epoch   1 Batch   55/491 - Train Accuracy:  0.803, Validation Accuracy:  0.810, Loss:  2.841\n",
      "Epoch   1 Batch   56/491 - Train Accuracy:  0.793, Validation Accuracy:  0.801, Loss:  2.718\n",
      "Epoch   1 Batch   57/491 - Train Accuracy:  0.766, Validation Accuracy:  0.806, Loss:  2.802\n",
      "Epoch   1 Batch   58/491 - Train Accuracy:  0.788, Validation Accuracy:  0.795, Loss:  2.772\n",
      "Epoch   1 Batch   59/491 - Train Accuracy:  0.799, Validation Accuracy:  0.784, Loss:  2.766\n",
      "Epoch   1 Batch   60/491 - Train Accuracy:  0.810, Validation Accuracy:  0.794, Loss:  2.772\n",
      "Epoch   1 Batch   61/491 - Train Accuracy:  0.811, Validation Accuracy:  0.787, Loss:  2.756\n",
      "Epoch   1 Batch   62/491 - Train Accuracy:  0.783, Validation Accuracy:  0.783, Loss:  2.825\n",
      "Epoch   1 Batch   63/491 - Train Accuracy:  0.810, Validation Accuracy:  0.789, Loss:  2.825\n",
      "Epoch   1 Batch   64/491 - Train Accuracy:  0.813, Validation Accuracy:  0.784, Loss:  2.840\n",
      "Epoch   1 Batch   65/491 - Train Accuracy:  0.773, Validation Accuracy:  0.775, Loss:  2.807\n",
      "Epoch   1 Batch   66/491 - Train Accuracy:  0.811, Validation Accuracy:  0.778, Loss:  2.797\n",
      "Epoch   1 Batch   67/491 - Train Accuracy:  0.813, Validation Accuracy:  0.786, Loss:  2.794\n",
      "Epoch   1 Batch   68/491 - Train Accuracy:  0.809, Validation Accuracy:  0.790, Loss:  2.709\n",
      "Epoch   1 Batch   69/491 - Train Accuracy:  0.802, Validation Accuracy:  0.787, Loss:  2.771\n",
      "Epoch   1 Batch   70/491 - Train Accuracy:  0.797, Validation Accuracy:  0.785, Loss:  2.828\n",
      "Epoch   1 Batch   71/491 - Train Accuracy:  0.802, Validation Accuracy:  0.779, Loss:  2.827\n",
      "Epoch   1 Batch   72/491 - Train Accuracy:  0.818, Validation Accuracy:  0.799, Loss:  2.736\n",
      "Epoch   1 Batch   73/491 - Train Accuracy:  0.783, Validation Accuracy:  0.805, Loss:  2.820\n",
      "Epoch   1 Batch   74/491 - Train Accuracy:  0.792, Validation Accuracy:  0.799, Loss:  2.849\n",
      "Epoch   1 Batch   75/491 - Train Accuracy:  0.812, Validation Accuracy:  0.786, Loss:  2.768\n",
      "Epoch   1 Batch   76/491 - Train Accuracy:  0.782, Validation Accuracy:  0.802, Loss:  2.779\n",
      "Epoch   1 Batch   77/491 - Train Accuracy:  0.800, Validation Accuracy:  0.782, Loss:  2.774\n",
      "Epoch   1 Batch   78/491 - Train Accuracy:  0.799, Validation Accuracy:  0.778, Loss:  2.778\n",
      "Epoch   1 Batch   79/491 - Train Accuracy:  0.817, Validation Accuracy:  0.797, Loss:  2.748\n",
      "Epoch   1 Batch   80/491 - Train Accuracy:  0.773, Validation Accuracy:  0.794, Loss:  2.763\n",
      "Epoch   1 Batch   81/491 - Train Accuracy:  0.802, Validation Accuracy:  0.792, Loss:  2.772\n",
      "Epoch   1 Batch   82/491 - Train Accuracy:  0.786, Validation Accuracy:  0.781, Loss:  2.808\n",
      "Epoch   1 Batch   83/491 - Train Accuracy:  0.785, Validation Accuracy:  0.777, Loss:  2.747\n",
      "Epoch   1 Batch   84/491 - Train Accuracy:  0.787, Validation Accuracy:  0.786, Loss:  2.770\n",
      "Epoch   1 Batch   85/491 - Train Accuracy:  0.824, Validation Accuracy:  0.798, Loss:  2.743\n",
      "Epoch   1 Batch   86/491 - Train Accuracy:  0.808, Validation Accuracy:  0.799, Loss:  2.746\n",
      "Epoch   1 Batch   87/491 - Train Accuracy:  0.787, Validation Accuracy:  0.789, Loss:  2.762\n",
      "Epoch   1 Batch   88/491 - Train Accuracy:  0.813, Validation Accuracy:  0.784, Loss:  2.785\n",
      "Epoch   1 Batch   89/491 - Train Accuracy:  0.791, Validation Accuracy:  0.798, Loss:  2.761\n",
      "Epoch   1 Batch   90/491 - Train Accuracy:  0.762, Validation Accuracy:  0.789, Loss:  2.788\n",
      "Epoch   1 Batch   91/491 - Train Accuracy:  0.789, Validation Accuracy:  0.780, Loss:  2.752\n",
      "Epoch   1 Batch   92/491 - Train Accuracy:  0.796, Validation Accuracy:  0.783, Loss:  2.786\n",
      "Epoch   1 Batch   93/491 - Train Accuracy:  0.796, Validation Accuracy:  0.789, Loss:  2.756\n",
      "Epoch   1 Batch   94/491 - Train Accuracy:  0.803, Validation Accuracy:  0.788, Loss:  2.814\n",
      "Epoch   1 Batch   95/491 - Train Accuracy:  0.818, Validation Accuracy:  0.791, Loss:  2.705\n",
      "Epoch   1 Batch   96/491 - Train Accuracy:  0.828, Validation Accuracy:  0.795, Loss:  2.700\n",
      "Epoch   1 Batch   97/491 - Train Accuracy:  0.814, Validation Accuracy:  0.798, Loss:  2.745\n",
      "Epoch   1 Batch   98/491 - Train Accuracy:  0.824, Validation Accuracy:  0.796, Loss:  2.764\n",
      "Epoch   1 Batch   99/491 - Train Accuracy:  0.800, Validation Accuracy:  0.804, Loss:  2.679\n",
      "Epoch   1 Batch  100/491 - Train Accuracy:  0.815, Validation Accuracy:  0.803, Loss:  2.740\n",
      "Epoch   1 Batch  101/491 - Train Accuracy:  0.801, Validation Accuracy:  0.804, Loss:  2.804\n",
      "Epoch   1 Batch  102/491 - Train Accuracy:  0.822, Validation Accuracy:  0.811, Loss:  2.765\n",
      "Epoch   1 Batch  103/491 - Train Accuracy:  0.817, Validation Accuracy:  0.809, Loss:  2.785\n",
      "Epoch   1 Batch  104/491 - Train Accuracy:  0.811, Validation Accuracy:  0.814, Loss:  2.685\n",
      "Epoch   1 Batch  105/491 - Train Accuracy:  0.820, Validation Accuracy:  0.815, Loss:  2.703\n",
      "Epoch   1 Batch  106/491 - Train Accuracy:  0.799, Validation Accuracy:  0.821, Loss:  2.766\n",
      "Epoch   1 Batch  107/491 - Train Accuracy:  0.798, Validation Accuracy:  0.830, Loss:  2.779\n",
      "Epoch   1 Batch  108/491 - Train Accuracy:  0.821, Validation Accuracy:  0.836, Loss:  2.768\n",
      "Epoch   1 Batch  109/491 - Train Accuracy:  0.846, Validation Accuracy:  0.835, Loss:  2.736\n",
      "Epoch   1 Batch  110/491 - Train Accuracy:  0.793, Validation Accuracy:  0.826, Loss:  2.762\n",
      "Epoch   1 Batch  111/491 - Train Accuracy:  0.845, Validation Accuracy:  0.816, Loss:  2.743\n",
      "Epoch   1 Batch  112/491 - Train Accuracy:  0.844, Validation Accuracy:  0.813, Loss:  2.741\n",
      "Epoch   1 Batch  113/491 - Train Accuracy:  0.781, Validation Accuracy:  0.810, Loss:  2.769\n",
      "Epoch   1 Batch  114/491 - Train Accuracy:  0.812, Validation Accuracy:  0.803, Loss:  2.751\n",
      "Epoch   1 Batch  115/491 - Train Accuracy:  0.825, Validation Accuracy:  0.818, Loss:  2.762\n",
      "Epoch   1 Batch  116/491 - Train Accuracy:  0.808, Validation Accuracy:  0.820, Loss:  2.789\n",
      "Epoch   1 Batch  117/491 - Train Accuracy:  0.809, Validation Accuracy:  0.811, Loss:  2.708\n",
      "Epoch   1 Batch  118/491 - Train Accuracy:  0.822, Validation Accuracy:  0.812, Loss:  2.757\n",
      "Epoch   1 Batch  119/491 - Train Accuracy:  0.845, Validation Accuracy:  0.827, Loss:  2.703\n",
      "Epoch   1 Batch  120/491 - Train Accuracy:  0.835, Validation Accuracy:  0.825, Loss:  2.767\n",
      "Epoch   1 Batch  121/491 - Train Accuracy:  0.807, Validation Accuracy:  0.821, Loss:  2.783\n",
      "Epoch   1 Batch  122/491 - Train Accuracy:  0.794, Validation Accuracy:  0.826, Loss:  2.758\n",
      "Epoch   1 Batch  123/491 - Train Accuracy:  0.828, Validation Accuracy:  0.816, Loss:  2.813\n",
      "Epoch   1 Batch  124/491 - Train Accuracy:  0.818, Validation Accuracy:  0.808, Loss:  2.766\n",
      "Epoch   1 Batch  125/491 - Train Accuracy:  0.825, Validation Accuracy:  0.826, Loss:  2.757\n",
      "Epoch   1 Batch  126/491 - Train Accuracy:  0.822, Validation Accuracy:  0.818, Loss:  2.742\n",
      "Epoch   1 Batch  127/491 - Train Accuracy:  0.813, Validation Accuracy:  0.812, Loss:  2.677\n",
      "Epoch   1 Batch  128/491 - Train Accuracy:  0.817, Validation Accuracy:  0.811, Loss:  2.772\n",
      "Epoch   1 Batch  129/491 - Train Accuracy:  0.823, Validation Accuracy:  0.805, Loss:  2.699\n",
      "Epoch   1 Batch  130/491 - Train Accuracy:  0.830, Validation Accuracy:  0.819, Loss:  2.817\n",
      "Epoch   1 Batch  131/491 - Train Accuracy:  0.841, Validation Accuracy:  0.823, Loss:  2.749\n",
      "Epoch   1 Batch  132/491 - Train Accuracy:  0.812, Validation Accuracy:  0.824, Loss:  2.734\n",
      "Epoch   1 Batch  133/491 - Train Accuracy:  0.802, Validation Accuracy:  0.833, Loss:  2.808\n",
      "Epoch   1 Batch  134/491 - Train Accuracy:  0.807, Validation Accuracy:  0.808, Loss:  2.781\n",
      "Epoch   1 Batch  135/491 - Train Accuracy:  0.834, Validation Accuracy:  0.806, Loss:  2.745\n",
      "Epoch   1 Batch  136/491 - Train Accuracy:  0.805, Validation Accuracy:  0.808, Loss:  2.729\n",
      "Epoch   1 Batch  137/491 - Train Accuracy:  0.817, Validation Accuracy:  0.831, Loss:  2.747\n",
      "Epoch   1 Batch  138/491 - Train Accuracy:  0.807, Validation Accuracy:  0.825, Loss:  2.714\n",
      "Epoch   1 Batch  139/491 - Train Accuracy:  0.796, Validation Accuracy:  0.823, Loss:  2.800\n",
      "Epoch   1 Batch  140/491 - Train Accuracy:  0.826, Validation Accuracy:  0.827, Loss:  2.760\n",
      "Epoch   1 Batch  141/491 - Train Accuracy:  0.838, Validation Accuracy:  0.808, Loss:  2.783\n",
      "Epoch   1 Batch  142/491 - Train Accuracy:  0.853, Validation Accuracy:  0.809, Loss:  2.720\n",
      "Epoch   1 Batch  143/491 - Train Accuracy:  0.815, Validation Accuracy:  0.812, Loss:  2.780\n",
      "Epoch   1 Batch  144/491 - Train Accuracy:  0.840, Validation Accuracy:  0.828, Loss:  2.765\n",
      "Epoch   1 Batch  145/491 - Train Accuracy:  0.809, Validation Accuracy:  0.833, Loss:  2.775\n",
      "Epoch   1 Batch  146/491 - Train Accuracy:  0.819, Validation Accuracy:  0.829, Loss:  2.795\n",
      "Epoch   1 Batch  147/491 - Train Accuracy:  0.846, Validation Accuracy:  0.817, Loss:  2.772\n",
      "Epoch   1 Batch  148/491 - Train Accuracy:  0.823, Validation Accuracy:  0.809, Loss:  2.654\n",
      "Epoch   1 Batch  149/491 - Train Accuracy:  0.844, Validation Accuracy:  0.804, Loss:  2.779\n",
      "Epoch   1 Batch  150/491 - Train Accuracy:  0.841, Validation Accuracy:  0.823, Loss:  2.766\n",
      "Epoch   1 Batch  151/491 - Train Accuracy:  0.852, Validation Accuracy:  0.805, Loss:  2.741\n",
      "Epoch   1 Batch  152/491 - Train Accuracy:  0.838, Validation Accuracy:  0.804, Loss:  2.702\n",
      "Epoch   1 Batch  153/491 - Train Accuracy:  0.810, Validation Accuracy:  0.807, Loss:  2.723\n",
      "Epoch   1 Batch  154/491 - Train Accuracy:  0.836, Validation Accuracy:  0.817, Loss:  2.733\n",
      "Epoch   1 Batch  155/491 - Train Accuracy:  0.822, Validation Accuracy:  0.834, Loss:  2.705\n",
      "Epoch   1 Batch  156/491 - Train Accuracy:  0.834, Validation Accuracy:  0.835, Loss:  2.676\n",
      "Epoch   1 Batch  157/491 - Train Accuracy:  0.855, Validation Accuracy:  0.840, Loss:  2.786\n",
      "Epoch   1 Batch  158/491 - Train Accuracy:  0.827, Validation Accuracy:  0.850, Loss:  2.725\n",
      "Epoch   1 Batch  159/491 - Train Accuracy:  0.825, Validation Accuracy:  0.843, Loss:  2.734\n",
      "Epoch   1 Batch  160/491 - Train Accuracy:  0.806, Validation Accuracy:  0.826, Loss:  2.737\n",
      "Epoch   1 Batch  161/491 - Train Accuracy:  0.851, Validation Accuracy:  0.819, Loss:  2.721\n",
      "Epoch   1 Batch  162/491 - Train Accuracy:  0.843, Validation Accuracy:  0.807, Loss:  2.742\n",
      "Epoch   1 Batch  163/491 - Train Accuracy:  0.829, Validation Accuracy:  0.810, Loss:  2.747\n",
      "Epoch   1 Batch  164/491 - Train Accuracy:  0.800, Validation Accuracy:  0.814, Loss:  2.777\n",
      "Epoch   1 Batch  165/491 - Train Accuracy:  0.837, Validation Accuracy:  0.822, Loss:  2.691\n",
      "Epoch   1 Batch  166/491 - Train Accuracy:  0.860, Validation Accuracy:  0.819, Loss:  2.704\n",
      "Epoch   1 Batch  167/491 - Train Accuracy:  0.828, Validation Accuracy:  0.818, Loss:  2.734\n",
      "Epoch   1 Batch  168/491 - Train Accuracy:  0.795, Validation Accuracy:  0.829, Loss:  2.737\n",
      "Epoch   1 Batch  169/491 - Train Accuracy:  0.841, Validation Accuracy:  0.825, Loss:  2.695\n",
      "Epoch   1 Batch  170/491 - Train Accuracy:  0.837, Validation Accuracy:  0.821, Loss:  2.798\n",
      "Epoch   1 Batch  171/491 - Train Accuracy:  0.837, Validation Accuracy:  0.838, Loss:  2.695\n",
      "Epoch   1 Batch  172/491 - Train Accuracy:  0.831, Validation Accuracy:  0.835, Loss:  2.762\n",
      "Epoch   1 Batch  173/491 - Train Accuracy:  0.840, Validation Accuracy:  0.820, Loss:  2.785\n",
      "Epoch   1 Batch  174/491 - Train Accuracy:  0.830, Validation Accuracy:  0.824, Loss:  2.706\n",
      "Epoch   1 Batch  175/491 - Train Accuracy:  0.831, Validation Accuracy:  0.824, Loss:  2.714\n",
      "Epoch   1 Batch  176/491 - Train Accuracy:  0.830, Validation Accuracy:  0.832, Loss:  2.749\n",
      "Epoch   1 Batch  177/491 - Train Accuracy:  0.842, Validation Accuracy:  0.835, Loss:  2.708\n",
      "Epoch   1 Batch  178/491 - Train Accuracy:  0.808, Validation Accuracy:  0.829, Loss:  2.742\n",
      "Epoch   1 Batch  179/491 - Train Accuracy:  0.828, Validation Accuracy:  0.832, Loss:  2.642\n",
      "Epoch   1 Batch  180/491 - Train Accuracy:  0.843, Validation Accuracy:  0.844, Loss:  2.736\n",
      "Epoch   1 Batch  181/491 - Train Accuracy:  0.831, Validation Accuracy:  0.831, Loss:  2.668\n",
      "Epoch   1 Batch  182/491 - Train Accuracy:  0.845, Validation Accuracy:  0.838, Loss:  2.663\n",
      "Epoch   1 Batch  183/491 - Train Accuracy:  0.871, Validation Accuracy:  0.849, Loss:  2.745\n",
      "Epoch   1 Batch  184/491 - Train Accuracy:  0.860, Validation Accuracy:  0.839, Loss:  2.689\n",
      "Epoch   1 Batch  185/491 - Train Accuracy:  0.862, Validation Accuracy:  0.835, Loss:  2.754\n",
      "Epoch   1 Batch  186/491 - Train Accuracy:  0.863, Validation Accuracy:  0.836, Loss:  2.736\n",
      "Epoch   1 Batch  187/491 - Train Accuracy:  0.846, Validation Accuracy:  0.830, Loss:  2.724\n",
      "Epoch   1 Batch  188/491 - Train Accuracy:  0.841, Validation Accuracy:  0.841, Loss:  2.727\n",
      "Epoch   1 Batch  189/491 - Train Accuracy:  0.853, Validation Accuracy:  0.848, Loss:  2.758\n",
      "Epoch   1 Batch  190/491 - Train Accuracy:  0.817, Validation Accuracy:  0.845, Loss:  2.682\n",
      "Epoch   1 Batch  191/491 - Train Accuracy:  0.839, Validation Accuracy:  0.845, Loss:  2.787\n",
      "Epoch   1 Batch  192/491 - Train Accuracy:  0.857, Validation Accuracy:  0.849, Loss:  2.764\n",
      "Epoch   1 Batch  193/491 - Train Accuracy:  0.860, Validation Accuracy:  0.844, Loss:  2.679\n",
      "Epoch   1 Batch  194/491 - Train Accuracy:  0.813, Validation Accuracy:  0.862, Loss:  2.726\n",
      "Epoch   1 Batch  195/491 - Train Accuracy:  0.826, Validation Accuracy:  0.861, Loss:  2.765\n",
      "Epoch   1 Batch  196/491 - Train Accuracy:  0.849, Validation Accuracy:  0.854, Loss:  2.728\n",
      "Epoch   1 Batch  197/491 - Train Accuracy:  0.839, Validation Accuracy:  0.858, Loss:  2.715\n",
      "Epoch   1 Batch  198/491 - Train Accuracy:  0.867, Validation Accuracy:  0.849, Loss:  2.642\n",
      "Epoch   1 Batch  199/491 - Train Accuracy:  0.829, Validation Accuracy:  0.852, Loss:  2.666\n",
      "Epoch   1 Batch  200/491 - Train Accuracy:  0.830, Validation Accuracy:  0.840, Loss:  2.763\n",
      "Epoch   1 Batch  201/491 - Train Accuracy:  0.843, Validation Accuracy:  0.828, Loss:  2.686\n",
      "Epoch   1 Batch  202/491 - Train Accuracy:  0.857, Validation Accuracy:  0.843, Loss:  2.746\n",
      "Epoch   1 Batch  203/491 - Train Accuracy:  0.835, Validation Accuracy:  0.848, Loss:  2.689\n",
      "Epoch   1 Batch  204/491 - Train Accuracy:  0.853, Validation Accuracy:  0.835, Loss:  2.712\n",
      "Epoch   1 Batch  205/491 - Train Accuracy:  0.849, Validation Accuracy:  0.839, Loss:  2.766\n",
      "Epoch   1 Batch  206/491 - Train Accuracy:  0.829, Validation Accuracy:  0.847, Loss:  2.721\n",
      "Epoch   1 Batch  207/491 - Train Accuracy:  0.841, Validation Accuracy:  0.823, Loss:  2.726\n",
      "Epoch   1 Batch  208/491 - Train Accuracy:  0.829, Validation Accuracy:  0.818, Loss:  2.758\n",
      "Epoch   1 Batch  209/491 - Train Accuracy:  0.864, Validation Accuracy:  0.819, Loss:  2.750\n",
      "Epoch   1 Batch  210/491 - Train Accuracy:  0.826, Validation Accuracy:  0.859, Loss:  2.694\n",
      "Epoch   1 Batch  211/491 - Train Accuracy:  0.834, Validation Accuracy:  0.857, Loss:  2.715\n",
      "Epoch   1 Batch  212/491 - Train Accuracy:  0.850, Validation Accuracy:  0.849, Loss:  2.737\n",
      "Epoch   1 Batch  213/491 - Train Accuracy:  0.852, Validation Accuracy:  0.847, Loss:  2.676\n",
      "Epoch   1 Batch  214/491 - Train Accuracy:  0.858, Validation Accuracy:  0.855, Loss:  2.769\n",
      "Epoch   1 Batch  215/491 - Train Accuracy:  0.845, Validation Accuracy:  0.845, Loss:  2.665\n",
      "Epoch   1 Batch  216/491 - Train Accuracy:  0.869, Validation Accuracy:  0.852, Loss:  2.710\n",
      "Epoch   1 Batch  217/491 - Train Accuracy:  0.845, Validation Accuracy:  0.838, Loss:  2.696\n",
      "Epoch   1 Batch  218/491 - Train Accuracy:  0.867, Validation Accuracy:  0.850, Loss:  2.711\n",
      "Epoch   1 Batch  219/491 - Train Accuracy:  0.820, Validation Accuracy:  0.849, Loss:  2.783\n",
      "Epoch   1 Batch  220/491 - Train Accuracy:  0.838, Validation Accuracy:  0.854, Loss:  2.712\n",
      "Epoch   1 Batch  221/491 - Train Accuracy:  0.858, Validation Accuracy:  0.849, Loss:  2.712\n",
      "Epoch   1 Batch  222/491 - Train Accuracy:  0.854, Validation Accuracy:  0.840, Loss:  2.667\n",
      "Epoch   1 Batch  223/491 - Train Accuracy:  0.834, Validation Accuracy:  0.846, Loss:  2.739\n",
      "Epoch   1 Batch  224/491 - Train Accuracy:  0.828, Validation Accuracy:  0.837, Loss:  2.705\n",
      "Epoch   1 Batch  225/491 - Train Accuracy:  0.863, Validation Accuracy:  0.844, Loss:  2.692\n",
      "Epoch   1 Batch  226/491 - Train Accuracy:  0.860, Validation Accuracy:  0.855, Loss:  2.710\n",
      "Epoch   1 Batch  227/491 - Train Accuracy:  0.845, Validation Accuracy:  0.855, Loss:  2.638\n",
      "Epoch   1 Batch  228/491 - Train Accuracy:  0.855, Validation Accuracy:  0.852, Loss:  2.676\n",
      "Epoch   1 Batch  229/491 - Train Accuracy:  0.850, Validation Accuracy:  0.861, Loss:  2.696\n",
      "Epoch   1 Batch  230/491 - Train Accuracy:  0.846, Validation Accuracy:  0.860, Loss:  2.646\n",
      "Epoch   1 Batch  231/491 - Train Accuracy:  0.841, Validation Accuracy:  0.848, Loss:  2.629\n",
      "Epoch   1 Batch  232/491 - Train Accuracy:  0.859, Validation Accuracy:  0.842, Loss:  2.719\n",
      "Epoch   1 Batch  233/491 - Train Accuracy:  0.868, Validation Accuracy:  0.848, Loss:  2.817\n",
      "Epoch   1 Batch  234/491 - Train Accuracy:  0.861, Validation Accuracy:  0.837, Loss:  2.740\n",
      "Epoch   1 Batch  235/491 - Train Accuracy:  0.868, Validation Accuracy:  0.844, Loss:  2.668\n",
      "Epoch   1 Batch  236/491 - Train Accuracy:  0.836, Validation Accuracy:  0.861, Loss:  2.762\n",
      "Epoch   1 Batch  237/491 - Train Accuracy:  0.848, Validation Accuracy:  0.844, Loss:  2.687\n",
      "Epoch   1 Batch  238/491 - Train Accuracy:  0.888, Validation Accuracy:  0.847, Loss:  2.709\n",
      "Epoch   1 Batch  239/491 - Train Accuracy:  0.868, Validation Accuracy:  0.850, Loss:  2.669\n",
      "Epoch   1 Batch  240/491 - Train Accuracy:  0.851, Validation Accuracy:  0.848, Loss:  2.744\n",
      "Epoch   1 Batch  241/491 - Train Accuracy:  0.863, Validation Accuracy:  0.857, Loss:  2.733\n",
      "Epoch   1 Batch  242/491 - Train Accuracy:  0.863, Validation Accuracy:  0.862, Loss:  2.678\n",
      "Epoch   1 Batch  243/491 - Train Accuracy:  0.859, Validation Accuracy:  0.852, Loss:  2.641\n",
      "Epoch   1 Batch  244/491 - Train Accuracy:  0.859, Validation Accuracy:  0.848, Loss:  2.744\n",
      "Epoch   1 Batch  245/491 - Train Accuracy:  0.838, Validation Accuracy:  0.841, Loss:  2.721\n",
      "Epoch   1 Batch  246/491 - Train Accuracy:  0.847, Validation Accuracy:  0.845, Loss:  2.708\n",
      "Epoch   1 Batch  247/491 - Train Accuracy:  0.853, Validation Accuracy:  0.850, Loss:  2.662\n",
      "Epoch   1 Batch  248/491 - Train Accuracy:  0.869, Validation Accuracy:  0.854, Loss:  2.694\n",
      "Epoch   1 Batch  249/491 - Train Accuracy:  0.859, Validation Accuracy:  0.863, Loss:  2.705\n",
      "Epoch   1 Batch  250/491 - Train Accuracy:  0.868, Validation Accuracy:  0.865, Loss:  2.696\n",
      "Epoch   1 Batch  251/491 - Train Accuracy:  0.887, Validation Accuracy:  0.872, Loss:  2.700\n",
      "Epoch   1 Batch  252/491 - Train Accuracy:  0.866, Validation Accuracy:  0.872, Loss:  2.650\n",
      "Epoch   1 Batch  253/491 - Train Accuracy:  0.843, Validation Accuracy:  0.872, Loss:  2.705\n",
      "Epoch   1 Batch  254/491 - Train Accuracy:  0.855, Validation Accuracy:  0.863, Loss:  2.769\n",
      "Epoch   1 Batch  255/491 - Train Accuracy:  0.867, Validation Accuracy:  0.853, Loss:  2.686\n",
      "Epoch   1 Batch  256/491 - Train Accuracy:  0.853, Validation Accuracy:  0.850, Loss:  2.721\n",
      "Epoch   1 Batch  257/491 - Train Accuracy:  0.840, Validation Accuracy:  0.853, Loss:  2.726\n",
      "Epoch   1 Batch  258/491 - Train Accuracy:  0.860, Validation Accuracy:  0.863, Loss:  2.646\n",
      "Epoch   1 Batch  259/491 - Train Accuracy:  0.870, Validation Accuracy:  0.857, Loss:  2.657\n",
      "Epoch   1 Batch  260/491 - Train Accuracy:  0.839, Validation Accuracy:  0.856, Loss:  2.706\n",
      "Epoch   1 Batch  261/491 - Train Accuracy:  0.860, Validation Accuracy:  0.855, Loss:  2.707\n",
      "Epoch   1 Batch  262/491 - Train Accuracy:  0.870, Validation Accuracy:  0.839, Loss:  2.725\n",
      "Epoch   1 Batch  263/491 - Train Accuracy:  0.866, Validation Accuracy:  0.851, Loss:  2.677\n",
      "Epoch   1 Batch  264/491 - Train Accuracy:  0.855, Validation Accuracy:  0.858, Loss:  2.719\n",
      "Epoch   1 Batch  265/491 - Train Accuracy:  0.848, Validation Accuracy:  0.866, Loss:  2.705\n",
      "Epoch   1 Batch  266/491 - Train Accuracy:  0.872, Validation Accuracy:  0.876, Loss:  2.672\n",
      "Epoch   1 Batch  267/491 - Train Accuracy:  0.884, Validation Accuracy:  0.877, Loss:  2.719\n",
      "Epoch   1 Batch  268/491 - Train Accuracy:  0.877, Validation Accuracy:  0.877, Loss:  2.735\n",
      "Epoch   1 Batch  269/491 - Train Accuracy:  0.857, Validation Accuracy:  0.860, Loss:  2.718\n",
      "Epoch   1 Batch  270/491 - Train Accuracy:  0.851, Validation Accuracy:  0.856, Loss:  2.626\n",
      "Epoch   1 Batch  271/491 - Train Accuracy:  0.894, Validation Accuracy:  0.863, Loss:  2.665\n",
      "Epoch   1 Batch  272/491 - Train Accuracy:  0.841, Validation Accuracy:  0.868, Loss:  2.682\n",
      "Epoch   1 Batch  273/491 - Train Accuracy:  0.866, Validation Accuracy:  0.869, Loss:  2.611\n",
      "Epoch   1 Batch  274/491 - Train Accuracy:  0.819, Validation Accuracy:  0.868, Loss:  2.684\n",
      "Epoch   1 Batch  275/491 - Train Accuracy:  0.845, Validation Accuracy:  0.843, Loss:  2.738\n",
      "Epoch   1 Batch  276/491 - Train Accuracy:  0.833, Validation Accuracy:  0.830, Loss:  2.750\n",
      "Epoch   1 Batch  277/491 - Train Accuracy:  0.851, Validation Accuracy:  0.843, Loss:  2.629\n",
      "Epoch   1 Batch  278/491 - Train Accuracy:  0.870, Validation Accuracy:  0.846, Loss:  2.660\n",
      "Epoch   1 Batch  279/491 - Train Accuracy:  0.857, Validation Accuracy:  0.835, Loss:  2.679\n",
      "Epoch   1 Batch  280/491 - Train Accuracy:  0.875, Validation Accuracy:  0.845, Loss:  2.703\n",
      "Epoch   1 Batch  281/491 - Train Accuracy:  0.851, Validation Accuracy:  0.857, Loss:  2.723\n",
      "Epoch   1 Batch  282/491 - Train Accuracy:  0.865, Validation Accuracy:  0.840, Loss:  2.736\n",
      "Epoch   1 Batch  283/491 - Train Accuracy:  0.864, Validation Accuracy:  0.857, Loss:  2.772\n",
      "Epoch   1 Batch  284/491 - Train Accuracy:  0.863, Validation Accuracy:  0.862, Loss:  2.675\n",
      "Epoch   1 Batch  285/491 - Train Accuracy:  0.875, Validation Accuracy:  0.867, Loss:  2.679\n",
      "Epoch   1 Batch  286/491 - Train Accuracy:  0.847, Validation Accuracy:  0.868, Loss:  2.691\n",
      "Epoch   1 Batch  287/491 - Train Accuracy:  0.895, Validation Accuracy:  0.854, Loss:  2.660\n",
      "Epoch   1 Batch  288/491 - Train Accuracy:  0.866, Validation Accuracy:  0.849, Loss:  2.715\n",
      "Epoch   1 Batch  289/491 - Train Accuracy:  0.876, Validation Accuracy:  0.863, Loss:  2.706\n",
      "Epoch   1 Batch  290/491 - Train Accuracy:  0.887, Validation Accuracy:  0.862, Loss:  2.737\n",
      "Epoch   1 Batch  291/491 - Train Accuracy:  0.865, Validation Accuracy:  0.874, Loss:  2.712\n",
      "Epoch   1 Batch  292/491 - Train Accuracy:  0.896, Validation Accuracy:  0.888, Loss:  2.651\n",
      "Epoch   1 Batch  293/491 - Train Accuracy:  0.875, Validation Accuracy:  0.893, Loss:  2.736\n",
      "Epoch   1 Batch  294/491 - Train Accuracy:  0.888, Validation Accuracy:  0.893, Loss:  2.712\n",
      "Epoch   1 Batch  295/491 - Train Accuracy:  0.892, Validation Accuracy:  0.890, Loss:  2.641\n",
      "Epoch   1 Batch  296/491 - Train Accuracy:  0.865, Validation Accuracy:  0.886, Loss:  2.737\n",
      "Epoch   1 Batch  297/491 - Train Accuracy:  0.881, Validation Accuracy:  0.880, Loss:  2.713\n",
      "Epoch   1 Batch  298/491 - Train Accuracy:  0.863, Validation Accuracy:  0.875, Loss:  2.694\n",
      "Epoch   1 Batch  299/491 - Train Accuracy:  0.860, Validation Accuracy:  0.871, Loss:  2.672\n",
      "Epoch   1 Batch  300/491 - Train Accuracy:  0.881, Validation Accuracy:  0.875, Loss:  2.694\n",
      "Epoch   1 Batch  301/491 - Train Accuracy:  0.862, Validation Accuracy:  0.889, Loss:  2.704\n",
      "Epoch   1 Batch  302/491 - Train Accuracy:  0.886, Validation Accuracy:  0.879, Loss:  2.715\n",
      "Epoch   1 Batch  303/491 - Train Accuracy:  0.899, Validation Accuracy:  0.879, Loss:  2.716\n",
      "Epoch   1 Batch  304/491 - Train Accuracy:  0.864, Validation Accuracy:  0.879, Loss:  2.692\n",
      "Epoch   1 Batch  305/491 - Train Accuracy:  0.893, Validation Accuracy:  0.887, Loss:  2.659\n",
      "Epoch   1 Batch  306/491 - Train Accuracy:  0.875, Validation Accuracy:  0.867, Loss:  2.688\n",
      "Epoch   1 Batch  307/491 - Train Accuracy:  0.870, Validation Accuracy:  0.861, Loss:  2.704\n",
      "Epoch   1 Batch  308/491 - Train Accuracy:  0.879, Validation Accuracy:  0.872, Loss:  2.759\n",
      "Epoch   1 Batch  309/491 - Train Accuracy:  0.880, Validation Accuracy:  0.860, Loss:  2.757\n",
      "Epoch   1 Batch  310/491 - Train Accuracy:  0.911, Validation Accuracy:  0.862, Loss:  2.623\n",
      "Epoch   1 Batch  311/491 - Train Accuracy:  0.860, Validation Accuracy:  0.863, Loss:  2.724\n",
      "Epoch   1 Batch  312/491 - Train Accuracy:  0.888, Validation Accuracy:  0.867, Loss:  2.763\n",
      "Epoch   1 Batch  313/491 - Train Accuracy:  0.871, Validation Accuracy:  0.878, Loss:  2.554\n",
      "Epoch   1 Batch  314/491 - Train Accuracy:  0.886, Validation Accuracy:  0.881, Loss:  2.716\n",
      "Epoch   1 Batch  315/491 - Train Accuracy:  0.852, Validation Accuracy:  0.878, Loss:  2.646\n",
      "Epoch   1 Batch  316/491 - Train Accuracy:  0.870, Validation Accuracy:  0.885, Loss:  2.669\n",
      "Epoch   1 Batch  317/491 - Train Accuracy:  0.887, Validation Accuracy:  0.877, Loss:  2.637\n",
      "Epoch   1 Batch  318/491 - Train Accuracy:  0.863, Validation Accuracy:  0.884, Loss:  2.690\n",
      "Epoch   1 Batch  319/491 - Train Accuracy:  0.883, Validation Accuracy:  0.892, Loss:  2.706\n",
      "Epoch   1 Batch  320/491 - Train Accuracy:  0.861, Validation Accuracy:  0.869, Loss:  2.704\n",
      "Epoch   1 Batch  321/491 - Train Accuracy:  0.874, Validation Accuracy:  0.866, Loss:  2.682\n",
      "Epoch   1 Batch  322/491 - Train Accuracy:  0.858, Validation Accuracy:  0.851, Loss:  2.723\n",
      "Epoch   1 Batch  323/491 - Train Accuracy:  0.891, Validation Accuracy:  0.863, Loss:  2.674\n",
      "Epoch   1 Batch  324/491 - Train Accuracy:  0.865, Validation Accuracy:  0.880, Loss:  2.711\n",
      "Epoch   1 Batch  325/491 - Train Accuracy:  0.889, Validation Accuracy:  0.882, Loss:  2.689\n",
      "Epoch   1 Batch  326/491 - Train Accuracy:  0.873, Validation Accuracy:  0.888, Loss:  2.695\n",
      "Epoch   1 Batch  327/491 - Train Accuracy:  0.871, Validation Accuracy:  0.883, Loss:  2.633\n",
      "Epoch   1 Batch  328/491 - Train Accuracy:  0.896, Validation Accuracy:  0.891, Loss:  2.617\n",
      "Epoch   1 Batch  329/491 - Train Accuracy:  0.909, Validation Accuracy:  0.898, Loss:  2.730\n",
      "Epoch   1 Batch  330/491 - Train Accuracy:  0.896, Validation Accuracy:  0.876, Loss:  2.692\n",
      "Epoch   1 Batch  331/491 - Train Accuracy:  0.883, Validation Accuracy:  0.860, Loss:  2.682\n",
      "Epoch   1 Batch  332/491 - Train Accuracy:  0.881, Validation Accuracy:  0.863, Loss:  2.661\n",
      "Epoch   1 Batch  333/491 - Train Accuracy:  0.874, Validation Accuracy:  0.864, Loss:  2.682\n",
      "Epoch   1 Batch  334/491 - Train Accuracy:  0.874, Validation Accuracy:  0.875, Loss:  2.721\n",
      "Epoch   1 Batch  335/491 - Train Accuracy:  0.883, Validation Accuracy:  0.870, Loss:  2.679\n",
      "Epoch   1 Batch  336/491 - Train Accuracy:  0.877, Validation Accuracy:  0.879, Loss:  2.696\n",
      "Epoch   1 Batch  337/491 - Train Accuracy:  0.888, Validation Accuracy:  0.876, Loss:  2.645\n",
      "Epoch   1 Batch  338/491 - Train Accuracy:  0.861, Validation Accuracy:  0.887, Loss:  2.668\n",
      "Epoch   1 Batch  339/491 - Train Accuracy:  0.861, Validation Accuracy:  0.874, Loss:  2.656\n",
      "Epoch   1 Batch  340/491 - Train Accuracy:  0.888, Validation Accuracy:  0.878, Loss:  2.676\n",
      "Epoch   1 Batch  341/491 - Train Accuracy:  0.891, Validation Accuracy:  0.883, Loss:  2.702\n",
      "Epoch   1 Batch  342/491 - Train Accuracy:  0.879, Validation Accuracy:  0.885, Loss:  2.741\n",
      "Epoch   1 Batch  343/491 - Train Accuracy:  0.889, Validation Accuracy:  0.883, Loss:  2.709\n",
      "Epoch   1 Batch  344/491 - Train Accuracy:  0.896, Validation Accuracy:  0.871, Loss:  2.643\n",
      "Epoch   1 Batch  345/491 - Train Accuracy:  0.886, Validation Accuracy:  0.880, Loss:  2.678\n",
      "Epoch   1 Batch  346/491 - Train Accuracy:  0.852, Validation Accuracy:  0.891, Loss:  2.766\n",
      "Epoch   1 Batch  347/491 - Train Accuracy:  0.885, Validation Accuracy:  0.895, Loss:  2.679\n",
      "Epoch   1 Batch  348/491 - Train Accuracy:  0.875, Validation Accuracy:  0.872, Loss:  2.756\n",
      "Epoch   1 Batch  349/491 - Train Accuracy:  0.891, Validation Accuracy:  0.885, Loss:  2.701\n",
      "Epoch   1 Batch  350/491 - Train Accuracy:  0.900, Validation Accuracy:  0.892, Loss:  2.744\n",
      "Epoch   1 Batch  351/491 - Train Accuracy:  0.879, Validation Accuracy:  0.889, Loss:  2.674\n",
      "Epoch   1 Batch  352/491 - Train Accuracy:  0.871, Validation Accuracy:  0.894, Loss:  2.672\n",
      "Epoch   1 Batch  353/491 - Train Accuracy:  0.863, Validation Accuracy:  0.877, Loss:  2.680\n",
      "Epoch   1 Batch  354/491 - Train Accuracy:  0.870, Validation Accuracy:  0.868, Loss:  2.712\n",
      "Epoch   1 Batch  355/491 - Train Accuracy:  0.877, Validation Accuracy:  0.880, Loss:  2.674\n",
      "Epoch   1 Batch  356/491 - Train Accuracy:  0.889, Validation Accuracy:  0.884, Loss:  2.682\n",
      "Epoch   1 Batch  357/491 - Train Accuracy:  0.864, Validation Accuracy:  0.867, Loss:  2.713\n",
      "Epoch   1 Batch  358/491 - Train Accuracy:  0.882, Validation Accuracy:  0.846, Loss:  2.694\n",
      "Epoch   1 Batch  359/491 - Train Accuracy:  0.868, Validation Accuracy:  0.874, Loss:  2.699\n",
      "Epoch   1 Batch  360/491 - Train Accuracy:  0.868, Validation Accuracy:  0.891, Loss:  2.715\n",
      "Epoch   1 Batch  361/491 - Train Accuracy:  0.898, Validation Accuracy:  0.908, Loss:  2.656\n",
      "Epoch   1 Batch  362/491 - Train Accuracy:  0.899, Validation Accuracy:  0.899, Loss:  2.619\n",
      "Epoch   1 Batch  363/491 - Train Accuracy:  0.873, Validation Accuracy:  0.880, Loss:  2.704\n",
      "Epoch   1 Batch  364/491 - Train Accuracy:  0.871, Validation Accuracy:  0.870, Loss:  2.727\n",
      "Epoch   1 Batch  365/491 - Train Accuracy:  0.850, Validation Accuracy:  0.865, Loss:  2.656\n",
      "Epoch   1 Batch  366/491 - Train Accuracy:  0.886, Validation Accuracy:  0.863, Loss:  2.697\n",
      "Epoch   1 Batch  367/491 - Train Accuracy:  0.882, Validation Accuracy:  0.873, Loss:  2.669\n",
      "Epoch   1 Batch  368/491 - Train Accuracy:  0.914, Validation Accuracy:  0.880, Loss:  2.731\n",
      "Epoch   1 Batch  369/491 - Train Accuracy:  0.897, Validation Accuracy:  0.870, Loss:  2.671\n",
      "Epoch   1 Batch  370/491 - Train Accuracy:  0.893, Validation Accuracy:  0.871, Loss:  2.703\n",
      "Epoch   1 Batch  371/491 - Train Accuracy:  0.895, Validation Accuracy:  0.885, Loss:  2.722\n",
      "Epoch   1 Batch  372/491 - Train Accuracy:  0.914, Validation Accuracy:  0.896, Loss:  2.630\n",
      "Epoch   1 Batch  373/491 - Train Accuracy:  0.877, Validation Accuracy:  0.899, Loss:  2.694\n",
      "Epoch   1 Batch  374/491 - Train Accuracy:  0.898, Validation Accuracy:  0.900, Loss:  2.673\n",
      "Epoch   1 Batch  375/491 - Train Accuracy:  0.892, Validation Accuracy:  0.897, Loss:  2.684\n",
      "Epoch   1 Batch  376/491 - Train Accuracy:  0.880, Validation Accuracy:  0.897, Loss:  2.600\n",
      "Epoch   1 Batch  377/491 - Train Accuracy:  0.900, Validation Accuracy:  0.888, Loss:  2.620\n",
      "Epoch   1 Batch  378/491 - Train Accuracy:  0.890, Validation Accuracy:  0.896, Loss:  2.681\n",
      "Epoch   1 Batch  379/491 - Train Accuracy:  0.894, Validation Accuracy:  0.900, Loss:  2.726\n",
      "Epoch   1 Batch  380/491 - Train Accuracy:  0.882, Validation Accuracy:  0.892, Loss:  2.706\n",
      "Epoch   1 Batch  381/491 - Train Accuracy:  0.905, Validation Accuracy:  0.890, Loss:  2.676\n",
      "Epoch   1 Batch  382/491 - Train Accuracy:  0.879, Validation Accuracy:  0.896, Loss:  2.643\n",
      "Epoch   1 Batch  383/491 - Train Accuracy:  0.896, Validation Accuracy:  0.900, Loss:  2.677\n",
      "Epoch   1 Batch  384/491 - Train Accuracy:  0.887, Validation Accuracy:  0.885, Loss:  2.693\n",
      "Epoch   1 Batch  385/491 - Train Accuracy:  0.905, Validation Accuracy:  0.882, Loss:  2.716\n",
      "Epoch   1 Batch  386/491 - Train Accuracy:  0.886, Validation Accuracy:  0.883, Loss:  2.722\n",
      "Epoch   1 Batch  387/491 - Train Accuracy:  0.879, Validation Accuracy:  0.889, Loss:  2.660\n",
      "Epoch   1 Batch  388/491 - Train Accuracy:  0.904, Validation Accuracy:  0.881, Loss:  2.712\n",
      "Epoch   1 Batch  389/491 - Train Accuracy:  0.851, Validation Accuracy:  0.876, Loss:  2.719\n",
      "Epoch   1 Batch  390/491 - Train Accuracy:  0.888, Validation Accuracy:  0.888, Loss:  2.696\n",
      "Epoch   1 Batch  391/491 - Train Accuracy:  0.886, Validation Accuracy:  0.883, Loss:  2.696\n",
      "Epoch   1 Batch  392/491 - Train Accuracy:  0.881, Validation Accuracy:  0.883, Loss:  2.625\n",
      "Epoch   1 Batch  393/491 - Train Accuracy:  0.881, Validation Accuracy:  0.880, Loss:  2.696\n",
      "Epoch   1 Batch  394/491 - Train Accuracy:  0.855, Validation Accuracy:  0.886, Loss:  2.647\n",
      "Epoch   1 Batch  395/491 - Train Accuracy:  0.875, Validation Accuracy:  0.864, Loss:  2.626\n",
      "Epoch   1 Batch  396/491 - Train Accuracy:  0.881, Validation Accuracy:  0.875, Loss:  2.671\n",
      "Epoch   1 Batch  397/491 - Train Accuracy:  0.886, Validation Accuracy:  0.886, Loss:  2.651\n",
      "Epoch   1 Batch  398/491 - Train Accuracy:  0.892, Validation Accuracy:  0.880, Loss:  2.668\n",
      "Epoch   1 Batch  399/491 - Train Accuracy:  0.847, Validation Accuracy:  0.871, Loss:  2.749\n",
      "Epoch   1 Batch  400/491 - Train Accuracy:  0.873, Validation Accuracy:  0.871, Loss:  2.671\n",
      "Epoch   1 Batch  401/491 - Train Accuracy:  0.887, Validation Accuracy:  0.868, Loss:  2.682\n",
      "Epoch   1 Batch  402/491 - Train Accuracy:  0.898, Validation Accuracy:  0.868, Loss:  2.768\n",
      "Epoch   1 Batch  403/491 - Train Accuracy:  0.897, Validation Accuracy:  0.870, Loss:  2.673\n",
      "Epoch   1 Batch  404/491 - Train Accuracy:  0.858, Validation Accuracy:  0.871, Loss:  2.692\n",
      "Epoch   1 Batch  405/491 - Train Accuracy:  0.884, Validation Accuracy:  0.883, Loss:  2.633\n",
      "Epoch   1 Batch  406/491 - Train Accuracy:  0.887, Validation Accuracy:  0.882, Loss:  2.686\n",
      "Epoch   1 Batch  407/491 - Train Accuracy:  0.892, Validation Accuracy:  0.860, Loss:  2.682\n",
      "Epoch   1 Batch  408/491 - Train Accuracy:  0.879, Validation Accuracy:  0.876, Loss:  2.731\n",
      "Epoch   1 Batch  409/491 - Train Accuracy:  0.865, Validation Accuracy:  0.878, Loss:  2.666\n",
      "Epoch   1 Batch  410/491 - Train Accuracy:  0.900, Validation Accuracy:  0.866, Loss:  2.707\n",
      "Epoch   1 Batch  411/491 - Train Accuracy:  0.892, Validation Accuracy:  0.872, Loss:  2.672\n",
      "Epoch   1 Batch  412/491 - Train Accuracy:  0.876, Validation Accuracy:  0.871, Loss:  2.672\n",
      "Epoch   1 Batch  413/491 - Train Accuracy:  0.871, Validation Accuracy:  0.876, Loss:  2.754\n",
      "Epoch   1 Batch  414/491 - Train Accuracy:  0.850, Validation Accuracy:  0.875, Loss:  2.687\n",
      "Epoch   1 Batch  415/491 - Train Accuracy:  0.867, Validation Accuracy:  0.880, Loss:  2.706\n",
      "Epoch   1 Batch  416/491 - Train Accuracy:  0.892, Validation Accuracy:  0.878, Loss:  2.666\n",
      "Epoch   1 Batch  417/491 - Train Accuracy:  0.879, Validation Accuracy:  0.873, Loss:  2.659\n",
      "Epoch   1 Batch  418/491 - Train Accuracy:  0.881, Validation Accuracy:  0.867, Loss:  2.669\n",
      "Epoch   1 Batch  419/491 - Train Accuracy:  0.893, Validation Accuracy:  0.865, Loss:  2.642\n",
      "Epoch   1 Batch  420/491 - Train Accuracy:  0.904, Validation Accuracy:  0.876, Loss:  2.734\n",
      "Epoch   1 Batch  421/491 - Train Accuracy:  0.877, Validation Accuracy:  0.878, Loss:  2.716\n",
      "Epoch   1 Batch  422/491 - Train Accuracy:  0.890, Validation Accuracy:  0.891, Loss:  2.610\n",
      "Epoch   1 Batch  423/491 - Train Accuracy:  0.898, Validation Accuracy:  0.883, Loss:  2.676\n",
      "Epoch   1 Batch  424/491 - Train Accuracy:  0.881, Validation Accuracy:  0.887, Loss:  2.723\n",
      "Epoch   1 Batch  425/491 - Train Accuracy:  0.873, Validation Accuracy:  0.887, Loss:  2.710\n",
      "Epoch   1 Batch  426/491 - Train Accuracy:  0.901, Validation Accuracy:  0.886, Loss:  2.656\n",
      "Epoch   1 Batch  427/491 - Train Accuracy:  0.866, Validation Accuracy:  0.903, Loss:  2.681\n",
      "Epoch   1 Batch  428/491 - Train Accuracy:  0.889, Validation Accuracy:  0.898, Loss:  2.578\n",
      "Epoch   1 Batch  429/491 - Train Accuracy:  0.906, Validation Accuracy:  0.893, Loss:  2.734\n",
      "Epoch   1 Batch  430/491 - Train Accuracy:  0.899, Validation Accuracy:  0.899, Loss:  2.636\n",
      "Epoch   1 Batch  431/491 - Train Accuracy:  0.909, Validation Accuracy:  0.892, Loss:  2.578\n",
      "Epoch   1 Batch  432/491 - Train Accuracy:  0.888, Validation Accuracy:  0.888, Loss:  2.627\n",
      "Epoch   1 Batch  433/491 - Train Accuracy:  0.901, Validation Accuracy:  0.893, Loss:  2.645\n",
      "Epoch   1 Batch  434/491 - Train Accuracy:  0.866, Validation Accuracy:  0.901, Loss:  2.694\n",
      "Epoch   1 Batch  435/491 - Train Accuracy:  0.894, Validation Accuracy:  0.903, Loss:  2.722\n",
      "Epoch   1 Batch  436/491 - Train Accuracy:  0.883, Validation Accuracy:  0.888, Loss:  2.688\n",
      "Epoch   1 Batch  437/491 - Train Accuracy:  0.892, Validation Accuracy:  0.887, Loss:  2.653\n",
      "Epoch   1 Batch  438/491 - Train Accuracy:  0.885, Validation Accuracy:  0.898, Loss:  2.700\n",
      "Epoch   1 Batch  439/491 - Train Accuracy:  0.924, Validation Accuracy:  0.904, Loss:  2.670\n",
      "Epoch   1 Batch  440/491 - Train Accuracy:  0.886, Validation Accuracy:  0.890, Loss:  2.735\n",
      "Epoch   1 Batch  441/491 - Train Accuracy:  0.870, Validation Accuracy:  0.895, Loss:  2.735\n",
      "Epoch   1 Batch  442/491 - Train Accuracy:  0.900, Validation Accuracy:  0.892, Loss:  2.658\n",
      "Epoch   1 Batch  443/491 - Train Accuracy:  0.882, Validation Accuracy:  0.889, Loss:  2.673\n",
      "Epoch   1 Batch  444/491 - Train Accuracy:  0.865, Validation Accuracy:  0.885, Loss:  2.657\n",
      "Epoch   1 Batch  445/491 - Train Accuracy:  0.900, Validation Accuracy:  0.891, Loss:  2.630\n",
      "Epoch   1 Batch  446/491 - Train Accuracy:  0.897, Validation Accuracy:  0.887, Loss:  2.643\n",
      "Epoch   1 Batch  447/491 - Train Accuracy:  0.880, Validation Accuracy:  0.895, Loss:  2.749\n",
      "Epoch   1 Batch  448/491 - Train Accuracy:  0.897, Validation Accuracy:  0.886, Loss:  2.682\n",
      "Epoch   1 Batch  449/491 - Train Accuracy:  0.914, Validation Accuracy:  0.886, Loss:  2.677\n",
      "Epoch   1 Batch  450/491 - Train Accuracy:  0.880, Validation Accuracy:  0.881, Loss:  2.722\n",
      "Epoch   1 Batch  451/491 - Train Accuracy:  0.872, Validation Accuracy:  0.877, Loss:  2.627\n",
      "Epoch   1 Batch  452/491 - Train Accuracy:  0.901, Validation Accuracy:  0.884, Loss:  2.625\n",
      "Epoch   1 Batch  453/491 - Train Accuracy:  0.886, Validation Accuracy:  0.891, Loss:  2.710\n",
      "Epoch   1 Batch  454/491 - Train Accuracy:  0.894, Validation Accuracy:  0.892, Loss:  2.699\n",
      "Epoch   1 Batch  455/491 - Train Accuracy:  0.898, Validation Accuracy:  0.901, Loss:  2.681\n",
      "Epoch   1 Batch  456/491 - Train Accuracy:  0.905, Validation Accuracy:  0.897, Loss:  2.670\n",
      "Epoch   1 Batch  457/491 - Train Accuracy:  0.889, Validation Accuracy:  0.898, Loss:  2.680\n",
      "Epoch   1 Batch  458/491 - Train Accuracy:  0.888, Validation Accuracy:  0.893, Loss:  2.647\n",
      "Epoch   1 Batch  459/491 - Train Accuracy:  0.888, Validation Accuracy:  0.890, Loss:  2.632\n",
      "Epoch   1 Batch  460/491 - Train Accuracy:  0.866, Validation Accuracy:  0.898, Loss:  2.720\n",
      "Epoch   1 Batch  461/491 - Train Accuracy:  0.902, Validation Accuracy:  0.893, Loss:  2.732\n",
      "Epoch   1 Batch  462/491 - Train Accuracy:  0.903, Validation Accuracy:  0.897, Loss:  2.644\n",
      "Epoch   1 Batch  463/491 - Train Accuracy:  0.876, Validation Accuracy:  0.899, Loss:  2.672\n",
      "Epoch   1 Batch  464/491 - Train Accuracy:  0.895, Validation Accuracy:  0.897, Loss:  2.632\n",
      "Epoch   1 Batch  465/491 - Train Accuracy:  0.888, Validation Accuracy:  0.889, Loss:  2.718\n",
      "Epoch   1 Batch  466/491 - Train Accuracy:  0.903, Validation Accuracy:  0.873, Loss:  2.787\n",
      "Epoch   1 Batch  467/491 - Train Accuracy:  0.888, Validation Accuracy:  0.861, Loss:  2.681\n",
      "Epoch   1 Batch  468/491 - Train Accuracy:  0.886, Validation Accuracy:  0.870, Loss:  2.691\n",
      "Epoch   1 Batch  469/491 - Train Accuracy:  0.896, Validation Accuracy:  0.872, Loss:  2.659\n",
      "Epoch   1 Batch  470/491 - Train Accuracy:  0.888, Validation Accuracy:  0.877, Loss:  2.600\n",
      "Epoch   1 Batch  471/491 - Train Accuracy:  0.890, Validation Accuracy:  0.880, Loss:  2.658\n",
      "Epoch   1 Batch  472/491 - Train Accuracy:  0.925, Validation Accuracy:  0.888, Loss:  2.675\n",
      "Epoch   1 Batch  473/491 - Train Accuracy:  0.868, Validation Accuracy:  0.892, Loss:  2.665\n",
      "Epoch   1 Batch  474/491 - Train Accuracy:  0.886, Validation Accuracy:  0.886, Loss:  2.706\n",
      "Epoch   1 Batch  475/491 - Train Accuracy:  0.906, Validation Accuracy:  0.890, Loss:  2.690\n",
      "Epoch   1 Batch  476/491 - Train Accuracy:  0.880, Validation Accuracy:  0.898, Loss:  2.669\n",
      "Epoch   1 Batch  477/491 - Train Accuracy:  0.873, Validation Accuracy:  0.899, Loss:  2.783\n",
      "Epoch   1 Batch  478/491 - Train Accuracy:  0.908, Validation Accuracy:  0.902, Loss:  2.692\n",
      "Epoch   1 Batch  479/491 - Train Accuracy:  0.904, Validation Accuracy:  0.900, Loss:  2.674\n",
      "Epoch   1 Batch  480/491 - Train Accuracy:  0.912, Validation Accuracy:  0.909, Loss:  2.634\n",
      "Epoch   1 Batch  481/491 - Train Accuracy:  0.903, Validation Accuracy:  0.898, Loss:  2.675\n",
      "Epoch   1 Batch  482/491 - Train Accuracy:  0.898, Validation Accuracy:  0.896, Loss:  2.642\n",
      "Epoch   1 Batch  483/491 - Train Accuracy:  0.874, Validation Accuracy:  0.894, Loss:  2.719\n",
      "Epoch   1 Batch  484/491 - Train Accuracy:  0.896, Validation Accuracy:  0.890, Loss:  2.599\n",
      "Epoch   1 Batch  485/491 - Train Accuracy:  0.897, Validation Accuracy:  0.896, Loss:  2.690\n",
      "Epoch   1 Batch  486/491 - Train Accuracy:  0.912, Validation Accuracy:  0.901, Loss:  2.702\n",
      "Epoch   1 Batch  487/491 - Train Accuracy:  0.899, Validation Accuracy:  0.899, Loss:  2.660\n",
      "Epoch   1 Batch  488/491 - Train Accuracy:  0.901, Validation Accuracy:  0.910, Loss:  2.641\n",
      "Epoch   1 Batch  489/491 - Train Accuracy:  0.879, Validation Accuracy:  0.900, Loss:  2.706\n",
      "Epoch   2 Batch    0/491 - Train Accuracy:  0.912, Validation Accuracy:  0.898, Loss:  2.628\n",
      "Epoch   2 Batch    1/491 - Train Accuracy:  0.914, Validation Accuracy:  0.901, Loss:  2.660\n",
      "Epoch   2 Batch    2/491 - Train Accuracy:  0.913, Validation Accuracy:  0.899, Loss:  2.652\n",
      "Epoch   2 Batch    3/491 - Train Accuracy:  0.915, Validation Accuracy:  0.875, Loss:  2.692\n",
      "Epoch   2 Batch    4/491 - Train Accuracy:  0.897, Validation Accuracy:  0.878, Loss:  2.662\n",
      "Epoch   2 Batch    5/491 - Train Accuracy:  0.892, Validation Accuracy:  0.884, Loss:  2.666\n",
      "Epoch   2 Batch    6/491 - Train Accuracy:  0.910, Validation Accuracy:  0.891, Loss:  2.692\n",
      "Epoch   2 Batch    7/491 - Train Accuracy:  0.918, Validation Accuracy:  0.886, Loss:  2.686\n",
      "Epoch   2 Batch    8/491 - Train Accuracy:  0.882, Validation Accuracy:  0.891, Loss:  2.633\n",
      "Epoch   2 Batch    9/491 - Train Accuracy:  0.898, Validation Accuracy:  0.892, Loss:  2.650\n",
      "Epoch   2 Batch   10/491 - Train Accuracy:  0.896, Validation Accuracy:  0.894, Loss:  2.699\n",
      "Epoch   2 Batch   11/491 - Train Accuracy:  0.902, Validation Accuracy:  0.893, Loss:  2.643\n",
      "Epoch   2 Batch   12/491 - Train Accuracy:  0.912, Validation Accuracy:  0.874, Loss:  2.758\n",
      "Epoch   2 Batch   13/491 - Train Accuracy:  0.927, Validation Accuracy:  0.895, Loss:  2.701\n",
      "Epoch   2 Batch   14/491 - Train Accuracy:  0.887, Validation Accuracy:  0.893, Loss:  2.672\n",
      "Epoch   2 Batch   15/491 - Train Accuracy:  0.899, Validation Accuracy:  0.890, Loss:  2.663\n",
      "Epoch   2 Batch   16/491 - Train Accuracy:  0.887, Validation Accuracy:  0.889, Loss:  2.726\n",
      "Epoch   2 Batch   17/491 - Train Accuracy:  0.900, Validation Accuracy:  0.893, Loss:  2.652\n",
      "Epoch   2 Batch   18/491 - Train Accuracy:  0.907, Validation Accuracy:  0.895, Loss:  2.656\n",
      "Epoch   2 Batch   19/491 - Train Accuracy:  0.884, Validation Accuracy:  0.894, Loss:  2.701\n",
      "Epoch   2 Batch   20/491 - Train Accuracy:  0.896, Validation Accuracy:  0.892, Loss:  2.682\n",
      "Epoch   2 Batch   21/491 - Train Accuracy:  0.920, Validation Accuracy:  0.889, Loss:  2.667\n",
      "Epoch   2 Batch   22/491 - Train Accuracy:  0.900, Validation Accuracy:  0.895, Loss:  2.612\n",
      "Epoch   2 Batch   23/491 - Train Accuracy:  0.906, Validation Accuracy:  0.893, Loss:  2.688\n",
      "Epoch   2 Batch   24/491 - Train Accuracy:  0.916, Validation Accuracy:  0.894, Loss:  2.624\n",
      "Epoch   2 Batch   25/491 - Train Accuracy:  0.893, Validation Accuracy:  0.892, Loss:  2.692\n",
      "Epoch   2 Batch   26/491 - Train Accuracy:  0.879, Validation Accuracy:  0.899, Loss:  2.677\n",
      "Epoch   2 Batch   27/491 - Train Accuracy:  0.893, Validation Accuracy:  0.894, Loss:  2.574\n",
      "Epoch   2 Batch   28/491 - Train Accuracy:  0.892, Validation Accuracy:  0.896, Loss:  2.666\n",
      "Epoch   2 Batch   29/491 - Train Accuracy:  0.902, Validation Accuracy:  0.893, Loss:  2.715\n",
      "Epoch   2 Batch   30/491 - Train Accuracy:  0.868, Validation Accuracy:  0.887, Loss:  2.687\n",
      "Epoch   2 Batch   31/491 - Train Accuracy:  0.903, Validation Accuracy:  0.881, Loss:  2.661\n",
      "Epoch   2 Batch   32/491 - Train Accuracy:  0.898, Validation Accuracy:  0.894, Loss:  2.568\n",
      "Epoch   2 Batch   33/491 - Train Accuracy:  0.903, Validation Accuracy:  0.897, Loss:  2.660\n",
      "Epoch   2 Batch   34/491 - Train Accuracy:  0.891, Validation Accuracy:  0.903, Loss:  2.637\n",
      "Epoch   2 Batch   35/491 - Train Accuracy:  0.913, Validation Accuracy:  0.907, Loss:  2.637\n",
      "Epoch   2 Batch   36/491 - Train Accuracy:  0.900, Validation Accuracy:  0.914, Loss:  2.653\n",
      "Epoch   2 Batch   37/491 - Train Accuracy:  0.909, Validation Accuracy:  0.906, Loss:  2.651\n",
      "Epoch   2 Batch   38/491 - Train Accuracy:  0.905, Validation Accuracy:  0.898, Loss:  2.594\n",
      "Epoch   2 Batch   39/491 - Train Accuracy:  0.910, Validation Accuracy:  0.896, Loss:  2.683\n",
      "Epoch   2 Batch   40/491 - Train Accuracy:  0.907, Validation Accuracy:  0.900, Loss:  2.639\n",
      "Epoch   2 Batch   41/491 - Train Accuracy:  0.916, Validation Accuracy:  0.905, Loss:  2.599\n",
      "Epoch   2 Batch   42/491 - Train Accuracy:  0.886, Validation Accuracy:  0.896, Loss:  2.607\n",
      "Epoch   2 Batch   43/491 - Train Accuracy:  0.885, Validation Accuracy:  0.897, Loss:  2.641\n",
      "Epoch   2 Batch   44/491 - Train Accuracy:  0.874, Validation Accuracy:  0.890, Loss:  2.683\n",
      "Epoch   2 Batch   45/491 - Train Accuracy:  0.903, Validation Accuracy:  0.888, Loss:  2.705\n",
      "Epoch   2 Batch   46/491 - Train Accuracy:  0.910, Validation Accuracy:  0.900, Loss:  2.631\n",
      "Epoch   2 Batch   47/491 - Train Accuracy:  0.899, Validation Accuracy:  0.905, Loss:  2.682\n",
      "Epoch   2 Batch   48/491 - Train Accuracy:  0.891, Validation Accuracy:  0.907, Loss:  2.624\n",
      "Epoch   2 Batch   49/491 - Train Accuracy:  0.904, Validation Accuracy:  0.903, Loss:  2.688\n",
      "Epoch   2 Batch   50/491 - Train Accuracy:  0.899, Validation Accuracy:  0.903, Loss:  2.635\n",
      "Epoch   2 Batch   51/491 - Train Accuracy:  0.908, Validation Accuracy:  0.902, Loss:  2.594\n",
      "Epoch   2 Batch   52/491 - Train Accuracy:  0.886, Validation Accuracy:  0.902, Loss:  2.642\n",
      "Epoch   2 Batch   53/491 - Train Accuracy:  0.901, Validation Accuracy:  0.892, Loss:  2.650\n",
      "Epoch   2 Batch   54/491 - Train Accuracy:  0.911, Validation Accuracy:  0.886, Loss:  2.644\n",
      "Epoch   2 Batch   55/491 - Train Accuracy:  0.893, Validation Accuracy:  0.893, Loss:  2.645\n",
      "Epoch   2 Batch   56/491 - Train Accuracy:  0.898, Validation Accuracy:  0.899, Loss:  2.714\n",
      "Epoch   2 Batch   57/491 - Train Accuracy:  0.884, Validation Accuracy:  0.896, Loss:  2.675\n",
      "Epoch   2 Batch   58/491 - Train Accuracy:  0.891, Validation Accuracy:  0.895, Loss:  2.636\n",
      "Epoch   2 Batch   59/491 - Train Accuracy:  0.896, Validation Accuracy:  0.896, Loss:  2.657\n",
      "Epoch   2 Batch   60/491 - Train Accuracy:  0.908, Validation Accuracy:  0.892, Loss:  2.642\n",
      "Epoch   2 Batch   61/491 - Train Accuracy:  0.896, Validation Accuracy:  0.892, Loss:  2.633\n",
      "Epoch   2 Batch   62/491 - Train Accuracy:  0.903, Validation Accuracy:  0.893, Loss:  2.692\n",
      "Epoch   2 Batch   63/491 - Train Accuracy:  0.919, Validation Accuracy:  0.882, Loss:  2.613\n",
      "Epoch   2 Batch   64/491 - Train Accuracy:  0.894, Validation Accuracy:  0.892, Loss:  2.673\n",
      "Epoch   2 Batch   65/491 - Train Accuracy:  0.870, Validation Accuracy:  0.897, Loss:  2.615\n",
      "Epoch   2 Batch   66/491 - Train Accuracy:  0.918, Validation Accuracy:  0.901, Loss:  2.672\n",
      "Epoch   2 Batch   67/491 - Train Accuracy:  0.912, Validation Accuracy:  0.907, Loss:  2.651\n",
      "Epoch   2 Batch   68/491 - Train Accuracy:  0.908, Validation Accuracy:  0.905, Loss:  2.611\n",
      "Epoch   2 Batch   69/491 - Train Accuracy:  0.892, Validation Accuracy:  0.896, Loss:  2.611\n",
      "Epoch   2 Batch   70/491 - Train Accuracy:  0.905, Validation Accuracy:  0.897, Loss:  2.648\n",
      "Epoch   2 Batch   71/491 - Train Accuracy:  0.883, Validation Accuracy:  0.891, Loss:  2.686\n",
      "Epoch   2 Batch   72/491 - Train Accuracy:  0.920, Validation Accuracy:  0.894, Loss:  2.703\n",
      "Epoch   2 Batch   73/491 - Train Accuracy:  0.897, Validation Accuracy:  0.899, Loss:  2.619\n",
      "Epoch   2 Batch   74/491 - Train Accuracy:  0.899, Validation Accuracy:  0.895, Loss:  2.713\n",
      "Epoch   2 Batch   75/491 - Train Accuracy:  0.905, Validation Accuracy:  0.897, Loss:  2.624\n",
      "Epoch   2 Batch   76/491 - Train Accuracy:  0.890, Validation Accuracy:  0.893, Loss:  2.670\n",
      "Epoch   2 Batch   77/491 - Train Accuracy:  0.901, Validation Accuracy:  0.896, Loss:  2.694\n",
      "Epoch   2 Batch   78/491 - Train Accuracy:  0.911, Validation Accuracy:  0.894, Loss:  2.697\n",
      "Epoch   2 Batch   79/491 - Train Accuracy:  0.908, Validation Accuracy:  0.897, Loss:  2.690\n",
      "Epoch   2 Batch   80/491 - Train Accuracy:  0.899, Validation Accuracy:  0.898, Loss:  2.674\n",
      "Epoch   2 Batch   81/491 - Train Accuracy:  0.885, Validation Accuracy:  0.896, Loss:  2.661\n",
      "Epoch   2 Batch   82/491 - Train Accuracy:  0.918, Validation Accuracy:  0.903, Loss:  2.664\n",
      "Epoch   2 Batch   83/491 - Train Accuracy:  0.905, Validation Accuracy:  0.896, Loss:  2.629\n",
      "Epoch   2 Batch   84/491 - Train Accuracy:  0.884, Validation Accuracy:  0.884, Loss:  2.712\n",
      "Epoch   2 Batch   85/491 - Train Accuracy:  0.916, Validation Accuracy:  0.880, Loss:  2.683\n",
      "Epoch   2 Batch   86/491 - Train Accuracy:  0.904, Validation Accuracy:  0.881, Loss:  2.646\n",
      "Epoch   2 Batch   87/491 - Train Accuracy:  0.897, Validation Accuracy:  0.884, Loss:  2.665\n",
      "Epoch   2 Batch   88/491 - Train Accuracy:  0.896, Validation Accuracy:  0.896, Loss:  2.623\n",
      "Epoch   2 Batch   89/491 - Train Accuracy:  0.916, Validation Accuracy:  0.904, Loss:  2.601\n",
      "Epoch   2 Batch   90/491 - Train Accuracy:  0.905, Validation Accuracy:  0.899, Loss:  2.655\n",
      "Epoch   2 Batch   91/491 - Train Accuracy:  0.902, Validation Accuracy:  0.899, Loss:  2.724\n",
      "Epoch   2 Batch   92/491 - Train Accuracy:  0.907, Validation Accuracy:  0.890, Loss:  2.676\n",
      "Epoch   2 Batch   93/491 - Train Accuracy:  0.899, Validation Accuracy:  0.899, Loss:  2.672\n",
      "Epoch   2 Batch   94/491 - Train Accuracy:  0.900, Validation Accuracy:  0.895, Loss:  2.692\n",
      "Epoch   2 Batch   95/491 - Train Accuracy:  0.885, Validation Accuracy:  0.894, Loss:  2.681\n",
      "Epoch   2 Batch   96/491 - Train Accuracy:  0.915, Validation Accuracy:  0.896, Loss:  2.668\n",
      "Epoch   2 Batch   97/491 - Train Accuracy:  0.910, Validation Accuracy:  0.906, Loss:  2.698\n",
      "Epoch   2 Batch   98/491 - Train Accuracy:  0.911, Validation Accuracy:  0.894, Loss:  2.622\n",
      "Epoch   2 Batch   99/491 - Train Accuracy:  0.897, Validation Accuracy:  0.902, Loss:  2.704\n",
      "Epoch   2 Batch  100/491 - Train Accuracy:  0.907, Validation Accuracy:  0.900, Loss:  2.606\n",
      "Epoch   2 Batch  101/491 - Train Accuracy:  0.889, Validation Accuracy:  0.902, Loss:  2.616\n",
      "Epoch   2 Batch  102/491 - Train Accuracy:  0.878, Validation Accuracy:  0.896, Loss:  2.628\n",
      "Epoch   2 Batch  103/491 - Train Accuracy:  0.899, Validation Accuracy:  0.894, Loss:  2.658\n",
      "Epoch   2 Batch  104/491 - Train Accuracy:  0.915, Validation Accuracy:  0.891, Loss:  2.694\n",
      "Epoch   2 Batch  105/491 - Train Accuracy:  0.908, Validation Accuracy:  0.888, Loss:  2.625\n",
      "Epoch   2 Batch  106/491 - Train Accuracy:  0.888, Validation Accuracy:  0.894, Loss:  2.638\n",
      "Epoch   2 Batch  107/491 - Train Accuracy:  0.904, Validation Accuracy:  0.901, Loss:  2.690\n",
      "Epoch   2 Batch  108/491 - Train Accuracy:  0.909, Validation Accuracy:  0.896, Loss:  2.666\n",
      "Epoch   2 Batch  109/491 - Train Accuracy:  0.912, Validation Accuracy:  0.897, Loss:  2.712\n",
      "Epoch   2 Batch  110/491 - Train Accuracy:  0.900, Validation Accuracy:  0.897, Loss:  2.632\n",
      "Epoch   2 Batch  111/491 - Train Accuracy:  0.899, Validation Accuracy:  0.894, Loss:  2.646\n",
      "Epoch   2 Batch  112/491 - Train Accuracy:  0.912, Validation Accuracy:  0.900, Loss:  2.744\n",
      "Epoch   2 Batch  113/491 - Train Accuracy:  0.894, Validation Accuracy:  0.914, Loss:  2.572\n",
      "Epoch   2 Batch  114/491 - Train Accuracy:  0.889, Validation Accuracy:  0.905, Loss:  2.713\n",
      "Epoch   2 Batch  115/491 - Train Accuracy:  0.917, Validation Accuracy:  0.908, Loss:  2.655\n",
      "Epoch   2 Batch  116/491 - Train Accuracy:  0.894, Validation Accuracy:  0.902, Loss:  2.742\n",
      "Epoch   2 Batch  117/491 - Train Accuracy:  0.906, Validation Accuracy:  0.891, Loss:  2.695\n",
      "Epoch   2 Batch  118/491 - Train Accuracy:  0.894, Validation Accuracy:  0.888, Loss:  2.663\n",
      "Epoch   2 Batch  119/491 - Train Accuracy:  0.932, Validation Accuracy:  0.887, Loss:  2.660\n",
      "Epoch   2 Batch  120/491 - Train Accuracy:  0.908, Validation Accuracy:  0.899, Loss:  2.736\n",
      "Epoch   2 Batch  121/491 - Train Accuracy:  0.902, Validation Accuracy:  0.906, Loss:  2.658\n",
      "Epoch   2 Batch  122/491 - Train Accuracy:  0.911, Validation Accuracy:  0.903, Loss:  2.671\n",
      "Epoch   2 Batch  123/491 - Train Accuracy:  0.908, Validation Accuracy:  0.908, Loss:  2.616\n",
      "Epoch   2 Batch  124/491 - Train Accuracy:  0.906, Validation Accuracy:  0.906, Loss:  2.669\n",
      "Epoch   2 Batch  125/491 - Train Accuracy:  0.894, Validation Accuracy:  0.906, Loss:  2.682\n",
      "Epoch   2 Batch  126/491 - Train Accuracy:  0.894, Validation Accuracy:  0.906, Loss:  2.628\n",
      "Epoch   2 Batch  127/491 - Train Accuracy:  0.903, Validation Accuracy:  0.906, Loss:  2.653\n",
      "Epoch   2 Batch  128/491 - Train Accuracy:  0.925, Validation Accuracy:  0.912, Loss:  2.658\n",
      "Epoch   2 Batch  129/491 - Train Accuracy:  0.906, Validation Accuracy:  0.914, Loss:  2.618\n",
      "Epoch   2 Batch  130/491 - Train Accuracy:  0.912, Validation Accuracy:  0.908, Loss:  2.628\n",
      "Epoch   2 Batch  131/491 - Train Accuracy:  0.931, Validation Accuracy:  0.896, Loss:  2.650\n",
      "Epoch   2 Batch  132/491 - Train Accuracy:  0.882, Validation Accuracy:  0.898, Loss:  2.676\n",
      "Epoch   2 Batch  133/491 - Train Accuracy:  0.901, Validation Accuracy:  0.902, Loss:  2.614\n",
      "Epoch   2 Batch  134/491 - Train Accuracy:  0.887, Validation Accuracy:  0.909, Loss:  2.610\n",
      "Epoch   2 Batch  135/491 - Train Accuracy:  0.916, Validation Accuracy:  0.913, Loss:  2.662\n",
      "Epoch   2 Batch  136/491 - Train Accuracy:  0.917, Validation Accuracy:  0.901, Loss:  2.652\n",
      "Epoch   2 Batch  137/491 - Train Accuracy:  0.893, Validation Accuracy:  0.906, Loss:  2.686\n",
      "Epoch   2 Batch  138/491 - Train Accuracy:  0.903, Validation Accuracy:  0.902, Loss:  2.638\n",
      "Epoch   2 Batch  139/491 - Train Accuracy:  0.903, Validation Accuracy:  0.896, Loss:  2.725\n",
      "Epoch   2 Batch  140/491 - Train Accuracy:  0.890, Validation Accuracy:  0.897, Loss:  2.676\n",
      "Epoch   2 Batch  141/491 - Train Accuracy:  0.911, Validation Accuracy:  0.903, Loss:  2.690\n",
      "Epoch   2 Batch  142/491 - Train Accuracy:  0.914, Validation Accuracy:  0.906, Loss:  2.656\n",
      "Epoch   2 Batch  143/491 - Train Accuracy:  0.902, Validation Accuracy:  0.914, Loss:  2.660\n",
      "Epoch   2 Batch  144/491 - Train Accuracy:  0.909, Validation Accuracy:  0.909, Loss:  2.625\n",
      "Epoch   2 Batch  145/491 - Train Accuracy:  0.903, Validation Accuracy:  0.896, Loss:  2.620\n",
      "Epoch   2 Batch  146/491 - Train Accuracy:  0.895, Validation Accuracy:  0.898, Loss:  2.692\n",
      "Epoch   2 Batch  147/491 - Train Accuracy:  0.897, Validation Accuracy:  0.898, Loss:  2.719\n",
      "Epoch   2 Batch  148/491 - Train Accuracy:  0.895, Validation Accuracy:  0.900, Loss:  2.620\n",
      "Epoch   2 Batch  149/491 - Train Accuracy:  0.915, Validation Accuracy:  0.888, Loss:  2.727\n",
      "Epoch   2 Batch  150/491 - Train Accuracy:  0.913, Validation Accuracy:  0.895, Loss:  2.675\n",
      "Epoch   2 Batch  151/491 - Train Accuracy:  0.909, Validation Accuracy:  0.889, Loss:  2.630\n",
      "Epoch   2 Batch  152/491 - Train Accuracy:  0.902, Validation Accuracy:  0.895, Loss:  2.672\n",
      "Epoch   2 Batch  153/491 - Train Accuracy:  0.902, Validation Accuracy:  0.898, Loss:  2.633\n",
      "Epoch   2 Batch  154/491 - Train Accuracy:  0.909, Validation Accuracy:  0.896, Loss:  2.671\n",
      "Epoch   2 Batch  155/491 - Train Accuracy:  0.915, Validation Accuracy:  0.902, Loss:  2.718\n",
      "Epoch   2 Batch  156/491 - Train Accuracy:  0.931, Validation Accuracy:  0.901, Loss:  2.664\n",
      "Epoch   2 Batch  157/491 - Train Accuracy:  0.917, Validation Accuracy:  0.901, Loss:  2.645\n",
      "Epoch   2 Batch  158/491 - Train Accuracy:  0.911, Validation Accuracy:  0.895, Loss:  2.698\n",
      "Epoch   2 Batch  159/491 - Train Accuracy:  0.897, Validation Accuracy:  0.892, Loss:  2.654\n",
      "Epoch   2 Batch  160/491 - Train Accuracy:  0.897, Validation Accuracy:  0.892, Loss:  2.683\n",
      "Epoch   2 Batch  161/491 - Train Accuracy:  0.912, Validation Accuracy:  0.894, Loss:  2.670\n",
      "Epoch   2 Batch  162/491 - Train Accuracy:  0.891, Validation Accuracy:  0.901, Loss:  2.669\n",
      "Epoch   2 Batch  163/491 - Train Accuracy:  0.888, Validation Accuracy:  0.898, Loss:  2.707\n",
      "Epoch   2 Batch  164/491 - Train Accuracy:  0.908, Validation Accuracy:  0.904, Loss:  2.630\n",
      "Epoch   2 Batch  165/491 - Train Accuracy:  0.900, Validation Accuracy:  0.906, Loss:  2.668\n",
      "Epoch   2 Batch  166/491 - Train Accuracy:  0.929, Validation Accuracy:  0.896, Loss:  2.687\n",
      "Epoch   2 Batch  167/491 - Train Accuracy:  0.919, Validation Accuracy:  0.907, Loss:  2.629\n",
      "Epoch   2 Batch  168/491 - Train Accuracy:  0.895, Validation Accuracy:  0.908, Loss:  2.622\n",
      "Epoch   2 Batch  169/491 - Train Accuracy:  0.907, Validation Accuracy:  0.907, Loss:  2.715\n",
      "Epoch   2 Batch  170/491 - Train Accuracy:  0.906, Validation Accuracy:  0.901, Loss:  2.677\n",
      "Epoch   2 Batch  171/491 - Train Accuracy:  0.901, Validation Accuracy:  0.915, Loss:  2.624\n",
      "Epoch   2 Batch  172/491 - Train Accuracy:  0.900, Validation Accuracy:  0.911, Loss:  2.624\n",
      "Epoch   2 Batch  173/491 - Train Accuracy:  0.919, Validation Accuracy:  0.905, Loss:  2.675\n",
      "Epoch   2 Batch  174/491 - Train Accuracy:  0.896, Validation Accuracy:  0.910, Loss:  2.633\n",
      "Epoch   2 Batch  175/491 - Train Accuracy:  0.915, Validation Accuracy:  0.917, Loss:  2.610\n",
      "Epoch   2 Batch  176/491 - Train Accuracy:  0.911, Validation Accuracy:  0.910, Loss:  2.637\n",
      "Epoch   2 Batch  177/491 - Train Accuracy:  0.900, Validation Accuracy:  0.915, Loss:  2.697\n",
      "Epoch   2 Batch  178/491 - Train Accuracy:  0.893, Validation Accuracy:  0.917, Loss:  2.649\n",
      "Epoch   2 Batch  179/491 - Train Accuracy:  0.923, Validation Accuracy:  0.920, Loss:  2.602\n",
      "Epoch   2 Batch  180/491 - Train Accuracy:  0.923, Validation Accuracy:  0.911, Loss:  2.688\n",
      "Epoch   2 Batch  181/491 - Train Accuracy:  0.895, Validation Accuracy:  0.911, Loss:  2.665\n",
      "Epoch   2 Batch  182/491 - Train Accuracy:  0.929, Validation Accuracy:  0.908, Loss:  2.602\n",
      "Epoch   2 Batch  183/491 - Train Accuracy:  0.924, Validation Accuracy:  0.900, Loss:  2.686\n",
      "Epoch   2 Batch  184/491 - Train Accuracy:  0.925, Validation Accuracy:  0.902, Loss:  2.618\n",
      "Epoch   2 Batch  185/491 - Train Accuracy:  0.916, Validation Accuracy:  0.905, Loss:  2.680\n",
      "Epoch   2 Batch  186/491 - Train Accuracy:  0.929, Validation Accuracy:  0.907, Loss:  2.636\n",
      "Epoch   2 Batch  187/491 - Train Accuracy:  0.917, Validation Accuracy:  0.904, Loss:  2.680\n",
      "Epoch   2 Batch  188/491 - Train Accuracy:  0.903, Validation Accuracy:  0.906, Loss:  2.600\n",
      "Epoch   2 Batch  189/491 - Train Accuracy:  0.924, Validation Accuracy:  0.910, Loss:  2.641\n",
      "Epoch   2 Batch  190/491 - Train Accuracy:  0.901, Validation Accuracy:  0.919, Loss:  2.607\n",
      "Epoch   2 Batch  191/491 - Train Accuracy:  0.909, Validation Accuracy:  0.903, Loss:  2.635\n",
      "Epoch   2 Batch  192/491 - Train Accuracy:  0.900, Validation Accuracy:  0.905, Loss:  2.636\n",
      "Epoch   2 Batch  193/491 - Train Accuracy:  0.898, Validation Accuracy:  0.905, Loss:  2.641\n",
      "Epoch   2 Batch  194/491 - Train Accuracy:  0.896, Validation Accuracy:  0.906, Loss:  2.603\n",
      "Epoch   2 Batch  195/491 - Train Accuracy:  0.915, Validation Accuracy:  0.904, Loss:  2.638\n",
      "Epoch   2 Batch  196/491 - Train Accuracy:  0.916, Validation Accuracy:  0.914, Loss:  2.615\n",
      "Epoch   2 Batch  197/491 - Train Accuracy:  0.914, Validation Accuracy:  0.907, Loss:  2.620\n",
      "Epoch   2 Batch  198/491 - Train Accuracy:  0.922, Validation Accuracy:  0.902, Loss:  2.679\n",
      "Epoch   2 Batch  199/491 - Train Accuracy:  0.900, Validation Accuracy:  0.903, Loss:  2.651\n",
      "Epoch   2 Batch  200/491 - Train Accuracy:  0.909, Validation Accuracy:  0.904, Loss:  2.627\n",
      "Epoch   2 Batch  201/491 - Train Accuracy:  0.916, Validation Accuracy:  0.907, Loss:  2.695\n",
      "Epoch   2 Batch  202/491 - Train Accuracy:  0.907, Validation Accuracy:  0.898, Loss:  2.694\n",
      "Epoch   2 Batch  203/491 - Train Accuracy:  0.901, Validation Accuracy:  0.898, Loss:  2.714\n",
      "Epoch   2 Batch  204/491 - Train Accuracy:  0.892, Validation Accuracy:  0.898, Loss:  2.578\n",
      "Epoch   2 Batch  205/491 - Train Accuracy:  0.903, Validation Accuracy:  0.898, Loss:  2.703\n",
      "Epoch   2 Batch  206/491 - Train Accuracy:  0.895, Validation Accuracy:  0.900, Loss:  2.644\n",
      "Epoch   2 Batch  207/491 - Train Accuracy:  0.915, Validation Accuracy:  0.904, Loss:  2.674\n",
      "Epoch   2 Batch  208/491 - Train Accuracy:  0.913, Validation Accuracy:  0.897, Loss:  2.644\n",
      "Epoch   2 Batch  209/491 - Train Accuracy:  0.933, Validation Accuracy:  0.898, Loss:  2.703\n",
      "Epoch   2 Batch  210/491 - Train Accuracy:  0.877, Validation Accuracy:  0.895, Loss:  2.655\n",
      "Epoch   2 Batch  211/491 - Train Accuracy:  0.904, Validation Accuracy:  0.896, Loss:  2.594\n",
      "Epoch   2 Batch  212/491 - Train Accuracy:  0.915, Validation Accuracy:  0.902, Loss:  2.663\n",
      "Epoch   2 Batch  213/491 - Train Accuracy:  0.906, Validation Accuracy:  0.899, Loss:  2.652\n",
      "Epoch   2 Batch  214/491 - Train Accuracy:  0.915, Validation Accuracy:  0.896, Loss:  2.695\n",
      "Epoch   2 Batch  215/491 - Train Accuracy:  0.937, Validation Accuracy:  0.896, Loss:  2.649\n",
      "Epoch   2 Batch  216/491 - Train Accuracy:  0.919, Validation Accuracy:  0.907, Loss:  2.679\n",
      "Epoch   2 Batch  217/491 - Train Accuracy:  0.910, Validation Accuracy:  0.909, Loss:  2.683\n",
      "Epoch   2 Batch  218/491 - Train Accuracy:  0.905, Validation Accuracy:  0.909, Loss:  2.626\n",
      "Epoch   2 Batch  219/491 - Train Accuracy:  0.885, Validation Accuracy:  0.908, Loss:  2.710\n",
      "Epoch   2 Batch  220/491 - Train Accuracy:  0.904, Validation Accuracy:  0.900, Loss:  2.564\n",
      "Epoch   2 Batch  221/491 - Train Accuracy:  0.926, Validation Accuracy:  0.899, Loss:  2.671\n",
      "Epoch   2 Batch  222/491 - Train Accuracy:  0.900, Validation Accuracy:  0.884, Loss:  2.654\n",
      "Epoch   2 Batch  223/491 - Train Accuracy:  0.904, Validation Accuracy:  0.889, Loss:  2.680\n",
      "Epoch   2 Batch  224/491 - Train Accuracy:  0.905, Validation Accuracy:  0.895, Loss:  2.732\n",
      "Epoch   2 Batch  225/491 - Train Accuracy:  0.924, Validation Accuracy:  0.913, Loss:  2.641\n",
      "Epoch   2 Batch  226/491 - Train Accuracy:  0.919, Validation Accuracy:  0.917, Loss:  2.612\n",
      "Epoch   2 Batch  227/491 - Train Accuracy:  0.919, Validation Accuracy:  0.915, Loss:  2.685\n",
      "Epoch   2 Batch  228/491 - Train Accuracy:  0.900, Validation Accuracy:  0.906, Loss:  2.717\n",
      "Epoch   2 Batch  229/491 - Train Accuracy:  0.907, Validation Accuracy:  0.903, Loss:  2.700\n",
      "Epoch   2 Batch  230/491 - Train Accuracy:  0.892, Validation Accuracy:  0.898, Loss:  2.613\n",
      "Epoch   2 Batch  231/491 - Train Accuracy:  0.906, Validation Accuracy:  0.896, Loss:  2.686\n",
      "Epoch   2 Batch  232/491 - Train Accuracy:  0.923, Validation Accuracy:  0.902, Loss:  2.628\n",
      "Epoch   2 Batch  233/491 - Train Accuracy:  0.928, Validation Accuracy:  0.904, Loss:  2.676\n",
      "Epoch   2 Batch  234/491 - Train Accuracy:  0.926, Validation Accuracy:  0.910, Loss:  2.649\n",
      "Epoch   2 Batch  235/491 - Train Accuracy:  0.926, Validation Accuracy:  0.906, Loss:  2.699\n",
      "Epoch   2 Batch  236/491 - Train Accuracy:  0.923, Validation Accuracy:  0.913, Loss:  2.592\n",
      "Epoch   2 Batch  237/491 - Train Accuracy:  0.907, Validation Accuracy:  0.904, Loss:  2.670\n",
      "Epoch   2 Batch  238/491 - Train Accuracy:  0.932, Validation Accuracy:  0.910, Loss:  2.614\n",
      "Epoch   2 Batch  239/491 - Train Accuracy:  0.908, Validation Accuracy:  0.909, Loss:  2.635\n",
      "Epoch   2 Batch  240/491 - Train Accuracy:  0.912, Validation Accuracy:  0.904, Loss:  2.611\n",
      "Epoch   2 Batch  241/491 - Train Accuracy:  0.912, Validation Accuracy:  0.909, Loss:  2.636\n",
      "Epoch   2 Batch  242/491 - Train Accuracy:  0.916, Validation Accuracy:  0.909, Loss:  2.581\n",
      "Epoch   2 Batch  243/491 - Train Accuracy:  0.926, Validation Accuracy:  0.909, Loss:  2.618\n",
      "Epoch   2 Batch  244/491 - Train Accuracy:  0.907, Validation Accuracy:  0.903, Loss:  2.612\n",
      "Epoch   2 Batch  245/491 - Train Accuracy:  0.899, Validation Accuracy:  0.900, Loss:  2.738\n",
      "Epoch   2 Batch  246/491 - Train Accuracy:  0.927, Validation Accuracy:  0.906, Loss:  2.663\n",
      "Epoch   2 Batch  247/491 - Train Accuracy:  0.893, Validation Accuracy:  0.907, Loss:  2.669\n",
      "Epoch   2 Batch  248/491 - Train Accuracy:  0.916, Validation Accuracy:  0.917, Loss:  2.644\n",
      "Epoch   2 Batch  249/491 - Train Accuracy:  0.920, Validation Accuracy:  0.924, Loss:  2.687\n",
      "Epoch   2 Batch  250/491 - Train Accuracy:  0.924, Validation Accuracy:  0.929, Loss:  2.654\n",
      "Epoch   2 Batch  251/491 - Train Accuracy:  0.917, Validation Accuracy:  0.918, Loss:  2.678\n",
      "Epoch   2 Batch  252/491 - Train Accuracy:  0.918, Validation Accuracy:  0.913, Loss:  2.671\n",
      "Epoch   2 Batch  253/491 - Train Accuracy:  0.892, Validation Accuracy:  0.906, Loss:  2.644\n",
      "Epoch   2 Batch  254/491 - Train Accuracy:  0.888, Validation Accuracy:  0.899, Loss:  2.605\n",
      "Epoch   2 Batch  255/491 - Train Accuracy:  0.906, Validation Accuracy:  0.893, Loss:  2.698\n",
      "Epoch   2 Batch  256/491 - Train Accuracy:  0.902, Validation Accuracy:  0.894, Loss:  2.649\n",
      "Epoch   2 Batch  257/491 - Train Accuracy:  0.911, Validation Accuracy:  0.898, Loss:  2.667\n",
      "Epoch   2 Batch  258/491 - Train Accuracy:  0.914, Validation Accuracy:  0.913, Loss:  2.650\n",
      "Epoch   2 Batch  259/491 - Train Accuracy:  0.899, Validation Accuracy:  0.917, Loss:  2.717\n",
      "Epoch   2 Batch  260/491 - Train Accuracy:  0.883, Validation Accuracy:  0.920, Loss:  2.629\n",
      "Epoch   2 Batch  261/491 - Train Accuracy:  0.920, Validation Accuracy:  0.915, Loss:  2.650\n",
      "Epoch   2 Batch  262/491 - Train Accuracy:  0.914, Validation Accuracy:  0.910, Loss:  2.608\n",
      "Epoch   2 Batch  263/491 - Train Accuracy:  0.902, Validation Accuracy:  0.912, Loss:  2.618\n",
      "Epoch   2 Batch  264/491 - Train Accuracy:  0.902, Validation Accuracy:  0.907, Loss:  2.642\n",
      "Epoch   2 Batch  265/491 - Train Accuracy:  0.910, Validation Accuracy:  0.904, Loss:  2.586\n",
      "Epoch   2 Batch  266/491 - Train Accuracy:  0.900, Validation Accuracy:  0.905, Loss:  2.663\n",
      "Epoch   2 Batch  267/491 - Train Accuracy:  0.904, Validation Accuracy:  0.896, Loss:  2.660\n",
      "Epoch   2 Batch  268/491 - Train Accuracy:  0.937, Validation Accuracy:  0.895, Loss:  2.626\n",
      "Epoch   2 Batch  269/491 - Train Accuracy:  0.896, Validation Accuracy:  0.899, Loss:  2.681\n",
      "Epoch   2 Batch  270/491 - Train Accuracy:  0.911, Validation Accuracy:  0.913, Loss:  2.655\n",
      "Epoch   2 Batch  271/491 - Train Accuracy:  0.914, Validation Accuracy:  0.913, Loss:  2.587\n",
      "Epoch   2 Batch  272/491 - Train Accuracy:  0.924, Validation Accuracy:  0.917, Loss:  2.671\n",
      "Epoch   2 Batch  273/491 - Train Accuracy:  0.906, Validation Accuracy:  0.902, Loss:  2.667\n",
      "Epoch   2 Batch  274/491 - Train Accuracy:  0.879, Validation Accuracy:  0.902, Loss:  2.624\n",
      "Epoch   2 Batch  275/491 - Train Accuracy:  0.899, Validation Accuracy:  0.890, Loss:  2.653\n",
      "Epoch   2 Batch  276/491 - Train Accuracy:  0.891, Validation Accuracy:  0.896, Loss:  2.686\n",
      "Epoch   2 Batch  277/491 - Train Accuracy:  0.915, Validation Accuracy:  0.895, Loss:  2.645\n",
      "Epoch   2 Batch  278/491 - Train Accuracy:  0.928, Validation Accuracy:  0.902, Loss:  2.606\n",
      "Epoch   2 Batch  279/491 - Train Accuracy:  0.914, Validation Accuracy:  0.900, Loss:  2.631\n",
      "Epoch   2 Batch  280/491 - Train Accuracy:  0.924, Validation Accuracy:  0.895, Loss:  2.626\n",
      "Epoch   2 Batch  281/491 - Train Accuracy:  0.893, Validation Accuracy:  0.894, Loss:  2.674\n",
      "Epoch   2 Batch  282/491 - Train Accuracy:  0.904, Validation Accuracy:  0.899, Loss:  2.671\n",
      "Epoch   2 Batch  283/491 - Train Accuracy:  0.908, Validation Accuracy:  0.893, Loss:  2.599\n",
      "Epoch   2 Batch  284/491 - Train Accuracy:  0.910, Validation Accuracy:  0.887, Loss:  2.653\n",
      "Epoch   2 Batch  285/491 - Train Accuracy:  0.900, Validation Accuracy:  0.882, Loss:  2.629\n",
      "Epoch   2 Batch  286/491 - Train Accuracy:  0.885, Validation Accuracy:  0.875, Loss:  2.633\n",
      "Epoch   2 Batch  287/491 - Train Accuracy:  0.916, Validation Accuracy:  0.877, Loss:  2.705\n",
      "Epoch   2 Batch  288/491 - Train Accuracy:  0.925, Validation Accuracy:  0.877, Loss:  2.679\n",
      "Epoch   2 Batch  289/491 - Train Accuracy:  0.918, Validation Accuracy:  0.883, Loss:  2.683\n",
      "Epoch   2 Batch  290/491 - Train Accuracy:  0.926, Validation Accuracy:  0.891, Loss:  2.596\n",
      "Epoch   2 Batch  291/491 - Train Accuracy:  0.918, Validation Accuracy:  0.894, Loss:  2.597\n",
      "Epoch   2 Batch  292/491 - Train Accuracy:  0.929, Validation Accuracy:  0.896, Loss:  2.631\n",
      "Epoch   2 Batch  293/491 - Train Accuracy:  0.913, Validation Accuracy:  0.893, Loss:  2.693\n",
      "Epoch   2 Batch  294/491 - Train Accuracy:  0.898, Validation Accuracy:  0.900, Loss:  2.729\n",
      "Epoch   2 Batch  295/491 - Train Accuracy:  0.911, Validation Accuracy:  0.904, Loss:  2.674\n",
      "Epoch   2 Batch  296/491 - Train Accuracy:  0.889, Validation Accuracy:  0.908, Loss:  2.715\n",
      "Epoch   2 Batch  297/491 - Train Accuracy:  0.934, Validation Accuracy:  0.917, Loss:  2.683\n",
      "Epoch   2 Batch  298/491 - Train Accuracy:  0.901, Validation Accuracy:  0.922, Loss:  2.665\n",
      "Epoch   2 Batch  299/491 - Train Accuracy:  0.904, Validation Accuracy:  0.920, Loss:  2.677\n",
      "Epoch   2 Batch  300/491 - Train Accuracy:  0.918, Validation Accuracy:  0.922, Loss:  2.575\n",
      "Epoch   2 Batch  301/491 - Train Accuracy:  0.924, Validation Accuracy:  0.913, Loss:  2.653\n",
      "Epoch   2 Batch  302/491 - Train Accuracy:  0.925, Validation Accuracy:  0.900, Loss:  2.643\n",
      "Epoch   2 Batch  303/491 - Train Accuracy:  0.928, Validation Accuracy:  0.906, Loss:  2.594\n",
      "Epoch   2 Batch  304/491 - Train Accuracy:  0.916, Validation Accuracy:  0.904, Loss:  2.652\n",
      "Epoch   2 Batch  305/491 - Train Accuracy:  0.919, Validation Accuracy:  0.908, Loss:  2.613\n",
      "Epoch   2 Batch  306/491 - Train Accuracy:  0.922, Validation Accuracy:  0.917, Loss:  2.623\n",
      "Epoch   2 Batch  307/491 - Train Accuracy:  0.914, Validation Accuracy:  0.913, Loss:  2.644\n",
      "Epoch   2 Batch  308/491 - Train Accuracy:  0.925, Validation Accuracy:  0.910, Loss:  2.613\n",
      "Epoch   2 Batch  309/491 - Train Accuracy:  0.920, Validation Accuracy:  0.912, Loss:  2.687\n",
      "Epoch   2 Batch  310/491 - Train Accuracy:  0.938, Validation Accuracy:  0.911, Loss:  2.667\n",
      "Epoch   2 Batch  311/491 - Train Accuracy:  0.913, Validation Accuracy:  0.913, Loss:  2.639\n",
      "Epoch   2 Batch  312/491 - Train Accuracy:  0.916, Validation Accuracy:  0.916, Loss:  2.627\n",
      "Epoch   2 Batch  313/491 - Train Accuracy:  0.911, Validation Accuracy:  0.902, Loss:  2.649\n",
      "Epoch   2 Batch  314/491 - Train Accuracy:  0.905, Validation Accuracy:  0.909, Loss:  2.614\n",
      "Epoch   2 Batch  315/491 - Train Accuracy:  0.911, Validation Accuracy:  0.901, Loss:  2.666\n",
      "Epoch   2 Batch  316/491 - Train Accuracy:  0.909, Validation Accuracy:  0.906, Loss:  2.593\n",
      "Epoch   2 Batch  317/491 - Train Accuracy:  0.925, Validation Accuracy:  0.903, Loss:  2.633\n",
      "Epoch   2 Batch  318/491 - Train Accuracy:  0.911, Validation Accuracy:  0.912, Loss:  2.653\n",
      "Epoch   2 Batch  319/491 - Train Accuracy:  0.899, Validation Accuracy:  0.913, Loss:  2.633\n",
      "Epoch   2 Batch  320/491 - Train Accuracy:  0.918, Validation Accuracy:  0.916, Loss:  2.616\n",
      "Epoch   2 Batch  321/491 - Train Accuracy:  0.911, Validation Accuracy:  0.914, Loss:  2.661\n",
      "Epoch   2 Batch  322/491 - Train Accuracy:  0.896, Validation Accuracy:  0.907, Loss:  2.652\n",
      "Epoch   2 Batch  323/491 - Train Accuracy:  0.914, Validation Accuracy:  0.919, Loss:  2.593\n",
      "Epoch   2 Batch  324/491 - Train Accuracy:  0.921, Validation Accuracy:  0.899, Loss:  2.674\n",
      "Epoch   2 Batch  325/491 - Train Accuracy:  0.922, Validation Accuracy:  0.897, Loss:  2.696\n",
      "Epoch   2 Batch  326/491 - Train Accuracy:  0.910, Validation Accuracy:  0.901, Loss:  2.592\n",
      "Epoch   2 Batch  327/491 - Train Accuracy:  0.913, Validation Accuracy:  0.907, Loss:  2.669\n",
      "Epoch   2 Batch  328/491 - Train Accuracy:  0.921, Validation Accuracy:  0.907, Loss:  2.605\n",
      "Epoch   2 Batch  329/491 - Train Accuracy:  0.925, Validation Accuracy:  0.911, Loss:  2.664\n",
      "Epoch   2 Batch  330/491 - Train Accuracy:  0.930, Validation Accuracy:  0.917, Loss:  2.710\n",
      "Epoch   2 Batch  331/491 - Train Accuracy:  0.916, Validation Accuracy:  0.916, Loss:  2.657\n",
      "Epoch   2 Batch  332/491 - Train Accuracy:  0.901, Validation Accuracy:  0.919, Loss:  2.654\n",
      "Epoch   2 Batch  333/491 - Train Accuracy:  0.922, Validation Accuracy:  0.916, Loss:  2.641\n",
      "Epoch   2 Batch  334/491 - Train Accuracy:  0.925, Validation Accuracy:  0.913, Loss:  2.618\n",
      "Epoch   2 Batch  335/491 - Train Accuracy:  0.927, Validation Accuracy:  0.914, Loss:  2.695\n",
      "Epoch   2 Batch  336/491 - Train Accuracy:  0.921, Validation Accuracy:  0.903, Loss:  2.625\n",
      "Epoch   2 Batch  337/491 - Train Accuracy:  0.912, Validation Accuracy:  0.901, Loss:  2.657\n",
      "Epoch   2 Batch  338/491 - Train Accuracy:  0.912, Validation Accuracy:  0.906, Loss:  2.624\n",
      "Epoch   2 Batch  339/491 - Train Accuracy:  0.918, Validation Accuracy:  0.905, Loss:  2.726\n",
      "Epoch   2 Batch  340/491 - Train Accuracy:  0.920, Validation Accuracy:  0.906, Loss:  2.642\n",
      "Epoch   2 Batch  341/491 - Train Accuracy:  0.929, Validation Accuracy:  0.911, Loss:  2.632\n",
      "Epoch   2 Batch  342/491 - Train Accuracy:  0.918, Validation Accuracy:  0.911, Loss:  2.686\n",
      "Epoch   2 Batch  343/491 - Train Accuracy:  0.931, Validation Accuracy:  0.914, Loss:  2.680\n",
      "Epoch   2 Batch  344/491 - Train Accuracy:  0.945, Validation Accuracy:  0.906, Loss:  2.672\n",
      "Epoch   2 Batch  345/491 - Train Accuracy:  0.932, Validation Accuracy:  0.903, Loss:  2.654\n",
      "Epoch   2 Batch  346/491 - Train Accuracy:  0.915, Validation Accuracy:  0.904, Loss:  2.655\n",
      "Epoch   2 Batch  347/491 - Train Accuracy:  0.937, Validation Accuracy:  0.903, Loss:  2.676\n",
      "Epoch   2 Batch  348/491 - Train Accuracy:  0.909, Validation Accuracy:  0.901, Loss:  2.650\n",
      "Epoch   2 Batch  349/491 - Train Accuracy:  0.927, Validation Accuracy:  0.907, Loss:  2.642\n",
      "Epoch   2 Batch  350/491 - Train Accuracy:  0.918, Validation Accuracy:  0.911, Loss:  2.644\n",
      "Epoch   2 Batch  351/491 - Train Accuracy:  0.936, Validation Accuracy:  0.910, Loss:  2.621\n",
      "Epoch   2 Batch  352/491 - Train Accuracy:  0.905, Validation Accuracy:  0.911, Loss:  2.640\n",
      "Epoch   2 Batch  353/491 - Train Accuracy:  0.898, Validation Accuracy:  0.891, Loss:  2.645\n",
      "Epoch   2 Batch  354/491 - Train Accuracy:  0.929, Validation Accuracy:  0.889, Loss:  2.619\n",
      "Epoch   2 Batch  355/491 - Train Accuracy:  0.926, Validation Accuracy:  0.893, Loss:  2.656\n",
      "Epoch   2 Batch  356/491 - Train Accuracy:  0.927, Validation Accuracy:  0.902, Loss:  2.619\n",
      "Epoch   2 Batch  357/491 - Train Accuracy:  0.908, Validation Accuracy:  0.902, Loss:  2.681\n",
      "Epoch   2 Batch  358/491 - Train Accuracy:  0.918, Validation Accuracy:  0.907, Loss:  2.616\n",
      "Epoch   2 Batch  359/491 - Train Accuracy:  0.910, Validation Accuracy:  0.920, Loss:  2.601\n",
      "Epoch   2 Batch  360/491 - Train Accuracy:  0.907, Validation Accuracy:  0.920, Loss:  2.680\n",
      "Epoch   2 Batch  361/491 - Train Accuracy:  0.933, Validation Accuracy:  0.915, Loss:  2.619\n",
      "Epoch   2 Batch  362/491 - Train Accuracy:  0.940, Validation Accuracy:  0.909, Loss:  2.624\n",
      "Epoch   2 Batch  363/491 - Train Accuracy:  0.914, Validation Accuracy:  0.903, Loss:  2.671\n",
      "Epoch   2 Batch  364/491 - Train Accuracy:  0.912, Validation Accuracy:  0.902, Loss:  2.724\n",
      "Epoch   2 Batch  365/491 - Train Accuracy:  0.921, Validation Accuracy:  0.901, Loss:  2.633\n",
      "Epoch   2 Batch  366/491 - Train Accuracy:  0.926, Validation Accuracy:  0.900, Loss:  2.640\n",
      "Epoch   2 Batch  367/491 - Train Accuracy:  0.925, Validation Accuracy:  0.906, Loss:  2.642\n",
      "Epoch   2 Batch  368/491 - Train Accuracy:  0.932, Validation Accuracy:  0.904, Loss:  2.687\n",
      "Epoch   2 Batch  369/491 - Train Accuracy:  0.931, Validation Accuracy:  0.895, Loss:  2.597\n",
      "Epoch   2 Batch  370/491 - Train Accuracy:  0.937, Validation Accuracy:  0.901, Loss:  2.628\n",
      "Epoch   2 Batch  371/491 - Train Accuracy:  0.932, Validation Accuracy:  0.894, Loss:  2.578\n",
      "Epoch   2 Batch  372/491 - Train Accuracy:  0.922, Validation Accuracy:  0.902, Loss:  2.652\n",
      "Epoch   2 Batch  373/491 - Train Accuracy:  0.918, Validation Accuracy:  0.916, Loss:  2.641\n",
      "Epoch   2 Batch  374/491 - Train Accuracy:  0.924, Validation Accuracy:  0.920, Loss:  2.658\n",
      "Epoch   2 Batch  375/491 - Train Accuracy:  0.926, Validation Accuracy:  0.919, Loss:  2.641\n",
      "Epoch   2 Batch  376/491 - Train Accuracy:  0.912, Validation Accuracy:  0.921, Loss:  2.670\n",
      "Epoch   2 Batch  377/491 - Train Accuracy:  0.931, Validation Accuracy:  0.918, Loss:  2.689\n",
      "Epoch   2 Batch  378/491 - Train Accuracy:  0.928, Validation Accuracy:  0.919, Loss:  2.638\n",
      "Epoch   2 Batch  379/491 - Train Accuracy:  0.924, Validation Accuracy:  0.918, Loss:  2.622\n",
      "Epoch   2 Batch  380/491 - Train Accuracy:  0.917, Validation Accuracy:  0.916, Loss:  2.663\n",
      "Epoch   2 Batch  381/491 - Train Accuracy:  0.930, Validation Accuracy:  0.914, Loss:  2.625\n",
      "Epoch   2 Batch  382/491 - Train Accuracy:  0.906, Validation Accuracy:  0.913, Loss:  2.618\n",
      "Epoch   2 Batch  383/491 - Train Accuracy:  0.933, Validation Accuracy:  0.913, Loss:  2.674\n",
      "Epoch   2 Batch  384/491 - Train Accuracy:  0.893, Validation Accuracy:  0.917, Loss:  2.646\n",
      "Epoch   2 Batch  385/491 - Train Accuracy:  0.922, Validation Accuracy:  0.926, Loss:  2.613\n",
      "Epoch   2 Batch  386/491 - Train Accuracy:  0.914, Validation Accuracy:  0.924, Loss:  2.585\n",
      "Epoch   2 Batch  387/491 - Train Accuracy:  0.919, Validation Accuracy:  0.927, Loss:  2.615\n",
      "Epoch   2 Batch  388/491 - Train Accuracy:  0.919, Validation Accuracy:  0.929, Loss:  2.667\n",
      "Epoch   2 Batch  389/491 - Train Accuracy:  0.895, Validation Accuracy:  0.929, Loss:  2.663\n",
      "Epoch   2 Batch  390/491 - Train Accuracy:  0.928, Validation Accuracy:  0.928, Loss:  2.620\n",
      "Epoch   2 Batch  391/491 - Train Accuracy:  0.921, Validation Accuracy:  0.928, Loss:  2.619\n",
      "Epoch   2 Batch  392/491 - Train Accuracy:  0.912, Validation Accuracy:  0.895, Loss:  2.616\n",
      "Epoch   2 Batch  393/491 - Train Accuracy:  0.918, Validation Accuracy:  0.895, Loss:  2.624\n",
      "Epoch   2 Batch  394/491 - Train Accuracy:  0.891, Validation Accuracy:  0.895, Loss:  2.680\n",
      "Epoch   2 Batch  395/491 - Train Accuracy:  0.902, Validation Accuracy:  0.907, Loss:  2.693\n",
      "Epoch   2 Batch  396/491 - Train Accuracy:  0.912, Validation Accuracy:  0.917, Loss:  2.623\n",
      "Epoch   2 Batch  397/491 - Train Accuracy:  0.922, Validation Accuracy:  0.913, Loss:  2.700\n",
      "Epoch   2 Batch  398/491 - Train Accuracy:  0.925, Validation Accuracy:  0.907, Loss:  2.674\n",
      "Epoch   2 Batch  399/491 - Train Accuracy:  0.895, Validation Accuracy:  0.914, Loss:  2.630\n",
      "Epoch   2 Batch  400/491 - Train Accuracy:  0.918, Validation Accuracy:  0.908, Loss:  2.639\n",
      "Epoch   2 Batch  401/491 - Train Accuracy:  0.940, Validation Accuracy:  0.902, Loss:  2.655\n",
      "Epoch   2 Batch  402/491 - Train Accuracy:  0.912, Validation Accuracy:  0.904, Loss:  2.637\n",
      "Epoch   2 Batch  403/491 - Train Accuracy:  0.930, Validation Accuracy:  0.904, Loss:  2.711\n",
      "Epoch   2 Batch  404/491 - Train Accuracy:  0.917, Validation Accuracy:  0.908, Loss:  2.640\n",
      "Epoch   2 Batch  405/491 - Train Accuracy:  0.929, Validation Accuracy:  0.915, Loss:  2.609\n",
      "Epoch   2 Batch  406/491 - Train Accuracy:  0.918, Validation Accuracy:  0.904, Loss:  2.640\n",
      "Epoch   2 Batch  407/491 - Train Accuracy:  0.933, Validation Accuracy:  0.904, Loss:  2.605\n",
      "Epoch   2 Batch  408/491 - Train Accuracy:  0.920, Validation Accuracy:  0.907, Loss:  2.664\n",
      "Epoch   2 Batch  409/491 - Train Accuracy:  0.934, Validation Accuracy:  0.904, Loss:  2.595\n",
      "Epoch   2 Batch  410/491 - Train Accuracy:  0.929, Validation Accuracy:  0.912, Loss:  2.655\n",
      "Epoch   2 Batch  411/491 - Train Accuracy:  0.927, Validation Accuracy:  0.906, Loss:  2.713\n",
      "Epoch   2 Batch  412/491 - Train Accuracy:  0.916, Validation Accuracy:  0.910, Loss:  2.710\n",
      "Epoch   2 Batch  413/491 - Train Accuracy:  0.928, Validation Accuracy:  0.907, Loss:  2.663\n",
      "Epoch   2 Batch  414/491 - Train Accuracy:  0.890, Validation Accuracy:  0.906, Loss:  2.662\n",
      "Epoch   2 Batch  415/491 - Train Accuracy:  0.908, Validation Accuracy:  0.906, Loss:  2.624\n",
      "Epoch   2 Batch  416/491 - Train Accuracy:  0.926, Validation Accuracy:  0.901, Loss:  2.633\n",
      "Epoch   2 Batch  417/491 - Train Accuracy:  0.922, Validation Accuracy:  0.901, Loss:  2.623\n",
      "Epoch   2 Batch  418/491 - Train Accuracy:  0.923, Validation Accuracy:  0.909, Loss:  2.649\n",
      "Epoch   2 Batch  419/491 - Train Accuracy:  0.932, Validation Accuracy:  0.918, Loss:  2.627\n",
      "Epoch   2 Batch  420/491 - Train Accuracy:  0.917, Validation Accuracy:  0.911, Loss:  2.618\n",
      "Epoch   2 Batch  421/491 - Train Accuracy:  0.905, Validation Accuracy:  0.914, Loss:  2.560\n",
      "Epoch   2 Batch  422/491 - Train Accuracy:  0.934, Validation Accuracy:  0.912, Loss:  2.582\n",
      "Epoch   2 Batch  423/491 - Train Accuracy:  0.923, Validation Accuracy:  0.920, Loss:  2.670\n",
      "Epoch   2 Batch  424/491 - Train Accuracy:  0.913, Validation Accuracy:  0.923, Loss:  2.662\n",
      "Epoch   2 Batch  425/491 - Train Accuracy:  0.904, Validation Accuracy:  0.916, Loss:  2.655\n",
      "Epoch   2 Batch  426/491 - Train Accuracy:  0.921, Validation Accuracy:  0.904, Loss:  2.658\n",
      "Epoch   2 Batch  427/491 - Train Accuracy:  0.908, Validation Accuracy:  0.898, Loss:  2.720\n",
      "Epoch   2 Batch  428/491 - Train Accuracy:  0.942, Validation Accuracy:  0.901, Loss:  2.608\n",
      "Epoch   2 Batch  429/491 - Train Accuracy:  0.942, Validation Accuracy:  0.901, Loss:  2.666\n",
      "Epoch   2 Batch  430/491 - Train Accuracy:  0.927, Validation Accuracy:  0.907, Loss:  2.643\n",
      "Epoch   2 Batch  431/491 - Train Accuracy:  0.918, Validation Accuracy:  0.909, Loss:  2.602\n",
      "Epoch   2 Batch  432/491 - Train Accuracy:  0.917, Validation Accuracy:  0.906, Loss:  2.613\n",
      "Epoch   2 Batch  433/491 - Train Accuracy:  0.929, Validation Accuracy:  0.904, Loss:  2.724\n",
      "Epoch   2 Batch  434/491 - Train Accuracy:  0.900, Validation Accuracy:  0.906, Loss:  2.604\n",
      "Epoch   2 Batch  435/491 - Train Accuracy:  0.930, Validation Accuracy:  0.905, Loss:  2.668\n",
      "Epoch   2 Batch  436/491 - Train Accuracy:  0.923, Validation Accuracy:  0.914, Loss:  2.613\n",
      "Epoch   2 Batch  437/491 - Train Accuracy:  0.928, Validation Accuracy:  0.907, Loss:  2.689\n",
      "Epoch   2 Batch  438/491 - Train Accuracy:  0.933, Validation Accuracy:  0.898, Loss:  2.679\n",
      "Epoch   2 Batch  439/491 - Train Accuracy:  0.942, Validation Accuracy:  0.899, Loss:  2.653\n",
      "Epoch   2 Batch  440/491 - Train Accuracy:  0.917, Validation Accuracy:  0.903, Loss:  2.618\n",
      "Epoch   2 Batch  441/491 - Train Accuracy:  0.904, Validation Accuracy:  0.910, Loss:  2.628\n",
      "Epoch   2 Batch  442/491 - Train Accuracy:  0.928, Validation Accuracy:  0.913, Loss:  2.640\n",
      "Epoch   2 Batch  443/491 - Train Accuracy:  0.914, Validation Accuracy:  0.909, Loss:  2.612\n",
      "Epoch   2 Batch  444/491 - Train Accuracy:  0.915, Validation Accuracy:  0.910, Loss:  2.652\n",
      "Epoch   2 Batch  445/491 - Train Accuracy:  0.931, Validation Accuracy:  0.912, Loss:  2.589\n",
      "Epoch   2 Batch  446/491 - Train Accuracy:  0.931, Validation Accuracy:  0.915, Loss:  2.750\n",
      "Epoch   2 Batch  447/491 - Train Accuracy:  0.931, Validation Accuracy:  0.905, Loss:  2.625\n",
      "Epoch   2 Batch  448/491 - Train Accuracy:  0.934, Validation Accuracy:  0.901, Loss:  2.557\n",
      "Epoch   2 Batch  449/491 - Train Accuracy:  0.941, Validation Accuracy:  0.901, Loss:  2.622\n",
      "Epoch   2 Batch  450/491 - Train Accuracy:  0.900, Validation Accuracy:  0.913, Loss:  2.677\n",
      "Epoch   2 Batch  451/491 - Train Accuracy:  0.903, Validation Accuracy:  0.909, Loss:  2.613\n",
      "Epoch   2 Batch  452/491 - Train Accuracy:  0.927, Validation Accuracy:  0.911, Loss:  2.650\n",
      "Epoch   2 Batch  453/491 - Train Accuracy:  0.943, Validation Accuracy:  0.913, Loss:  2.647\n",
      "Epoch   2 Batch  454/491 - Train Accuracy:  0.926, Validation Accuracy:  0.919, Loss:  2.649\n",
      "Epoch   2 Batch  455/491 - Train Accuracy:  0.944, Validation Accuracy:  0.926, Loss:  2.635\n",
      "Epoch   2 Batch  456/491 - Train Accuracy:  0.926, Validation Accuracy:  0.909, Loss:  2.691\n",
      "Epoch   2 Batch  457/491 - Train Accuracy:  0.899, Validation Accuracy:  0.903, Loss:  2.629\n",
      "Epoch   2 Batch  458/491 - Train Accuracy:  0.928, Validation Accuracy:  0.910, Loss:  2.607\n",
      "Epoch   2 Batch  459/491 - Train Accuracy:  0.929, Validation Accuracy:  0.907, Loss:  2.626\n",
      "Epoch   2 Batch  460/491 - Train Accuracy:  0.900, Validation Accuracy:  0.916, Loss:  2.705\n",
      "Epoch   2 Batch  461/491 - Train Accuracy:  0.933, Validation Accuracy:  0.911, Loss:  2.658\n",
      "Epoch   2 Batch  462/491 - Train Accuracy:  0.901, Validation Accuracy:  0.913, Loss:  2.646\n",
      "Epoch   2 Batch  463/491 - Train Accuracy:  0.892, Validation Accuracy:  0.915, Loss:  2.589\n",
      "Epoch   2 Batch  464/491 - Train Accuracy:  0.940, Validation Accuracy:  0.921, Loss:  2.684\n",
      "Epoch   2 Batch  465/491 - Train Accuracy:  0.942, Validation Accuracy:  0.921, Loss:  2.673\n",
      "Epoch   2 Batch  466/491 - Train Accuracy:  0.926, Validation Accuracy:  0.920, Loss:  2.603\n",
      "Epoch   2 Batch  467/491 - Train Accuracy:  0.939, Validation Accuracy:  0.918, Loss:  2.649\n",
      "Epoch   2 Batch  468/491 - Train Accuracy:  0.935, Validation Accuracy:  0.920, Loss:  2.666\n",
      "Epoch   2 Batch  469/491 - Train Accuracy:  0.920, Validation Accuracy:  0.917, Loss:  2.670\n",
      "Epoch   2 Batch  470/491 - Train Accuracy:  0.932, Validation Accuracy:  0.907, Loss:  2.654\n",
      "Epoch   2 Batch  471/491 - Train Accuracy:  0.926, Validation Accuracy:  0.906, Loss:  2.632\n",
      "Epoch   2 Batch  472/491 - Train Accuracy:  0.941, Validation Accuracy:  0.902, Loss:  2.663\n",
      "Epoch   2 Batch  473/491 - Train Accuracy:  0.910, Validation Accuracy:  0.908, Loss:  2.640\n",
      "Epoch   2 Batch  474/491 - Train Accuracy:  0.923, Validation Accuracy:  0.905, Loss:  2.640\n",
      "Epoch   2 Batch  475/491 - Train Accuracy:  0.923, Validation Accuracy:  0.907, Loss:  2.636\n",
      "Epoch   2 Batch  476/491 - Train Accuracy:  0.921, Validation Accuracy:  0.911, Loss:  2.653\n",
      "Epoch   2 Batch  477/491 - Train Accuracy:  0.906, Validation Accuracy:  0.917, Loss:  2.726\n",
      "Epoch   2 Batch  478/491 - Train Accuracy:  0.957, Validation Accuracy:  0.920, Loss:  2.688\n",
      "Epoch   2 Batch  479/491 - Train Accuracy:  0.927, Validation Accuracy:  0.920, Loss:  2.618\n",
      "Epoch   2 Batch  480/491 - Train Accuracy:  0.926, Validation Accuracy:  0.918, Loss:  2.611\n",
      "Epoch   2 Batch  481/491 - Train Accuracy:  0.944, Validation Accuracy:  0.923, Loss:  2.725\n",
      "Epoch   2 Batch  482/491 - Train Accuracy:  0.925, Validation Accuracy:  0.926, Loss:  2.632\n",
      "Epoch   2 Batch  483/491 - Train Accuracy:  0.917, Validation Accuracy:  0.917, Loss:  2.682\n",
      "Epoch   2 Batch  484/491 - Train Accuracy:  0.922, Validation Accuracy:  0.918, Loss:  2.672\n",
      "Epoch   2 Batch  485/491 - Train Accuracy:  0.920, Validation Accuracy:  0.917, Loss:  2.706\n",
      "Epoch   2 Batch  486/491 - Train Accuracy:  0.943, Validation Accuracy:  0.912, Loss:  2.633\n",
      "Epoch   2 Batch  487/491 - Train Accuracy:  0.927, Validation Accuracy:  0.916, Loss:  2.608\n",
      "Epoch   2 Batch  488/491 - Train Accuracy:  0.946, Validation Accuracy:  0.919, Loss:  2.613\n",
      "Epoch   2 Batch  489/491 - Train Accuracy:  0.913, Validation Accuracy:  0.916, Loss:  2.656\n",
      "Model Trained and Saved\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "def get_accuracy(target, logits):\n",
    "    \"\"\"\n",
    "    Calculate accuracy\n",
    "    \"\"\"\n",
    "    max_seq = max(target.shape[1], logits.shape[1])\n",
    "    if max_seq - target.shape[1]:\n",
    "        target = np.pad(\n",
    "            target,\n",
    "            [(0,0),(0,max_seq - target.shape[1])],\n",
    "            'constant')\n",
    "    if max_seq - logits.shape[1]:\n",
    "        logits = np.pad(\n",
    "            logits,\n",
    "            [(0,0),(0,max_seq - logits.shape[1]), (0,0)],\n",
    "            'constant')\n",
    "\n",
    "    return np.mean(np.equal(target, np.argmax(logits, 2)))\n",
    "\n",
    "train_source = source_int_text[batch_size:]\n",
    "train_target = target_int_text[batch_size:]\n",
    "\n",
    "valid_source = helper.pad_sentence_batch(source_int_text[:batch_size])\n",
    "valid_target = helper.pad_sentence_batch(target_int_text[:batch_size])\n",
    "\n",
    "with tf.Session(graph=train_graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch_i in range(epochs):\n",
    "        for batch_i, (source_batch, target_batch) in enumerate(\n",
    "                helper.batch_data(train_source, train_target, batch_size)):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            _, loss = sess.run(\n",
    "                [train_op, cost],\n",
    "                {input_data: source_batch,\n",
    "                 targets: target_batch,\n",
    "                 lr: learning_rate,\n",
    "                 sequence_length: target_batch.shape[1],\n",
    "                 keep_prob: keep_probability})\n",
    "            \n",
    "            batch_train_logits = sess.run(\n",
    "                inference_logits,\n",
    "                {input_data: source_batch, keep_prob: 1.0})\n",
    "            batch_valid_logits = sess.run(\n",
    "                inference_logits,\n",
    "                {input_data: valid_source, keep_prob: 1.0})\n",
    "                \n",
    "            train_acc = get_accuracy(target_batch, batch_train_logits)\n",
    "            valid_acc = get_accuracy(np.array(valid_target), batch_valid_logits)\n",
    "            end_time = time.time()\n",
    "            print('Epoch {:>3} Batch {:>4}/{} - Train Accuracy: {:>6.3f}, Validation Accuracy: {:>6.3f}, Loss: {:>6.3f}'\n",
    "                  .format(epoch_i, batch_i, len(source_int_text) // batch_size, train_acc, valid_acc, loss))\n",
    "\n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    saver.save(sess, save_path)\n",
    "    print('Model Trained and Saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### 保存参数\n",
    "\n",
    "保存 `batch_size` 和 `save_path` 参数以进行推论（for inference）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Save parameters for checkpoint\n",
    "helper.save_params(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 检查点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import helper\n",
    "import problem_unittests as tests\n",
    "\n",
    "_, (source_vocab_to_int, target_vocab_to_int), (source_int_to_vocab, target_int_to_vocab) = helper.load_preprocess()\n",
    "load_path = helper.load_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 句子到序列\n",
    "\n",
    "要向模型提供要翻译的句子，你首先需要预处理该句子。实现函数 `sentence_to_seq()` 以预处理新的句子。\n",
    "\n",
    "- 将句子转换为小写形式\n",
    "- 使用 `vocab_to_int` 将单词转换为 id\n",
    " - 如果单词不在词汇表中，将其转换为`<UNK>` 单词 id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def sentence_to_seq(sentence, vocab_to_int):\n",
    "    \"\"\"\n",
    "    Convert a sentence to a sequence of ids\n",
    "    :param sentence: String\n",
    "    :param vocab_to_int: Dictionary to go from the words to an id\n",
    "    :return: List of word ids\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    words = sentence.lower().split(' ')\n",
    "    ids = []\n",
    "    for w in words:\n",
    "        if(w in vocab_to_int):\n",
    "            ids.append(vocab_to_int[w])\n",
    "        else:\n",
    "            ids.append(vocab_to_int['<UNK>'])\n",
    "    return ids\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_sentence_to_seq(sentence_to_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 翻译\n",
    "\n",
    "将 `translate_sentence` 从英语翻译成法语。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "  Word Ids:      [200, 164, 121, 68, 137, 205, 88]\n",
      "  English Words: ['he', 'saw', 'a', 'old', 'yellow', 'truck', '.']\n",
      "\n",
      "Prediction\n",
      "  Word Ids:      [89, 245, 355, 184, 46, 338, 277, 138, 1]\n",
      "  French Words: ['il', 'a', 'vu', 'un', 'vieux', 'camion', 'jaune', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "translate_sentence = 'he saw a old yellow truck .'\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "translate_sentence = sentence_to_seq(translate_sentence, source_vocab_to_int)\n",
    "\n",
    "loaded_graph = tf.Graph()\n",
    "with tf.Session(graph=loaded_graph) as sess:\n",
    "    # Load saved model\n",
    "    loader = tf.train.import_meta_graph(load_path + '.meta')\n",
    "    loader.restore(sess, load_path)\n",
    "\n",
    "    input_data = loaded_graph.get_tensor_by_name('input:0')\n",
    "    logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "    keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "\n",
    "    translate_logits = sess.run(logits, {input_data: [translate_sentence], keep_prob: 1.0})[0]\n",
    "\n",
    "print('Input')\n",
    "print('  Word Ids:      {}'.format([i for i in translate_sentence]))\n",
    "print('  English Words: {}'.format([source_int_to_vocab[i] for i in translate_sentence]))\n",
    "\n",
    "print('\\nPrediction')\n",
    "print('  Word Ids:      {}'.format([i for i in np.argmax(translate_logits, 1)]))\n",
    "print('  French Words: {}'.format([target_int_to_vocab[i] for i in np.argmax(translate_logits, 1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 不完美的翻译\n",
    "\n",
    "你可能注意到了，某些句子的翻译质量比其他的要好。因为你使用的数据集只有 227 个英语单词，但实际生活中有数千个单词，只有使用这些单词的句子结果才会比较理想。对于此项目，不需要达到完美的翻译。但是，如果你想创建更好的翻译模型，则需要更好的数据。\n",
    "\n",
    "你可以使用 [WMT10 French-English corpus](http://www.statmt.org/wmt10/training-giga-fren.tar) 语料库训练模型。该数据集拥有更多的词汇，讨论的话题也更丰富。但是，训练时间要好多天的时间，所以确保你有 GPU 并且对于我们提供的数据集，你的神经网络性能很棒。提交此项目后，别忘了研究下 WMT10 语料库。\n",
    "\n",
    "\n",
    "## 提交项目\n",
    "\n",
    "提交项目时，确保先运行所有单元，然后再保存记事本。保存记事本文件为 “dlnd_language_translation.ipynb”，再通过菜单中的“文件” ->“下载为”将其另存为 HTML 格式。提交的项目文档中需包含“helper.py”和“problem_unittests.py”文件。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
